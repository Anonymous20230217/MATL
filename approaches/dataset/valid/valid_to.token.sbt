( parameters : list of network parameters to tune these can be obtain by the root operator's parameters ) ( lr : func learn parameter schedule a learn rate in float or a learn rate schedule see also func learn parameter schedule ) ( gamma : trade off factor for current and previous gradients common value be 0 95 should be in range 0 0 1 0 ) ( inc : increase factor when try to adjust current learn rate should be greater than 1 ) ( dec : decrease factor when try to adjust current learn rate should be in range 0 0 1 0 ) ( max : maximum scale allow for the initial learn rate should be greater than zero and min ) ( min : the minibatch size that the learner's parameters be design or pre tune for this ) ( need ave multiplier : ) ( l1 regularization weight : the l1 regularization weight per sample default to 0 0 ) ( l2 regularization weight : the l2 regularization weight per sample default to 0 0 ) ( gaussian noise injection std dev : the standard deviation of the gaussian noise add to parameters post update default to 0 0 ) ( gradient clip threshold per sample : clip threshold per sample default to infinity ) ( gradient clip with truncation : use gradient clip with truncation ) ( use mean gradient : use average gradient as input to learner deprecate 2 2 use minibatch size parameter to specify the reference minibatch size ) ( minibatch size : the minibatch size that the learner's parameters be design or pre tune for this size be usually set to the same as the minibatch data source's size cntk will perform automatic scale of the parameters to enable efficient model parameter update implementation while approximate the behavior of pre design and pre tune parameters in case that minibatch size be not specify cntk will inherit the minibatch size from the learn rate schedule if the learn rate schedule do not specify the minibatch size cntk will set it to attr ignore set minibatch size to attr ignore will have the learner apply as it be prevent cntk perform any hyper parameter scale see also func learn parameter schedule ) ( epoch size : number of sample as a schedule unit for learn rate see also func learn parameter schedule )
( parameters : list of network parameters to tune these can be obtain by the root operator's parameters ) ( lr : func learn parameter schedule a learn rate in float or a learn rate schedule see also func learn parameter schedule ) ( need ave multiplier : ) ( l1 regularization weight : the l1 regularization weight per sample default to 0 0 ) ( l2 regularization weight : the l2 regularization weight per sample default to 0 0 ) ( gaussian noise injection std dev : the standard deviation of the gaussian noise add to parameters post update default to 0 0 ) ( gradient clip threshold per sample : clip threshold per sample default to infinity ) ( gradient clip with truncation : use gradient clip with truncation ) ( use mean gradient : use average gradient as input to learner deprecate 2 2 use minibatch size parameter to specify the reference minibatch size ) ( minibatch size : the minibatch size that the learner's parameters be design or pre tune for this size be usually set to the same as the minibatch data source's size cntk will perform automatic scale of the parameters to enable efficient model parameter update implementation while approximate the behavior of pre design and pre tune parameters in case that minibatch size be not specify cntk will inherit the minibatch size from the learn rate schedule if the learn rate schedule do not specify the minibatch size cntk will set it to attr ignore set minibatch size to attr ignore will have the learner apply as it be prevent cntk perform any hyper parameter scale see also func learn parameter schedule ) ( epoch size : number of sample as a schedule unit for learn rate see also func learn parameter schedule )
( model : either a file path of a model file or a byte buffer containing the binary representation of a model )  ( device : specifies the device to allocate the model on )  ( format : specifies the format of the file to load. if the specified format is ONNX, then model must be a filename )
( operand : input tensor with dimension math c \\times h \\times w ) ( block size : integer value this define the size of the spatial block whose elements be move to the depth dimension size of spatial dimension h w in the input tensor must be divisible by math block size ) ( name : the name of the function instance in the network )
( x : tensor to be pad ) ( pattern : how many value to add before and after the content of the tensor in each dimension ) ( mode : pad mode c ops constant pad c ops reflect pad and c ops symmetric pad ) ( constant value : the value use to fill the pad cells only meaningful under constant mode ) ( name : the name of the function instance in the network )
