( scale : scale ) ( output rank : output rank ) ( filter rank : filter rank ) ( seed : random seed )
( x : class cntk ops function function any class cntk ops function function that output a tensor ) ( alpha : the name of the function instance in the network )
( filter_shape : shape  ( spatial extent )  of the receptive field, not including the input feature-map depth. E.g.  ( 3,3 )  for a 2D convolution )  ( num_filters : number of filters  ( output feature-map depth ) , or  (  )  to denote scalar output items  ( output shape will have no depth axis ) . )  ( activation : optional function to apply at the end, e.g. relu )  ( init : initial value of weights W )  ( pad : if False, then the filter will be shifted over the 'valid' area of input, that is, no value outside the area is used. If pad=True on the other hand, the filter will be applied to all input positions, and positions outside the valid region will be considered containing zero. Use a tuple to specify a per-axis value )  ( strides : stride of the convolution  ( increment when sliding the filter over the input ) . Use a tuple to specify a per-axis value )  ( bias : the layer will have no bias if False is passed here )  ( init_bias : initial value of weights b )  ( output_shape : output shape. When strides > 2, the output shape is non-deterministic. User can specify the wanted output shape. Note the specified shape must satisify the condition that if a convolution is perform from the output with the same setting, the result must have same shape as the input. that is stored with tensor shape  ( H,W )  instead of  ( 1,H,W )  )  ( reduction_rank : set to 0 if input items are scalars  ( input has no depth axis ) , e.g. an audio signal or a black-and-white image )  ( dilation : the dilation value along each axis, default 1 mean no dilation )  ( name : the name of the Function instance in the network )
( shape : vector or tensor dimension of the output of this layer ) ( activation : class cntk ops function function default to identity optional function to apply at the end e g relu ) ( init : mod cntk initializer default to 0 initial value of weight b ) ( input rank : number of infer ax to add to w map rank must not be give ) ( map rank : expand w to leave exactly map rank ax input rank must not be give ) ( bias : the layer will have no bias if false be pass here ) ( init bias : mod cntk initializer default to 0 initial value of weight b ) ( name : the name of the function instance in the network )
( scale : scale ) ( seed : random seed )
( x : class cntk ops function function any class cntk ops function function that output a tensor ) ( alpha : the name of the function instance in the network )
( filter shape : shape spatial extent of the receptive field not include the input feature map depth e g 3 3 for a 2d convolution ) ( stride : stride increment when slide over the input use a tuple to specify a per axis value ) ( pad : if false then the pool operation will be shift over the "valid" area of input that be no value outside the area be use if pad true on the other hand pool will be apply to all input position and position outside the valid region will be consider contain zero use a tuple to specify a per axis value ) ( name : the name of the function instance in the network )
( x : input tensor ) ( dropout rate : probability of drop out an element mutually exclusive with keep prob ) ( seed : random seed ) ( name : class str optional the name of the function instance in the network )
( parameters : list of network parameters to tune these can be obtain by the root operator's parameters ) ( lr : func learn parameter schedule a learn rate in float or a learn rate schedule see also func learn parameter schedule ) ( gamma : trade off factor for current and previous gradients common value be 0 95 should be in range 0 0 1 0 ) ( inc : increase factor when try to adjust current learn rate should be greater than 1 ) ( dec : decrease factor when try to adjust current learn rate should be in range 0 0 1 0 ) ( max : maximum scale allow for the initial learn rate should be greater than zero and min ) ( min : the minibatch size that the learner's parameters be design or pre tune for this ) ( need ave multiplier : ) ( l1 regularization weight : the l1 regularization weight per sample default to 0 0 ) ( l2 regularization weight : the l2 regularization weight per sample default to 0 0 ) ( gaussian noise injection std dev : the standard deviation of the gaussian noise add to parameters post update default to 0 0 ) ( gradient clip threshold per sample : clip threshold per sample default to infinity ) ( gradient clip with truncation : use gradient clip with truncation ) ( use mean gradient : use average gradient as input to learner deprecate 2 2 use minibatch size parameter to specify the reference minibatch size ) ( minibatch size : the minibatch size that the learner's parameters be design or pre tune for this size be usually set to the same as the minibatch data source's size cntk will perform automatic scale of the parameters to enable efficient model parameter update implementation while approximate the behavior of pre design and pre tune parameters in case that minibatch size be not specify cntk will inherit the minibatch size from the learn rate schedule if the learn rate schedule do not specify the minibatch size cntk will set it to attr ignore set minibatch size to attr ignore will have the learner apply as it be prevent cntk perform any hyper parameter scale see also func learn parameter schedule ) ( epoch size : number of sample as a schedule unit for learn rate see also func learn parameter schedule )
( parameters : list of network parameters to tune these can be obtain by the root operator's parameters ) ( lr : func learn parameter schedule a learn rate in float or a learn rate schedule see also func learn parameter schedule ) ( need ave multiplier : ) ( l1 regularization weight : the l1 regularization weight per sample default to 0 0 ) ( l2 regularization weight : the l2 regularization weight per sample default to 0 0 ) ( gaussian noise injection std dev : the standard deviation of the gaussian noise add to parameters post update default to 0 0 ) ( gradient clip threshold per sample : clip threshold per sample default to infinity ) ( gradient clip with truncation : use gradient clip with truncation ) ( use mean gradient : use average gradient as input to learner deprecate 2 2 use minibatch size parameter to specify the reference minibatch size ) ( minibatch size : the minibatch size that the learner's parameters be design or pre tune for this size be usually set to the same as the minibatch data source's size cntk will perform automatic scale of the parameters to enable efficient model parameter update implementation while approximate the behavior of pre design and pre tune parameters in case that minibatch size be not specify cntk will inherit the minibatch size from the learn rate schedule if the learn rate schedule do not specify the minibatch size cntk will set it to attr ignore set minibatch size to attr ignore will have the learner apply as it be prevent cntk perform any hyper parameter scale see also func learn parameter schedule ) ( epoch size : number of sample as a schedule unit for learn rate see also func learn parameter schedule )
( model : either a file path of a model file or a byte buffer containing the binary representation of a model )  ( device : specifies the device to allocate the model on )  ( format : specifies the format of the file to load. if the specified format is ONNX, then model must be a filename )
( operand : input tensor with dimension math c \\times h \\times w ) ( block size : integer value this define the size of the spatial block whose elements be move to the depth dimension size of spatial dimension h w in the input tensor must be divisible by math block size ) ( name : the name of the function instance in the network )
( x : tensor to be pad ) ( pattern : how many value to add before and after the content of the tensor in each dimension ) ( mode : pad mode c ops constant pad c ops reflect pad and c ops symmetric pad ) ( constant value : the value use to fill the pad cells only meaningful under constant mode ) ( name : the name of the function instance in the network )
( filter shape : shape spatial extent of the receptive field not include the input feature map depth e g 3 3 for a 2d convolution ) ( stride : stride increment when slide over the input use a tuple to specify a per axis value ) ( pad : if false then the pool operation will be shift over the "valid" area of input that be no value outside the area be use if pad true on the other hand pool will be apply to all input position and position outside the valid region will be exclude from the average use a tuple to specify a per axis value ) ( name : the name of the function instance in the network )
( x : numpy array or any class cntk ops function function that output a tensor ) ( alpha : the alpha term of the above equation ) ( beta : the beta term of the above equation ) ( name : the name of the function instance in the network )
( filter shape : shape spatial extent of the receptive field not include the input feature map depth e g 3 3 for a 2d convolution ) ( num filter : number of filter output feature map depth or to denote scalar output items output shape will have no depth axis ) ( activation : class cntk ops function function default to identity optional function to apply at the end e g relu ) ( init : mod cntk initializer default to 0 initial value of weight b ) ( pad : if false then the filter will be shift over the "valid" area of input that be no value outside the area be use if pad true on the other hand the filter will be apply to all input position and position outside the valid region will be consider contain zero use a tuple to specify a per axis value ) ( stride : stride of the convolution increment when slide the filter over the input use a tuple to specify a per axis value ) ( bias : the layer will have no bias if false be pass here ) ( init bias : mod cntk initializer default to 0 initial value of weight b ) ( reduction rank : set to 0 if input items be scalars input have no depth axis e g an audio signal or a black and white image that be store with tensor shape h w instead of 1 h w ) ( dilation : the dilation value along each axis default 1 mean no dilation ) ( group : number of group during convolution that control the connections between input and output channel deafult value be 1 which mean that all input channel be convolve to produce all output channel a value of n would mean that the input and output channel be divide into n group with the input channel in one group say i th input group contribute to output channel in only one group i th output group number of input and output channel must be divisble by value of group argument also value of this argument must be strictly positive i e group 0 ) ( name : the name of the function instance in the network )
( shape : vector or tensor dimension of the output of this layer ) ( activation : class cntk ops function function default to identity optional function to apply at the end e g relu ) ( init : mod cntk initializer default to 0 initial value of weight b ) ( input rank : number of infer ax to add to w map rank must not be give ) ( map rank : expand w to leave exactly map rank ax input rank must not be give ) ( bias : the layer will have no bias if false be pass here ) ( init bias : mod cntk initializer default to 0 initial value of weight b ) ( name : the name of the function instance in the network )
( enumeration : NULL )
( x : class cntk ops function function any class cntk ops function function that output a tensor ) ( alpha : the alpha term of the above equation ) ( name : the name of the function instance in the network )
( leave : the name of the function instance in the network )
( shape : vector or tensor dimension of the output of this layer ) ( cell shape : if give then the output state be first compute at cell shape and linearly project to shape ) ( activation : class cntk ops function function default to signmoid function to apply at the end e g relu ) ( init : mod cntk initializer default to 0 initial value of weight b ) ( init bias : mod cntk initializer default to 0 initial value of weight b ) ( enable self stabilization : if true then add a func cntk layer block stabilizer to all state relate projections but not the data input ) ( name : the name of the function instance in the network )
( self : map of the function's arguments to value ) ( wrt : list of variables with respect to which the respect to all arguments of this function that need gradient will be compute ) ( output : output include intermediate output in the graph to fetch value for if not specify value for none of the output be fetch ) ( device : class cntk device devicedescriptor default none the device descriptor that contain the type and id of the device on which the computation be perform if none the default device be use ) ( as numpy : whether to return the gradients as a numpy array default true specify this as false return a cntk value which avoid a costly conversion but return a somewhat opaque object also the value object be temporary and only guarantee to be valid until the next forward/eval/backward/grad call you must explicitly clone the temporay value object if they need to be access later if not specify the output of this function will be use as gradient root ) ( grad root
( filter shape : shape spatial extent of the receptive field not include the input feature map depth e g 3 3 for a 2d convolution ) ( stride : stride increment when slide over the input use a tuple to specify a per axis value ) ( pad : if false then the pool operation will be shift over the "valid" area of input that be no value outside the area be use if pad true on the other hand pool will be apply to all input position and position outside the valid region will be exclude from the average use a tuple to specify a per axis value ) ( name : the name of the function instance in the network )
( layer : class cntk ops function function equivalent python function tuples of function or list thereof the list of function to apply in sequence a tuple aplies each of its items to the input and result in a tuple value an item that be a list will be flatten ) ( name
( parameters : list of network parameters to tune these can be obtain by the parameters method of the root operator ) ( lr : func learn parameter schedule a learn rate in float or a learn rate schedule see also func learn parameter schedule ) ( l1 regularization weight : the l1 regularization weight per sample default to 0 0 ) ( l2 regularization weight : the l2 regularization weight per sample default to 0 0 ) ( gaussian noise injection std dev : the standard deviation of the gaussian noise add to parameters post update default to 0 0 ) ( gradient clip threshold per sample : clip threshold per sample default to infinity ) ( gradient clip with truncation : use gradient clip with truncation ) ( use mean gradient : use average gradient as input to learner deprecate 2 2 use minibatch size parameter to specify the reference minibatch size ) ( minibatch size : the minibatch size that the learner's parameters be design or pre tune for this size be usually set to the same as the minibatch data source's size cntk will perform automatic scale of the parameters to enable efficient model parameter update implementation while approximate the behavior of pre design and pre tune parameters in case that minibatch size be not specify cntk will inherit the minibatch size from the learn rate schedule if the learn rate schedule do not specify the minibatch size cntk will set it to attr ignore set minibatch size to attr ignore will have the learner apply as it be prevent cntk perform any hyper parameter scale see also func learn parameter schedule ) ( epoch size : number of sample as a schedule unit for learn rate see also func learn parameter schedule )
( dropout rate : probability of drop out an element mutually exclusive with keep prob ) ( keep prob : probability of keep an element mutually exclusive with dropout rate ) ( seed : random seed ) ( name : the name of the function instance in the network )
( filter shape : shape spatial extent of the receptive field not include the input feature map depth e g 3 3 for a 2d convolution ) ( stride : stride increment when slide over the input use a tuple to specify a per axis value ) ( pad : if false then the pool operation will be shift over the "valid" area of input that be no value outside the area be use if pad true on the other hand pool will be apply to all input position and position outside the valid region will be exclude from the average use a tuple to specify a per axis value ) ( name : the name of the function instance in the network )
( shape : shape of the output entries be independent random draw ) ( dtype : data type default be np float32 ) ( mean : success probability ) ( seed : pseudo random number generator seed default automatically select a unique seed ) ( name : the name of the function instance in the network )
( shape : shape of the output entries be independent random draw ) ( dtype : data type default be np float32 ) ( mean : mean of the distribution ) ( scale : scale standard deviation of the distribution ) ( seed : pseudo random number generator seed default automatically select a unique seed ) ( name : the name of the function instance in the network )
( x : numpy array or any class cntk ops function function that output a tensor ) ( name : the name of the function instance in the network )
( scale : scale ) ( output rank : output rank ) ( filter rank : filter rank ) ( seed : random seed )
( output : the output value from the network ) ( target : it be usually a one hot vector where the hot bite correspond to the label index ) ( name : the name of the function instance in the network )
( scale : scale ) ( output rank : output rank ) ( filter rank : filter rank ) ( seed : random seed )
