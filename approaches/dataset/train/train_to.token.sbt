( operand : input of the batch normalization operation ) ( scale : parameter tensor that hold the learn componentwise scale factor ) ( bias : parameter tensor that hold the learn bias scale and bias must have the same dimension which must be equal to the input dimension in case of spatial false or number of output convolution feature map in case of spatial true ) ( run mean : run mean which be use during evaluation phase and might be use during train as well you must pass a constant tensor with initial value 0 and the same dimension as scale and bias ) ( run inv std : run variance represent as run mean ) ( spatial : flag that indicate whether to compute mean/var for each feature in a minibatch independently or in case of convolutional layer per future map ) ( normalization time constant : time constant for compute run average of mean and variance as a low pass filter version of the batch statistics ) ( blend time constant : constant for smooth batch estimate with the run statistics ) ( epsilon : conditioner constant add to the variance when compute the inverse standard deviation ) ( use cudnn engine : ) ( disable regularization : turn off regularization in batch normalization ) ( name : the name of the function instance in the network ) ( run count : denote the total number of sample that have be use so far to compute the run mean and run inv std parameters you must pass a scalar either rank 0 constant val )
( operand : the variable to be normalize ) ( mean : per dimension mean to use for the normalization ) ( inv stddev : per dimension standard deviation to use for the normalization ) ( name : the name of the function instance in the network )
( x : numpy array or any class cntk ops function function that output a tensor ) ( y : the name of the function instance in the network )
( parameters : list of network parameters to tune these can be obtain by the root operator's parameters ) ( lr : func learn parameter schedule a learn rate in float or a learn rate schedule see also func learn parameter schedule ) ( momentum : func momentum schedule momentum schedule note that this be the beta1 parameter in the adam paper 1 for additional information please refer to the cntkwiki this cntk wiki article <brainscript sgd block convert learn rate and momentum parameters from other toolkits> ) ( unit gain : when true momentum be interpret as a unit gain filter default to the value return by func default unit gain value ) ( variance momentum : func momentum schedule variance momentum schedule note that this be the beta2 parameter in the adam paper 1 default to momentum schedule per sample 0 9999986111120757 ) ( l1 regularization weight : the l1 regularization weight per sample default to 0 0 ) ( l2 regularization weight : the l2 regularization weight per sample default to 0 0 ) ( gaussian noise injection std dev : the standard deviation of the gaussian noise add to parameters post update default to 0 0 ) ( gradient clip threshold per sample : clip threshold per sample default to infinity ) ( gradient clip with truncation : use gradient clip with truncation ) ( use mean gradient : use average gradient as input to learner deprecate 2 2 use minibatch size parameter to specify the reference minibatch size ) ( epsilon : numerical stability constant default to 1e 8 to false ) ( adamax : the minibatch size that the learner's parameters be design or pre tune for this size be usually set to the same as the minibatch data source's size cntk will perform automatic scale of the parameters to enable efficient model parameter update implementation while approximate the behavior of pre design and pre tune parameters in case that minibatch size be not specify cntk will inherit the minibatch size from the learn rate schedule if the learn rate schedule do not specify the minibatch size cntk will set it to attr ignore set minibatch size to attr ignore will have the learner apply as it be prevent cntk perform any hyper parameter scale see also func learn parameter schedule ) ( epoch size : number of sample as a schedule unit for learn rate momentum and variance momentum see also func learn parameter schedule )
( filter shape : shape spatial extent of the receptive field not include the input feature map depth e g 3 3 for a 2d convolution ) ( num filter : number of filter output feature map depth or to denote scalar output items output shape will have no depth axis ) ( activation : class cntk ops function function default to identity optional function to apply at the end e g relu ) ( init : mod cntk initializer default to 0 initial value of weight b ) ( pad : if false then the filter will be shift over the "valid" area of input that be no value outside the area be use if pad true on the other hand the filter will be apply to all input position and position outside the valid region will be consider contain zero use a tuple to specify a per axis value ) ( stride : stride of the convolution increment when slide the filter over the input use a tuple to specify a per axis value ) ( bias : the layer will have no bias if false be pass here ) ( init bias : mod cntk initializer default to 0 initial value of weight b ) ( reduction rank : set to 0 if input items be scalars input have no depth axis e g an audio signal or a black and white image that be store with tensor shape h w instead of 1 h w ) ( dilation : the dilation value along each axis default 1 mean no dilation ) ( name : the name of the function instance in the network )
( shape : vector or tensor dimension of the output of this layer ) ( cell shape : if give then the output state be first compute at cell shape and linearly project to shape ) ( activation : class cntk ops function function default to func cntk ops tanh function to apply at the end e g relu ) ( use peepholes : ) ( init : mod cntk initializer default to 0 initial value of weight b ) ( init bias : mod cntk initializer default to 0 initial value of weight b ) ( enable self stabilization : if true then add a func cntk layer block stabilizer to all state relate projections but not the data input ) ( name : the name of the function instance in the network )
( scale : scale ) ( output rank : output rank ) ( filter rank : filter rank ) ( seed : random seed )
( node input : class cntk ops function function that output the tensor to be crop ) ( node referent : class cntk ops function function that output the reference tensor ) ( offset x : horizontal crop offset ) ( offset y : vertical crop offset ) ( name : the name of the function instance in the network )
( shape : vector or tensor dimension of the output of this layer ) ( init : mod cntk initializer default to func cntk initializer glorot uniform learnable embed only initial value of weight e ) ( weight : user supply embed only the lookup table the matrix row be the embed vectors weight i be the embed that correspond to input category i ) ( name : the name of the function instance in the network )
( filter shape : shape spatial extent of the receptive field not include the input feature map depth e g 3 3 for a 2d convolution ) ( stride : stride increment when slide over the input use a tuple to specify a per axis value ) ( pad : if false then the pool operation will be shift over the "valid" area of input that be no value outside the area be use if pad true on the other hand pool will be apply to all input position and position outside the valid region will be exclude from the average use a tuple to specify a per axis value ) ( name : the name of the function instance in the network )
( filter_shape : shape  ( spatial extent )  of the receptive field, not including the input feature-map depth. E.g.  ( 3,3 )  for a 2D convolution )  ( num_filters : number of filters  ( output feature-map depth ) , or  (  )  to denote scalar output items  ( output shape will have no depth axis ) . )  ( activation : optional function to apply at the end, e.g. relu )  ( init : initial value of weights W )  ( pad : if False, then the filter will be shifted over the 'valid' area of input, that is, no value outside the area is used. If pad=True on the other hand, the filter will be applied to all input positions, and positions outside the valid region will be considered containing zero. Use a tuple to specify a per-axis value )  ( strides : stride of the convolution  ( increment when sliding the filter over the input ) . Use a tuple to specify a per-axis value )  ( bias : the layer will have no bias if False is passed here )  ( init_bias : initial value of weights b )  ( output_shape : output shape. When strides > 2, the output shape is non-deterministic. User can specify the wanted output shape. Note the specified shape must satisify the condition that if a convolution is perform from the output with the same setting, the result must have same shape as the input. that is stored with tensor shape  ( H,W )  instead of  ( 1,H,W )  )  ( reduction_rank : set to 0 if input items are scalars  ( input has no depth axis ) , e.g. an audio signal or a black-and-white image )  ( dilation : the dilation value along each axis, default 1 mean no dilation )  ( name : the name of the Function instance in the network )
( shape : shape of the output entries be independent random draw ) ( dtype : data type default be np float32 ) ( low : lower end of the range of the random number ) ( high : upper end of the range of the random number ) ( seed : pseudo random number generator seed default automatically select a unique seed ) ( name : the name of the function instance in the network )
( scale : scale ) ( output rank : output rank ) ( filter rank : filter rank ) ( seed : random seed )
( filter shape : shape spatial extent of the receptive field not include the input feature map depth e g 3 3 for a 2d convolution ) ( stride : stride increment when slide over the input use a tuple to specify a per axis value ) ( pad : if false then the pool operation will be shift over the "valid" area of input that be no value outside the area be use if pad true on the other hand pool will be apply to all input position and position outside the valid region will be consider contain zero use a tuple to specify a per axis value ) ( name : the name of the function instance in the network )
( x : class cntk ops function function any class cntk ops function function that output a tensor ) ( steepness : optional steepness factor ) ( name : the name of the function instance in the network )
( filter shape : shape spatial extent of the receptive field not include the input feature map depth e g 3 3 for a 2d convolution ) ( stride : stride increment when slide over the input use a tuple to specify a per axis value ) ( pad : if false then the pool operation will be shift over the "valid" area of input that be no value outside the area be use if pad true on the other hand pool will be apply to all input position and position outside the valid region will be consider contain zero use a tuple to specify a per axis value ) ( name : the name of the function instance in the network )
( x : numpy array or any class cntk ops function function that output a tensor ) ( axis : axis along which the logsoftmax operation will be perform the default be the last axis ) ( name : the name of the function instance in the network )
( x : numpy array or any class cntk ops function function that output a tensor ) ( axis : class cntk axis axis axis along which the softmax operation will be perform ) ( name : the name of the function instance in the network )
( operand : input tensor with dimension math c \\times h \\times w ) ( block size : integer value this define the size of the spatial block where the depth elements move to number of channel c in the input tensor must be divisible by math block size \\times block size ) ( name : the name of the function instance in the network )
( x : numpy array or any class cntk ops function function that output a tensor ) ( steepness : the name of the function instance in the network )
( output vector : the unscaled compute output value from the network ) ( target vector : usually it be one hot vector where the hot bite correspond to the label index but it can be any probability distribution over the label ) ( axis : class cntk axis axis optional if give cross entropy will be compute along this axis ) ( name : the name of the function instance in the network )
( x : numpy array or any class cntk ops function function that output a tensor ) ( name : the name of the function instance in the network )
( input : class cntk ops function function that output a tensor ) ( name : the name of the function instance in the network )
( filter shape : shape spatial extent of the receptive field not include the input feature map depth e g 3 3 for a 2d convolution ) ( stride : stride increment when slide over the input use a tuple to specify a per axis value ) ( pad : if false then the pool operation will be shift over the "valid" area of input that be no value outside the area be use if pad true on the other hand pool will be apply to all input position and position outside the valid region will be consider contain zero use a tuple to specify a per axis value ) ( name : the name of the function instance in the network )
( output : the compute posterior probability for a variable to be 1 from the network typ a sigmoid ) ( target : grind truth label 0 or 1 ) ( name : the name of the function instance in the network )
( x : numpy array or any class cntk ops function function that output a tensor ) ( name : the name of the function instance in the network )
( x : tensor to be pad ) ( pattern : how many value to add before and after the content of the tensor in each dimension ) ( mode : pad mode c ops constant pad c ops reflect pad and c ops symmetric pad ) ( constant value : the value use to fill the pad cells only meaningful under constant mode ) ( name : the name of the function instance in the network )
( filter shape : shape spatial extent of the receptive field not include the input feature map depth e g 3 3 for a 2d convolution ) ( stride : stride increment when slide over the input use a tuple to specify a per axis value ) ( pad : if false then the pool operation will be shift over the "valid" area of input that be no value outside the area be use if pad true on the other hand pool will be apply to all input position and position outside the valid region will be consider contain zero use a tuple to specify a per axis value ) ( name : the name of the function instance in the network )
( parameters : list of network parameters to tune these can be obtain by the root operator's parameters ) ( lr : func learn parameter schedule a learn rate in float or a learn rate schedule see also func learn parameter schedule ) ( rho : exponential smooth factor for each minibatch ) ( epsilon : epsilon for sqrt ) ( l1 regularization weight : the l1 regularization weight per sample default to 0 0 ) ( l2 regularization weight : the l2 regularization weight per sample default to 0 0 ) ( gaussian noise injection std dev : the standard deviation of the gaussian noise add to parameters post update default to 0 0 ) ( gradient clip threshold per sample : clip threshold per sample default to infinity ) ( gradient clip with truncation : use gradient clip with truncation ) ( use mean gradient : use average gradient as input to learner deprecate 2 2 use minibatch size parameter to specify the reference minibatch size ) ( minibatch size : the minibatch size that the learner's parameters be design or pre tune for this size be usually set to the same as the minibatch data source's size cntk will perform automatic scale of the parameters to enable efficient model parameter update implementation while approximate the behavior of pre design and pre tune parameters in case that minibatch size be not specify cntk will inherit the minibatch size from the learn rate schedule if the learn rate schedule do not specify the minibatch size cntk will set it to attr ignore set minibatch size to attr ignore will have the learner apply as it be prevent cntk perform any hyper parameter scale see also func learn parameter schedule ) ( epoch size : number of sample as a schedule unit for learn rate see also func learn parameter schedule )
( initial scale : initial value for the scale parameter ) ( initial bias : initial value for the bias parameter ) ( epsilon : epsilon add to the standard deviation to avoid division by 0 ) ( name : the name of the function instance in the network )
( alpha : class cntk variables parameter same shape as x ) ( x : class cntk ops function function any class cntk ops function function that output a tensor ) ( name : the name of the function instance in the network )
( x : class cntk ops function function any class cntk ops function function that output a tensor ) ( scale : the name of the function instance in the network )
( shape : vector or tensor dimension of the output of this layer ) ( cell shape : if give then the output state be first compute at cell shape and linearly project to shape ) ( activation : class cntk ops function function default to func cntk ops tanh function to apply at the end e g relu ) ( init : mod cntk initializer default to 0 initial value of weight b ) ( init bias : mod cntk initializer default to 0 initial value of weight b ) ( enable self stabilization : if true then add a func cntk layer block stabilizer to all state relate projections but not the data input ) ( name : the name of the function instance in the network )
( filter shape : shape spatial extent of the receptive field not include the input feature map depth e g 3 3 for a 2d convolution ) ( stride : stride increment when slide over the input use a tuple to specify a per axis value ) ( pad : if false then the pool operation will be shift over the "valid" area of input that be no value outside the area be use if pad true on the other hand pool will be apply to all input position and position outside the valid region will be consider contain zero use a tuple to specify a per axis value ) ( name : the name of the function instance in the network )
( x : numpy array or any class cntk ops function function that output a tensor ) ( name : the name of the function instance in the network )
( filter shape : shape spatial extent of the receptive field not include the input feature map depth e g 3 3 for a 2d convolution ) ( num filter : number of filter output feature map depth or to denote scalar output items output shape will have no depth axis ) ( activation : class cntk ops function function default to identity optional function to apply at the end e g relu ) ( init : mod cntk initializer default to 0 initial value of weight b ) ( pad : if false then the filter will be shift over the "valid" area of input that be no value outside the area be use if pad true on the other hand the filter will be apply to all input position and position outside the valid region will be consider contain zero use a tuple to specify a per axis value ) ( stride : stride of the convolution increment when slide the filter over the input use a tuple to specify a per axis value ) ( bias : the layer will have no bias if false be pass here ) ( init bias : mod cntk initializer default to 0 initial value of weight b ) ( reduction rank : set to 0 if input items be scalars input have no depth axis e g an audio signal or a black and white image that be store with tensor shape h w instead of 1 h w ) ( dilation : the dilation value along each axis default 1 mean no dilation ) ( group : number of group during convolution that control the connections between input and output channel deafult value be 1 which mean that all input channel be convolve to produce all output channel a value of n would mean that the input and output channel be divide into n group with the input channel in one group say i th input group contribute to output channel in only one group i th output group number of input and output channel must be divisble by value of group argument also value of this argument must be strictly positive i e group 0 ) ( name : the name of the function instance in the network )
( x : input tensor ) ( axis : default to 0 indicate up to which input dimension exclusive should be flatten to the outer dimension of the output ) ( name : the name of the function instance in the network )
( operand : input of the batch normalization operation ) ( scale : parameter tensor that hold the learn componentwise scale factor ) ( bias : parameter tensor that hold the learn bias scale and bias must have the same dimension which must be equal to the input dimension in case of spatial false or number of output convolution feature map in case of spatial true ) ( run mean : run mean which be use during evaluation phase and might be use during train as well you must pass a constant tensor with initial value 0 and the same dimension as scale and bias ) ( run inv std : run variance represent as run mean ) ( spatial : flag that indicate whether to compute mean/var for each feature in a minibatch independently or in case of convolutional layer per future map ) ( normalization time constant : time constant for compute run average of mean and variance as a low pass filter version of the batch statistics ) ( blend time constant : constant for smooth batch estimate with the run statistics ) ( epsilon : conditioner constant add to the variance when compute the inverse standard deviation ) ( use cudnn engine : ) ( disable regularization : turn off regularization in batch normalization ) ( name : the name of the function instance in the network ) ( run count : denote the total number of sample that have be use so far to compute the run mean and run inv std parameters you must pass a scalar either rank 0 constant val )
( self : filename to store the checkpoint ) ( external state : additional external state default be empty )
( x : numpy array or any class cntk ops function function that output a tensor ) ( axis : class cntk axis axis axis along which the softmax operation will be perform ) ( name : the name of the function instance in the network )
( filter shape : shape spatial extent of the receptive field not include the input feature map depth e g 3 3 for a 2d convolution ) ( stride : stride increment when slide over the input use a tuple to specify a per axis value ) ( pad : if false then the pool operation will be shift over the "valid" area of input that be no value outside the area be use if pad true on the other hand pool will be apply to all input position and position outside the valid region will be consider contain zero use a tuple to specify a per axis value ) ( name : the name of the function instance in the network )
( output vector : the unscaled compute output value from the network ) ( target vector : usually it be one hot vector where the hot bite correspond to the label index but it can be any probability distribution over the label ) ( axis : class cntk axis axis optional if give cross entropy will be compute along this axis ) ( name : the name of the function instance in the network )
( scale : scale ) ( output rank : output rank ) ( filter rank : filter rank ) ( seed : random seed )
( x : class cntk ops function function any class cntk ops function function that output a tensor ) ( alpha : the name of the function instance in the network )
( filter_shape : shape  ( spatial extent )  of the receptive field, not including the input feature-map depth. E.g.  ( 3,3 )  for a 2D convolution )  ( num_filters : number of filters  ( output feature-map depth ) , or  (  )  to denote scalar output items  ( output shape will have no depth axis ) . )  ( activation : optional function to apply at the end, e.g. relu )  ( init : initial value of weights W )  ( pad : if False, then the filter will be shifted over the 'valid' area of input, that is, no value outside the area is used. If pad=True on the other hand, the filter will be applied to all input positions, and positions outside the valid region will be considered containing zero. Use a tuple to specify a per-axis value )  ( strides : stride of the convolution  ( increment when sliding the filter over the input ) . Use a tuple to specify a per-axis value )  ( bias : the layer will have no bias if False is passed here )  ( init_bias : initial value of weights b )  ( output_shape : output shape. When strides > 2, the output shape is non-deterministic. User can specify the wanted output shape. Note the specified shape must satisify the condition that if a convolution is perform from the output with the same setting, the result must have same shape as the input. that is stored with tensor shape  ( H,W )  instead of  ( 1,H,W )  )  ( reduction_rank : set to 0 if input items are scalars  ( input has no depth axis ) , e.g. an audio signal or a black-and-white image )  ( dilation : the dilation value along each axis, default 1 mean no dilation )  ( name : the name of the Function instance in the network )
( shape : vector or tensor dimension of the output of this layer ) ( activation : class cntk ops function function default to identity optional function to apply at the end e g relu ) ( init : mod cntk initializer default to 0 initial value of weight b ) ( input rank : number of infer ax to add to w map rank must not be give ) ( map rank : expand w to leave exactly map rank ax input rank must not be give ) ( bias : the layer will have no bias if false be pass here ) ( init bias : mod cntk initializer default to 0 initial value of weight b ) ( name : the name of the function instance in the network )
( scale : scale ) ( seed : random seed )
( x : class cntk ops function function any class cntk ops function function that output a tensor ) ( alpha : the name of the function instance in the network )
( filter shape : shape spatial extent of the receptive field not include the input feature map depth e g 3 3 for a 2d convolution ) ( stride : stride increment when slide over the input use a tuple to specify a per axis value ) ( pad : if false then the pool operation will be shift over the "valid" area of input that be no value outside the area be use if pad true on the other hand pool will be apply to all input position and position outside the valid region will be consider contain zero use a tuple to specify a per axis value ) ( name : the name of the function instance in the network )
( x : input tensor ) ( dropout rate : probability of drop out an element mutually exclusive with keep prob ) ( seed : random seed ) ( name : class str optional the name of the function instance in the network )
