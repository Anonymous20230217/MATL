{"torch.is_tensor": {"Parameters": {"obj (Object)": "Object to test"}, "description": "Returns True if obj is a PyTorch tensor."}, "torch.is_storage": {"Parameters": {"obj (Object)": "Object to test"}, "description": "Returns True if obj is a PyTorch storage object."}, "torch.is_complex": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Returns True if the data type of input is a complex data type i.e., one of torch.complex64, and torch.complex128."}, "torch.is_conj": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Returns True if the input is a conjugated tensor, i.e. its conjugate bit is set to True."}, "torch.is_floating_point": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Returns True if the data type of input is a floating point data type i.e., one of torch.float64, torch.float32, torch.float16, and torch.bfloat16."}, "torch.is_nonzero": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Returns True if the input is a single element tensor which is not equal to zero after type conversions."}, "torch.set_default_dtype": {"Parameters": {"d (torch.dtype)": "the floating point dtype to make the default.\nEither torch.float32 or torch.float64."}, "description": "Sets the default floating point dtype to d."}, "torch.get_default_dtype": {"description": "Get the current default floating point torch.dtype."}, "torch.set_default_tensor_type": {"Parameters": {"t (type or string)": "the floating point tensor type or its name"}, "description": "Sets the default torch.Tensor type to floating point tensor type t."}, "torch.numel": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Returns the total number of elements in the input tensor."}, "torch.set_printoptions": {"Parameters": {"precision": "Number of digits of precision for floating point output\n(default = 4).", "threshold": "Total number of array elements which trigger summarization\nrather than full repr (default = 1000).", "edgeitems": "Number of array items in summary at beginning and end of\neach dimension (default = 3).", "linewidth": "The number of characters per line for the purpose of\ninserting line breaks (default = 80). Thresholded matrices will\nignore this parameter.", "profile": "Sane defaults for pretty printing. Can override with any of\nthe above options. (any one of default, short, full)", "sci_mode": "Enable (True) or disable (False) scientific notation. If\nNone (default) is specified, the value is defined by\ntorch._tensor_str._Formatter. This value is automatically chosen\nby the framework."}, "description": "Set options for printing."}, "torch.set_flush_denormal": {"Parameters": {"mode (bool)": "Controls whether to enable flush denormal mode or not"}, "description": "Disables denormal floating numbers on CPU."}, "torch.tensor": {"Parameters": {"data (array_like)": "Initial data for the tensor. Can be a list, tuple,\nNumPy ndarray, scalar, and other types."}, "description": "Constructs a tensor with no autograd history (also known as a \u201cleaf tensor\u201d, see Autograd mechanics) by copying data."}, "torch.sparse_coo_tensor": {"Parameters": {"indices (array_like)": "Initial data for the tensor. Can be a list, tuple,\nNumPy ndarray, scalar, and other types. Will be cast to a torch.LongTensor\ninternally. The indices are the coordinates of the non-zero values in the matrix, and thus\nshould be two-dimensional where the first dimension is the number of tensor dimensions and\nthe second dimension is the number of non-zero values.", "values (array_like)": "Initial values for the tensor. Can be a list, tuple,\nNumPy ndarray, scalar, and other types.", "size (list, tuple, or torch.Size, optional)": "Size of the sparse tensor. If not\nprovided the size will be inferred as the minimum size big enough to hold all non-zero\nelements."}, "description": "Constructs a sparse tensor in COO(rdinate) format with specified values at the given indices."}, "torch.asarray": {"Parameters": {"obj (object)": "a tensor, NumPy array, DLPack Capsule, object that implements Python\u2019s\nbuffer protocol, scalar, or sequence of scalars."}, "description": "Converts obj to a tensor."}, "torch.as_tensor": {"Parameters": {"data (array_like)": "Initial data for the tensor. Can be a list, tuple,\nNumPy ndarray, scalar, and other types.", "dtype (torch.dtype, optional)": "the desired data type of returned tensor.\nDefault: if None, infers data type from data.", "device (torch.device, optional)": "the device of the constructed tensor. If None and data is a tensor\nthen the device of data is used. If None and data is not a tensor then\nthe result tensor is constructed on the CPU."}, "description": "Converts data into a tensor, sharing data and preserving autograd history if possible."}, "torch.as_strided": {"Parameters": {"input (Tensor)": "the input tensor.", "size (tuple or ints)": "the shape of the output tensor", "stride (tuple or ints)": "the stride of the output tensor", "storage_offset (int, optional)": "the offset in the underlying storage of the output tensor"}, "description": "Create a view of an existing torch.Tensor input with specified size, stride and storage_offset."}, "torch.from_numpy": {"description": "Creates a Tensor from a numpy.ndarray."}, "torch.frombuffer": {"Parameters": {"buffer (object)": "a Python object that exposes the buffer interface."}, "description": "Creates a 1-dimensional Tensor from an object that implements the Python buffer protocol."}, "torch.zeros": {"Parameters": {"size (int...)": "a sequence of integers defining the shape of the output tensor.\nCan be a variable number of arguments or a collection like a list or tuple."}, "description": "Returns a tensor filled with the scalar value 0, with the shape defined by the variable argument size."}, "torch.zeros_like": {"Parameters": {"input (Tensor)": "the size of input will determine size of the output tensor."}, "description": "Returns a tensor filled with the scalar value 0, with the same size as input."}, "torch.ones": {"Parameters": {"size (int...)": "a sequence of integers defining the shape of the output tensor.\nCan be a variable number of arguments or a collection like a list or tuple."}, "description": "Returns a tensor filled with the scalar value 1, with the shape defined by the variable argument size."}, "torch.ones_like": {"Parameters": {"input (Tensor)": "the size of input will determine size of the output tensor."}, "description": "Returns a tensor filled with the scalar value 1, with the same size as input."}, "torch.arange": {"Parameters": {"start (Number)": "the starting value for the set of points. Default: 0.", "end (Number)": "the ending value for the set of points", "step (Number)": "the gap between each pair of adjacent points. Default: 1."}, "description": "Returns a 1-D tensor of size \u2308end\u2212startstep\u2309\\left\\lceil \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rceil\u2308stepend\u2212start\u200b\u2309 with values from the interval [start, end) taken with common difference step beginning from start."}, "torch.range": {"Parameters": {"start (float)": "the starting value for the set of points. Default: 0.", "end (float)": "the ending value for the set of points", "step (float)": "the gap between each pair of adjacent points. Default: 1."}, "description": "Returns a 1-D tensor of size \u230aend\u2212startstep\u230b+1\\left\\lfloor \\frac{\\text{end} - \\text{start}}{\\text{step}} \\right\\rfloor + 1\u230astepend\u2212start\u200b\u230b+1 with values from start to end with step step."}, "torch.linspace": {"Parameters": {"start (float)": "the starting value for the set of points", "end (float)": "the ending value for the set of points", "steps (int)": "size of the constructed tensor"}, "description": "Creates a one-dimensional tensor of size steps whose values are evenly spaced from start to end, inclusive."}, "torch.logspace": {"Parameters": {"start (float)": "the starting value for the set of points", "end (float)": "the ending value for the set of points", "steps (int)": "size of the constructed tensor", "base (float, optional)": "base of the logarithm function. Default: 10.0."}, "description": "Creates a one-dimensional tensor of size steps whose values are evenly spaced from basestart{{\\text{{base}}}}^{{\\text{{start}}}}basestart to baseend{{\\text{{base}}}}^{{\\text{{end}}}}baseend, inclusive, on a logarithmic scale with base base."}, "torch.eye": {"Parameters": {"n (int)": "the number of rows", "m (int, optional)": "the number of columns with default being n"}, "Returns": "A 2-D tensor with ones on the diagonal and zeros elsewhere\n", "description": "Returns a 2-D tensor with ones on the diagonal and zeros elsewhere."}, "torch.empty": {"Parameters": {"size (int...)": "a sequence of integers defining the shape of the output tensor.\nCan be a variable number of arguments or a collection like a list or tuple."}, "description": "Returns a tensor filled with uninitialized data."}, "torch.empty_like": {"Parameters": {"input (Tensor)": "the size of input will determine size of the output tensor."}, "description": "Returns an uninitialized tensor with the same size as input."}, "torch.empty_strided": {"Parameters": {"size (tuple of python:ints)": "the shape of the output tensor", "stride (tuple of python:ints)": "the strides of the output tensor"}, "description": "Creates a tensor with the specified size and stride and filled with undefined data."}, "torch.full": {"Parameters": {"size (int...)": "a list, tuple, or torch.Size of integers defining the\nshape of the output tensor.", "fill_value (Scalar)": "the value to fill the output tensor with."}, "description": "Creates a tensor of size size filled with fill_value."}, "torch.full_like": {"Parameters": {"input (Tensor)": "the size of input will determine size of the output tensor.", "fill_value": "the number to fill the output tensor with."}, "description": "Returns a tensor with the same size as input filled with fill_value."}, "torch.quantize_per_tensor": {"Parameters": {"input (Tensor)": "float tensor or list of tensors to quantize", "scale (float or Tensor)": "scale to apply in quantization formula", "zero_point (int or Tensor)": "offset in integer value that maps to float zero", "dtype (torch.dtype)": "the desired data type of returned tensor.\nHas to be one of the quantized dtypes: torch.quint8, torch.qint8, torch.qint32"}, "Returns": "A newly quantized tensor or list of quantized tensors.\n", "description": "Converts a float tensor to a quantized tensor with given scale and zero point."}, "torch.quantize_per_channel": {"Parameters": {"input (Tensor)": "float tensor to quantize", "scales (Tensor)": "float 1D tensor of scales to use, size should match input.size(axis)", "zero_points (int)": "integer 1D tensor of offset to use, size should match input.size(axis)", "axis (int)": "dimension on which apply per-channel quantization", "dtype (torch.dtype)": "the desired data type of returned tensor.\nHas to be one of the quantized dtypes: torch.quint8, torch.qint8, torch.qint32"}, "Returns": "A newly quantized tensor\n", "description": "Converts a float tensor to a per-channel quantized tensor with given scales and zero points."}, "torch.dequantize": {"Parameters": {"tensors (sequence of Tensors)": "A list of quantized Tensors"}, "description": "Returns an fp32 Tensor by dequantizing a quantized Tensor"}, "torch.complex": {"Parameters": {"real (Tensor)": "The real part of the complex tensor. Must be float or double.", "imag (Tensor)": "The imaginary part of the complex tensor. Must be same dtype\nas real."}, "description": "Constructs a complex tensor with its real part equal to real and its imaginary part equal to imag."}, "torch.polar": {"Parameters": {"abs (Tensor)": "The absolute value the complex tensor. Must be float or double.", "angle (Tensor)": "The angle of the complex tensor. Must be same dtype as\nabs."}, "description": "Constructs a complex tensor whose elements are Cartesian coordinates corresponding to the polar coordinates with absolute value abs and angle angle."}, "torch.heaviside": {"Parameters": {"input (Tensor)": "the input tensor.", "values (Tensor)": "The values to use where input is zero."}, "description": "Computes the Heaviside step function for each element in input."}, "torch.adjoint": {"description": "Returns a view of the tensor conjugated and with the last two dimensions transposed."}, "torch.argwhere": {"Parameters": {"{input}": ""}, "description": "Returns a tensor containing the indices of all non-zero elements of input."}, "torch.cat": {"Parameters": {"tensors (sequence of Tensors)": "any python sequence of tensors of the same type.\nNon-empty tensors provided must have the same shape, except in the\ncat dimension.", "dim (int, optional)": "the dimension over which the tensors are concatenated"}, "description": "Concatenates the given sequence of seq tensors in the given dimension."}, "torch.concat": {"description": "Alias of torch.cat()."}, "torch.conj": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Returns a view of input with a flipped conjugate bit."}, "torch.chunk": {"Parameters": {"input (Tensor)": "the tensor to split", "chunks (int)": "number of chunks to return", "dim (int)": "dimension along which to split the tensor"}, "description": "Attempts to split a tensor into the specified number of chunks."}, "torch.dsplit": {"Parameters": {"input (Tensor)": "tensor to split.", "indices_or_sections (Tensor, int or list or tuple of python:ints)": "See argument in torch.tensor_split()."}, "description": "Splits input, a tensor with three or more dimensions, into multiple tensors depthwise according to indices_or_sections."}, "torch.column_stack": {"Parameters": {"tensors (sequence of Tensors)": "sequence of tensors to concatenate"}, "description": "Creates a new tensor by horizontally stacking the tensors in tensors."}, "torch.dstack": {"Parameters": {"tensors (sequence of Tensors)": "sequence of tensors to concatenate"}, "description": "Stack tensors in sequence depthwise (along third axis)."}, "torch.gather": {"Parameters": {"input (Tensor)": "the source tensor", "dim (int)": "the axis along which to index", "index (LongTensor)": "the indices of elements to gather"}, "description": "Gathers values along an axis specified by dim."}, "torch.hsplit": {"Parameters": {"input (Tensor)": "tensor to split.", "indices_or_sections (Tensor, int or list or tuple of python:ints)": "See argument in torch.tensor_split()."}, "description": "Splits input, a tensor with one or more dimensions, into multiple tensors horizontally according to indices_or_sections."}, "torch.hstack": {"Parameters": {"tensors (sequence of Tensors)": "sequence of tensors to concatenate"}, "description": "Stack tensors in sequence horizontally (column wise)."}, "torch.index_add": {"description": "See index_add_() for function description."}, "torch.index_select": {"Parameters": {"input (Tensor)": "the input tensor.", "dim (int)": "the dimension in which we index", "index (IntTensor or LongTensor)": "the 1-D tensor containing the indices to index"}, "description": "Returns a new tensor which indexes the input tensor along dimension dim using the entries in index which is a LongTensor."}, "torch.masked_select": {"Parameters": {"input (Tensor)": "the input tensor.", "mask (BoolTensor)": "the tensor containing the binary mask to index with"}, "description": "Returns a new 1-D tensor which indexes the input tensor according to the boolean mask mask which is a BoolTensor."}, "torch.movedim": {"Parameters": {"input (Tensor)": "the input tensor.", "source (int or tuple of python:ints)": "Original positions of the dims to move. These must be unique.", "destination (int or tuple of python:ints)": "Destination positions for each of the original dims. These must also be unique."}, "description": "Moves the dimension(s) of input at the position(s) in source to the position(s) in destination."}, "torch.moveaxis": {"description": "Alias for torch.movedim()."}, "torch.narrow": {"Parameters": {"input (Tensor)": "the tensor to narrow", "dim (int)": "the dimension along which to narrow", "start (int)": "the starting dimension", "length (int)": "the distance to the ending dimension"}, "description": "Returns a new tensor that is a narrowed version of input tensor."}, "torch.nonzero": {"Parameters": {"input (Tensor)": "the input tensor."}, "Returns": "If as_tuple is False, the output\ntensor containing indices. If as_tuple is True, one 1-D tensor for\neach dimension, containing the indices of each nonzero element along that\ndimension.\n", "description": ""}, "torch.permute": {"Parameters": {"input (Tensor)": "the input tensor.", "dims (tuple of python:ints)": "The desired ordering of dimensions"}, "description": "Returns a view of the original tensor input with its dimensions permuted."}, "torch.reshape": {"Parameters": {"input (Tensor)": "the tensor to be reshaped", "shape (tuple of python:ints)": "the new shape"}, "description": "Returns a tensor with the same data and number of elements as input, but with the specified shape."}, "torch.row_stack": {"description": "Alias of torch.vstack()."}, "torch.select": {"Parameters": {"input (Tensor)": "the input tensor.", "dim (int)": "the dimension to slice", "index (int)": "the index to select with"}, "description": "Slices the input tensor along the selected dimension at the given index."}, "torch.scatter": {"description": "Out-of-place version of torch.Tensor.scatter_()"}, "torch.diagonal_scatter": {"Parameters": {"input (Tensor)": "the input tensor. Must be at least 2-dimensional.", "src (Tensor)": "the tensor to embed into input.", "offset (int, optional)": "which diagonal to consider. Default: 0\n(main diagonal).", "dim1 (int, optional)": "first dimension with respect to which to\ntake diagonal. Default: 0.", "dim2 (int, optional)": "second dimension with respect to which to\ntake diagonal. Default: 1."}, "description": "Embeds the values of the src tensor into input along the diagonal elements of input, with respect to dim1 and dim2."}, "torch.select_scatter": {"Parameters": {"input (Tensor)": "the input tensor.", "src (Tensor)": "The tensor to embed into input", "dim (int)": "the dimension to insert the slice into.", "index (int)": "the index to select with"}, "description": "Embeds the values of the src tensor into input at the given index."}, "torch.slice_scatter": {"Parameters": {"input (Tensor)": "the input tensor.", "src (Tensor)": "The tensor to embed into input", "dim (int)": "the dimension to insert the slice into", "start (Optional[int])": "the start index of where to insert the slice", "end (Optional[int])": "the end index of where to insert the slice", "step (int)": "the how many elements to skip in"}, "description": "Embeds the values of the src tensor into input at the given dimension."}, "torch.scatter_add": {"description": "Out-of-place version of torch.Tensor.scatter_add_()"}, "torch.scatter_reduce": {"Parameters": {"input (Tensor)": "the input tensor", "dim (int)": "the axis along which to index", "index (LongTensor)": "the indices of elements to scatter and reduce.", "src (Tensor)": "the source elements to scatter and reduce", "reduce (str)": "the reduction operation to apply for non-unique indices\n(\"sum\", \"prod\", \"mean\", \"amax\", \"amin\")", "output_size (int, optional)": "the size of the output at dimension dim.\nIf set to None, will get automatically inferred according to\nindex.max() + 1"}, "description": "Reduces all values from the input tensor to the indices specified in the index tensor."}, "torch.split": {"Parameters": {"tensor (Tensor)": "tensor to split.", "split_size_or_sections (int) or (list(int))": "size of a single chunk or\nlist of sizes for each chunk", "dim (int)": "dimension along which to split the tensor."}, "description": "Splits the tensor into chunks."}, "torch.squeeze": {"Parameters": {"input (Tensor)": "the input tensor.", "dim (int, optional)": "if given, the input will be squeezed only in\nthis dimension"}, "description": "Returns a tensor with all the dimensions of input of size 1 removed."}, "torch.stack": {"Parameters": {"tensors (sequence of Tensors)": "sequence of tensors to concatenate", "dim (int)": "dimension to insert. Has to be between 0 and the number\nof dimensions of concatenated tensors (inclusive)"}, "description": "Concatenates a sequence of tensors along a new dimension."}, "torch.swapaxes": {"description": "Alias for torch.transpose()."}, "torch.swapdims": {"description": "Alias for torch.transpose()."}, "torch.t": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Expects input to be <= 2-D tensor and transposes dimensions 0 and 1."}, "torch.take": {"Parameters": {"input (Tensor)": "the input tensor.", "index (LongTensor)": "the indices into tensor"}, "description": "Returns a new tensor with the elements of input at the given indices."}, "torch.take_along_dim": {"Parameters": {"input (Tensor)": "the input tensor.", "indices (tensor)": "the indices into input. Must have long dtype.", "dim (int)": "dimension to select along."}, "description": "Selects values from input at the 1-dimensional indices from indices along the given dim."}, "torch.tensor_split": {"Parameters": {"input (Tensor)": "the tensor to split", "indices_or_sections (Tensor, int or list or tuple of python:ints)": "If indices_or_sections is an integer n or a zero dimensional long tensor\nwith value n, input is split into n sections along dimension dim.\nIf input is divisible by n along dimension dim, each\nsection will be of equal size, input.size(dim) / n. If input\nis not divisible by n, the sizes of the first int(input.size(dim) % n)\nsections will have size int(input.size(dim) / n) + 1, and the rest will\nhave size int(input.size(dim) / n).\nIf indices_or_sections is a list or tuple of ints, or a one-dimensional long\ntensor, then input is split along dimension dim at each of the indices\nin the list, tuple or tensor. For instance, indices_or_sections=[2, 3] and dim=0\nwould result in the tensors input[:2], input[2:3], and input[3:].\nIf indices_or_sections is a tensor, it must be a zero-dimensional or one-dimensional\nlong tensor on the CPU.", "dim (int, optional)": "dimension along which to split the tensor. Default: 0"}, "description": "Splits a tensor into multiple sub-tensors, all of which are views of input, along dimension dim according to the indices or number of sections specified by indices_or_sections."}, "torch.tile": {"Parameters": {"input (Tensor)": "the tensor whose elements to repeat.", "dims (tuple)": "the number of repetitions per dimension."}, "description": "Constructs a tensor by repeating the elements of input."}, "torch.transpose": {"Parameters": {"input (Tensor)": "the input tensor.", "dim0 (int)": "the first dimension to be transposed", "dim1 (int)": "the second dimension to be transposed"}, "description": "Returns a tensor that is a transposed version of input."}, "torch.unbind": {"Parameters": {"input (Tensor)": "the tensor to unbind", "dim (int)": "dimension to remove"}, "description": "Removes a tensor dimension."}, "torch.unsqueeze": {"Parameters": {"input (Tensor)": "the input tensor.", "dim (int)": "the index at which to insert the singleton dimension"}, "description": "Returns a new tensor with a dimension of size one inserted at the specified position."}, "torch.vsplit": {"Parameters": {"input (Tensor)": "tensor to split.", "indices_or_sections (Tensor, int or list or tuple of python:ints)": "See argument in torch.tensor_split()."}, "description": "Splits input, a tensor with two or more dimensions, into multiple tensors vertically according to indices_or_sections."}, "torch.vstack": {"Parameters": {"tensors (sequence of Tensors)": "sequence of tensors to concatenate"}, "description": "Stack tensors in sequence vertically (row wise)."}, "torch.where": {"Parameters": {"condition (BoolTensor)": "When True (nonzero), yield x, otherwise yield y", "x (Tensor or Scalar)": "value (if x is a scalar) or values selected at indices\nwhere condition is True", "y (Tensor or Scalar)": "value (if y is a scalar) or values selected at indices\nwhere condition is False"}, "Returns": "A tensor of shape equal to the broadcasted shape of condition, x, y\n", "description": "Return a tensor of elements selected from either x or y, depending on condition."}, "torch.Generator": {"Parameters": {"device (torch.device, optional)": "the desired device for the generator."}, "Returns": "An torch.Generator object.\n", "method": {"torch.Generator.get_state": {"Returns": "A torch.ByteTensor which contains all the necessary bits\nto restore a Generator to a specific point in time.\n", "description": null}, "torch.Generator.manual_seed": {"Parameters": {"seed (int)": "The desired seed. Value must be within the inclusive range\n[-0x8000_0000_0000_0000, 0xffff_ffff_ffff_ffff]. Otherwise, a RuntimeError\nis raised. Negative inputs are remapped to positive values with the formula\n0xffff_ffff_ffff_ffff + seed."}, "Returns": "An torch.Generator object.\n", "description": null}, "torch.Generator.set_state": {"Parameters": {"new_state (torch.ByteTensor)": "The desired state."}, "description": "Sets the Generator state."}}, "description": "Creates and returns a generator object that manages the state of the algorithm which produces pseudo random numbers."}, "torch.seed": {"description": "Sets the seed for generating random numbers to a non-deterministic random number."}, "torch.manual_seed": {"Parameters": {"seed (int)": "The desired seed. Value must be within the inclusive range\n[-0x8000_0000_0000_0000, 0xffff_ffff_ffff_ffff]. Otherwise, a RuntimeError\nis raised. Negative inputs are remapped to positive values with the formula\n0xffff_ffff_ffff_ffff + seed."}, "description": "Sets the seed for generating random numbers."}, "torch.initial_seed": {"description": "Returns the initial seed for generating random numbers as a Python long."}, "torch.get_rng_state": {"description": "Returns the random number generator state as a torch.ByteTensor."}, "torch.set_rng_state": {"Parameters": {"new_state (torch.ByteTensor)": "The desired state"}, "description": "Sets the random number generator state."}, "torch.bernoulli": {"Parameters": {"input (Tensor)": "the input tensor of probability values for the Bernoulli distribution"}, "description": "Draws binary random numbers (0 or 1) from a Bernoulli distribution."}, "torch.multinomial": {"Parameters": {"input (Tensor)": "the input tensor containing probabilities", "num_samples (int)": "number of samples to draw", "replacement (bool, optional)": "whether to draw with replacement or not"}, "description": "Returns a tensor where each row contains num_samples indices sampled from the multinomial probability distribution located in the corresponding row of tensor input."}, "torch.normal": {"Parameters": {"mean (float)": "the mean for all distributions", "std (float)": "the standard deviation for all distributions", "size (int...)": "a sequence of integers defining the shape of the output tensor."}, "description": "Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given."}, "torch.poisson": {"Parameters": {"input (Tensor)": "the input tensor containing the rates of the Poisson distribution"}, "description": "Returns a tensor of the same size as input with each element sampled from a Poisson distribution with rate parameter given by the corresponding element in input i.e.,"}, "torch.rand": {"Parameters": {"size (int...)": "a sequence of integers defining the shape of the output tensor.\nCan be a variable number of arguments or a collection like a list or tuple."}, "description": "Returns a tensor filled with random numbers from a uniform distribution on the interval [0,1)[0, 1)[0,1)"}, "torch.rand_like": {"Parameters": {"input (Tensor)": "the size of input will determine size of the output tensor."}, "description": "Returns a tensor with the same size as input that is filled with random numbers from a uniform distribution on the interval [0,1)[0, 1)[0,1)."}, "torch.randint": {"Parameters": {"low (int, optional)": "Lowest integer to be drawn from the distribution. Default: 0.", "high (int)": "One above the highest integer to be drawn from the distribution.", "size (tuple)": "a tuple defining the shape of the output tensor."}, "description": "Returns a tensor filled with random integers generated uniformly between low (inclusive) and high (exclusive)."}, "torch.randint_like": {"Parameters": {"input (Tensor)": "the size of input will determine size of the output tensor.", "low (int, optional)": "Lowest integer to be drawn from the distribution. Default: 0.", "high (int)": "One above the highest integer to be drawn from the distribution."}, "description": "Returns a tensor with the same shape as Tensor input filled with random integers generated uniformly between low (inclusive) and high (exclusive)."}, "torch.randn": {"Parameters": {"size (int...)": "a sequence of integers defining the shape of the output tensor.\nCan be a variable number of arguments or a collection like a list or tuple."}, "description": "Returns a tensor filled with random numbers from a normal distribution with mean 0 and variance 1 (also called the standard normal distribution)."}, "torch.randn_like": {"Parameters": {"input (Tensor)": "the size of input will determine size of the output tensor."}, "description": "Returns a tensor with the same size as input that is filled with random numbers from a normal distribution with mean 0 and variance 1."}, "torch.randperm": {"Parameters": {"n (int)": "the upper bound (exclusive)"}, "description": "Returns a random permutation of integers from 0 to n - 1."}, "torch.quasirandom.SobolEngine": {"Parameters": {"dimension (Int)": "The dimensionality of the sequence to be drawn", "scramble (bool, optional)": "Setting this to True will produce\nscrambled Sobol sequences. Scrambling is\ncapable of producing better Sobol\nsequences. Default: False.", "seed (Int, optional)": "This is the seed for the scrambling. The seed\nof the random number generator is set to this,\nif specified. Otherwise, it uses a random seed.\nDefault: None"}, "method": {"torch.quasirandom.SobolEngine.draw": {"Parameters": {"n (Int, optional)": "The length of sequence of points to draw.\nDefault: 1", "out (Tensor, optional)": "The output tensor", "dtype (torch.dtype, optional)": "the desired data type of the\nreturned tensor.\nDefault: torch.float32"}, "description": null}, "torch.quasirandom.SobolEngine.draw_base2": {"Parameters": {"m (Int)": "The (base2) exponent of the number of points to draw.", "out (Tensor, optional)": "The output tensor", "dtype (torch.dtype, optional)": "the desired data type of the\nreturned tensor.\nDefault: torch.float32"}, "description": null}, "torch.quasirandom.SobolEngine.fast_forward": {"Parameters": {"n (Int)": "The number of steps to fast-forward by."}, "description": null}}, "description": "The torch.quasirandom.SobolEngine is an engine for generating (scrambled) Sobol sequences."}, "torch.save": {"Parameters": {"obj": "saved object", "f": "a file-like object (has to implement write and flush) or a string or\nos.PathLike object containing a file name", "pickle_module": "module used for pickling metadata and objects", "pickle_protocol": "can be specified to override the default protocol"}, "description": "Saves an object to a disk file."}, "torch.load": {"Parameters": {"f": "a file-like object (has to implement read(), readline(), tell(), and seek()),\nor a string or os.PathLike object containing a file name", "map_location": "a function, torch.device, string or a dict specifying how to remap storage\nlocations", "pickle_module": "module used for unpickling metadata and objects (has to\nmatch the pickle_module used to serialize file)", "pickle_load_args": "(Python 3 only) optional keyword arguments passed over to\npickle_module.load() and pickle_module.Unpickler(), e.g.,\nerrors=...."}, "description": "Loads an object saved with torch.save() from a file."}, "torch.get_num_threads": {"description": "Returns the number of threads used for parallelizing CPU operations"}, "torch.set_num_threads": {"description": "Sets the number of threads used for intraop parallelism on CPU."}, "torch.get_num_interop_threads": {"description": "Returns the number of threads used for inter-op parallelism on CPU (e.g."}, "torch.set_num_interop_threads": {"description": "Sets the number of threads used for interop parallelism (e.g."}, "torch.no_grad": {"description": "Context-manager that disabled gradient calculation."}, "torch.enable_grad": {"description": "Context-manager that enables gradient calculation."}, "torch.set_grad_enabled": {"Parameters": {"mode (bool)": "Flag whether to enable grad (True), or disable\n(False). This can be used to conditionally enable\ngradients."}, "description": "Context-manager that sets gradient calculation to on or off."}, "torch.is_grad_enabled": {"description": "Returns True if grad mode is currently enabled."}, "torch.inference_mode": {"Parameters": {"mode (bool)": "Flag whether to enable or disable inference mode"}, "description": "Context-manager that enables or disables inference mode"}, "torch.is_inference_mode_enabled": {"description": "Returns True if inference mode is currently enabled."}, "torch.abs": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Computes the absolute value of each element in input."}, "torch.absolute": {"description": "Alias for torch.abs()"}, "torch.acos": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Computes the inverse cosine of each element in input."}, "torch.arccos": {"description": "Alias for torch.acos()."}, "torch.acosh": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Returns a new tensor with the inverse hyperbolic cosine of the elements of input."}, "torch.arccosh": {"description": "Alias for torch.acosh()."}, "torch.add": {"Parameters": {"input (Tensor)": "the input tensor.", "other (Tensor or Number)": "the tensor or number to add to input."}, "description": "Adds other, scaled by alpha, to input."}, "torch.addcdiv": {"Parameters": {"input (Tensor)": "the tensor to be added", "tensor1 (Tensor)": "the numerator tensor", "tensor2 (Tensor)": "the denominator tensor"}, "description": "Performs the element-wise division of tensor1 by tensor2, multiply the result by the scalar value and add it to input."}, "torch.addcmul": {"Parameters": {"input (Tensor)": "the tensor to be added", "tensor1 (Tensor)": "the tensor to be multiplied", "tensor2 (Tensor)": "the tensor to be multiplied"}, "description": "Performs the element-wise multiplication of tensor1 by tensor2, multiply the result by the scalar value and add it to input."}, "torch.angle": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Computes the element-wise angle (in radians) of the given input tensor."}, "torch.asin": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Returns a new tensor with the arcsine  of the elements of input."}, "torch.arcsin": {"description": "Alias for torch.asin()."}, "torch.asinh": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Returns a new tensor with the inverse hyperbolic sine of the elements of input."}, "torch.arcsinh": {"description": "Alias for torch.asinh()."}, "torch.atan": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Returns a new tensor with the arctangent  of the elements of input."}, "torch.arctan": {"description": "Alias for torch.atan()."}, "torch.atanh": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Returns a new tensor with the inverse hyperbolic tangent of the elements of input."}, "torch.arctanh": {"description": "Alias for torch.atanh()."}, "torch.atan2": {"Parameters": {"input (Tensor)": "the first input tensor", "other (Tensor)": "the second input tensor"}, "description": "Element-wise arctangent of inputi/otheri\\text{input}_{i} / \\text{other}_{i}inputi\u200b/otheri\u200b with consideration of the quadrant."}, "torch.arctan2": {"description": "Alias for torch.atan2()."}, "torch.bitwise_not": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Computes the bitwise NOT of the given input tensor."}, "torch.bitwise_and": {"Parameters": {"input": "the first input tensor", "other": "the second input tensor"}, "description": "Computes the bitwise AND of input and other."}, "torch.bitwise_or": {"Parameters": {"input": "the first input tensor", "other": "the second input tensor"}, "description": "Computes the bitwise OR of input and other."}, "torch.bitwise_xor": {"Parameters": {"input": "the first input tensor", "other": "the second input tensor"}, "description": "Computes the bitwise XOR of input and other."}, "torch.bitwise_left_shift": {"Parameters": {"input (Tensor or Scalar)": "the first input tensor", "other (Tensor or Scalar)": "the second input tensor"}, "description": "Computes the left arithmetic shift of input by other bits."}, "torch.bitwise_right_shift": {"Parameters": {"input (Tensor or Scalar)": "the first input tensor", "other (Tensor or Scalar)": "the second input tensor"}, "description": "Computes the right arithmetic shift of input by other bits."}, "torch.ceil": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Returns a new tensor with the ceil of the elements of input, the smallest integer greater than or equal to each element."}, "torch.clamp": {"Parameters": {"input (Tensor)": "the input tensor.", "min (Number or Tensor, optional)": "lower-bound of the range to be clamped to", "max (Number or Tensor, optional)": "upper-bound of the range to be clamped to"}, "description": "Clamps all elements in input into the range [ min, max ]."}, "torch.clip": {"description": "Alias for torch.clamp()."}, "torch.conj_physical": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Computes the element-wise conjugate of the given input tensor."}, "torch.copysign": {"Parameters": {"input (Tensor)": "magnitudes.", "other (Tensor or Number)": "contains value(s) whose signbit(s) are\napplied to the magnitudes in input."}, "description": "Create a new floating-point tensor with the magnitude of input and the sign of other, elementwise."}, "torch.cos": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Returns a new tensor with the cosine  of the elements of input."}, "torch.cosh": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Returns a new tensor with the hyperbolic cosine  of the elements of input."}, "torch.deg2rad": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Returns a new tensor with each of the elements of input converted from angles in degrees to radians."}, "torch.div": {"Parameters": {"input (Tensor)": "the dividend", "other (Tensor or Number)": "the divisor"}, "description": "Divides each element of the input input by the corresponding element of other."}, "torch.divide": {"description": "Alias for torch.div()."}, "torch.digamma": {"description": "Alias for torch.special.digamma()."}, "torch.erf": {"description": "Alias for torch.special.erf()."}, "torch.erfc": {"description": "Alias for torch.special.erfc()."}, "torch.erfinv": {"description": "Alias for torch.special.erfinv()."}, "torch.exp": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Returns a new tensor with the exponential of the elements of the input tensor input."}, "torch.exp2": {"description": "Alias for torch.special.exp2()."}, "torch.expm1": {"description": "Alias for torch.special.expm1()."}, "torch.fake_quantize_per_channel_affine": {"Parameters": {"input (Tensor)": "the input value(s), in torch.float32.", "scale (Tensor)": "quantization scale, per channel", "zero_point (Tensor)": "quantization zero_point, per channel", "axis (int32)": "channel axis", "quant_min (int64)": "lower bound of the quantized domain", "quant_max (int64)": "upper bound of the quantized domain"}, "Returns": "A newly fake_quantized per channel tensor\n", "description": "Returns a new tensor with the data in input fake quantized per channel using scale, zero_point, quant_min and quant_max, across the channel specified by axis."}, "torch.fake_quantize_per_tensor_affine": {"Parameters": {"input (Tensor)": "the input value(s), in torch.float32.", "scale (double or Tensor)": "quantization scale", "zero_point (int64 or Tensor)": "quantization zero_point", "quant_min (int64)": "lower bound of the quantized domain", "quant_max (int64)": "upper bound of the quantized domain"}, "Returns": "A newly fake_quantized tensor\n", "description": "Returns a new tensor with the data in input fake quantized using scale, zero_point, quant_min and quant_max."}, "torch.fix": {"description": "Alias for torch.trunc()"}, "torch.float_power": {"Parameters": {"input (Tensor or Number)": "the base value(s)", "exponent (Tensor or Number)": "the exponent value(s)"}, "description": "Raises input to the power of exponent, elementwise, in double precision."}, "torch.floor": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Returns a new tensor with the floor of the elements of input, the largest integer less than or equal to each element."}, "torch.floor_divide": {"Parameters": {"input (Tensor or Number)": "the dividend", "other (Tensor or Number)": "the divisor"}, "description": ""}, "torch.fmod": {"Parameters": {"input (Tensor)": "the dividend", "other (Tensor or Scalar)": "the divisor"}, "description": "Applies C++\u2019s std::fmod entrywise."}, "torch.frac": {"description": "Computes the fractional portion of each element in input."}, "torch.frexp": {"Parameters": {"input (Tensor)": "the input tensor"}, "description": "Decomposes input into mantissa and exponent tensors such that input=mantissa\u00d72exponent\\text{input} = \\text{mantissa} \\times 2^{\\text{exponent}}input=mantissa\u00d72exponent."}, "torch.gradient": {"Parameters": {"input (Tensor)": "the tensor that represents the values of the function"}, "description": "Estimates the gradient of a function g:Rn\u2192Rg : \\mathbb{R}^n \\rightarrow \\mathbb{R}g:Rn\u2192R in one or more dimensions using the second-order accurate central differences method."}, "torch.imag": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Returns a new tensor containing imaginary values of the self tensor."}, "torch.ldexp": {"Parameters": {"input (Tensor)": "the input tensor.", "other (Tensor)": "a tensor of exponents, typically integers."}, "description": "Multiplies input by 2**:attr:other."}, "torch.lerp": {"Parameters": {"input (Tensor)": "the tensor with the starting points", "end (Tensor)": "the tensor with the ending points", "weight (float or tensor)": "the weight for the interpolation formula"}, "description": "Does a linear interpolation of two tensors start (given by input) and end based on a scalar or tensor weight and returns the resulting out tensor."}, "torch.lgamma": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Computes the natural logarithm of the absolute value of the gamma function on input."}, "torch.log": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Returns a new tensor with the natural logarithm of the elements of input."}, "torch.log10": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Returns a new tensor with the logarithm to the base 10 of the elements of input."}, "torch.log1p": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Returns a new tensor with the natural logarithm of (1 + input)."}, "torch.log2": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Returns a new tensor with the logarithm to the base 2 of the elements of input."}, "torch.logaddexp": {"Parameters": {"input (Tensor)": "the input tensor.", "other (Tensor)": "the second input tensor"}, "description": "Logarithm of the sum of exponentiations of the inputs."}, "torch.logaddexp2": {"Parameters": {"input (Tensor)": "the input tensor.", "other (Tensor)": "the second input tensor"}, "description": "Logarithm of the sum of exponentiations of the inputs in base-2."}, "torch.logical_and": {"Parameters": {"input (Tensor)": "the input tensor.", "other (Tensor)": "the tensor to compute AND with"}, "description": "Computes the element-wise logical AND of the given input tensors."}, "torch.logical_not": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Computes the element-wise logical NOT of the given input tensor."}, "torch.logical_or": {"Parameters": {"input (Tensor)": "the input tensor.", "other (Tensor)": "the tensor to compute OR with"}, "description": "Computes the element-wise logical OR of the given input tensors."}, "torch.logical_xor": {"Parameters": {"input (Tensor)": "the input tensor.", "other (Tensor)": "the tensor to compute XOR with"}, "description": "Computes the element-wise logical XOR of the given input tensors."}, "torch.logit": {"description": "Alias for torch.special.logit()."}, "torch.hypot": {"Parameters": {"input (Tensor)": "the first input tensor", "other (Tensor)": "the second input tensor"}, "description": "Given the legs of a right triangle, return its hypotenuse."}, "torch.i0": {"description": "Alias for torch.special.i0()."}, "torch.igamma": {"description": "Alias for torch.special.gammainc()."}, "torch.igammac": {"description": "Alias for torch.special.gammaincc()."}, "torch.mul": {"Parameters": {"input (Tensor)": "the input tensor.", "other (Tensor or Number)": ""}, "description": "Multiplies input by other."}, "torch.multiply": {"description": "Alias for torch.mul()."}, "torch.mvlgamma": {"description": "Alias for torch.special.multigammaln()."}, "torch.nan_to_num": {"Parameters": {"input (Tensor)": "the input tensor.", "nan (Number, optional)": "the value to replace NaNs with. Default is zero.", "posinf (Number, optional)": "if a Number, the value to replace positive infinity values with.\nIf None, positive infinity values are replaced with the greatest finite value representable by input\u2019s dtype.\nDefault is None.", "neginf (Number, optional)": "if a Number, the value to replace negative infinity values with.\nIf None, negative infinity values are replaced with the lowest finite value representable by input\u2019s dtype.\nDefault is None."}, "description": "Replaces NaN, positive infinity, and negative infinity values in input with the values specified by nan, posinf, and neginf, respectively."}, "torch.neg": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Returns a new tensor with the negative of the elements of input."}, "torch.negative": {"description": "Alias for torch.neg()"}, "torch.nextafter": {"Parameters": {"input (Tensor)": "the first input tensor", "other (Tensor)": "the second input tensor"}, "description": "Return the next floating-point value after input towards other, elementwise."}, "torch.polygamma": {"description": "Alias for torch.special.polygamma()."}, "torch.positive": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Returns input."}, "torch.pow": {"Parameters": {"self (float)": "the scalar base value for the power operation", "exponent (Tensor)": "the exponent tensor"}, "description": "Takes the power of each element in input with exponent and returns a tensor with the result."}, "torch.quantized_batch_norm": {"Parameters": {"input (Tensor)": "quantized tensor", "weight (Tensor)": "float tensor that corresponds to the gamma, size C", "bias (Tensor)": "float tensor that corresponds to the beta, size C", "mean (Tensor)": "float mean value in batch normalization, size C", "var (Tensor)": "float tensor for variance, size C", "eps (float)": "a value added to the denominator for numerical stability.", "output_scale (float)": "output quantized tensor scale", "output_zero_point (int)": "output quantized tensor zero_point"}, "Returns": "A quantized tensor with batch normalization applied.\n", "description": "Applies batch normalization on a 4D (NCHW) quantized tensor."}, "torch.quantized_max_pool1d": {"Parameters": {"input (Tensor)": "quantized tensor", "kernel_size (list of python:int)": "the size of the sliding window", "stride (list of int, optional)": "the stride of the sliding window", "padding (list of int, opttional)": "padding to be added on both sides, must be >= 0 and <= kernel_size / 2", "dilation (list of int, optional)": "The stride between elements within a sliding window, must be > 0. Default 1", "ceil_mode (bool, optional)": "If True, will use ceil instead of floor to compute the output shape.\nDefaults to False."}, "Returns": "A quantized tensor with max_pool1d applied.\n", "description": "Applies a 1D max pooling over an input quantized tensor composed of several input planes."}, "torch.quantized_max_pool2d": {"Parameters": {"input (Tensor)": "quantized tensor", "kernel_size (list of int)": "the size of the sliding window", "stride (list of int, optional)": "the stride of the sliding window", "padding (list of int, optional)": "padding to be added on both sides, must be >= 0 and <= kernel_size / 2", "dilation (list of int, optional)": "The stride between elements within a sliding window, must be > 0. Default 1", "ceil_mode (bool, optional)": "If True, will use ceil instead of floor to compute the output shape.\nDefaults to False."}, "Returns": "A quantized tensor with max_pool2d applied.\n", "description": "Applies a 2D max pooling over an input quantized tensor composed of several input planes."}, "torch.rad2deg": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Returns a new tensor with each of the elements of input converted from angles in radians to degrees."}, "torch.real": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Returns a new tensor containing real values of the self tensor."}, "torch.reciprocal": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Returns a new tensor with the reciprocal of the elements of input"}, "torch.remainder": {"Parameters": {"input (Tensor or Scalar)": "the dividend", "other (Tensor or Scalar)": "the divisor"}, "description": "Computes Python\u2019s modulus operation entrywise."}, "torch.round": {"Parameters": {"input (Tensor)": "the input tensor.", "decimals (int)": "Number of decimal places to round to (default: 0).\nIf decimals is negative, it specifies the number of positions\nto the left of the decimal point."}, "description": "Rounds elements of input to the nearest integer."}, "torch.rsqrt": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Returns a new tensor with the reciprocal of the square-root of each of the elements of input."}, "torch.sigmoid": {"description": "Alias for torch.special.expit()."}, "torch.sign": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Returns a new tensor with the signs of the elements of input."}, "torch.sgn": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "This function is an extension of torch.sign() to complex tensors."}, "torch.signbit": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Tests if each element of input has its sign bit set (is less than zero) or not."}, "torch.sin": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Returns a new tensor with the sine of the elements of input."}, "torch.sinc": {"description": "Alias for torch.special.sinc()."}, "torch.sinh": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Returns a new tensor with the hyperbolic sine of the elements of input."}, "torch.sqrt": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Returns a new tensor with the square-root of the elements of input."}, "torch.square": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Returns a new tensor with the square of the elements of input."}, "torch.sub": {"Parameters": {"input (Tensor)": "the input tensor.", "other (Tensor or Number)": "the tensor or number to subtract from input."}, "description": "Subtracts other, scaled by alpha, from input."}, "torch.subtract": {"description": "Alias for torch.sub()."}, "torch.tan": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Returns a new tensor with the tangent of the elements of input."}, "torch.tanh": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Returns a new tensor with the hyperbolic tangent of the elements of input."}, "torch.true_divide": {"description": "Alias for torch.div() with rounding_mode=None."}, "torch.trunc": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Returns a new tensor with the truncated integer values of the elements of input."}, "torch.xlogy": {"description": "Alias for torch.special.xlogy()."}, "torch.argmax": {"Parameters": {"input (Tensor)": "the input tensor.", "dim (int)": "the dimension to reduce. If None, the argmax of the flattened input is returned.", "keepdim (bool)": "whether the output tensor has dim retained or not. Ignored if dim=None."}, "description": "Returns the indices of the maximum value of all elements in the input tensor."}, "torch.argmin": {"Parameters": {"input (Tensor)": "the input tensor.", "dim (int)": "the dimension to reduce. If None, the argmin of the flattened input is returned.", "keepdim (bool)": "whether the output tensor has dim retained or not. Ignored if dim=None."}, "description": "Returns the indices of the minimum value(s) of the flattened tensor or along a dimension"}, "torch.amax": {"Parameters": {"input (Tensor)": "the input tensor.", "dim (int or tuple of python:ints)": "the dimension or dimensions to reduce.", "keepdim (bool)": "whether the output tensor has dim retained or not."}, "description": "Returns the maximum value of each slice of the input tensor in the given dimension(s) dim."}, "torch.amin": {"Parameters": {"input (Tensor)": "the input tensor.", "dim (int or tuple of python:ints)": "the dimension or dimensions to reduce.", "keepdim (bool)": "whether the output tensor has dim retained or not."}, "description": "Returns the minimum value of each slice of the input tensor in the given dimension(s) dim."}, "torch.aminmax": {"Parameters": {"input (Tensor)": "The input tensor"}, "Returns": "A named tuple (min, max) containing the minimum and maximum values.\n", "description": "Computes the minimum and maximum values of the input tensor."}, "torch.all": {"Parameters": {"input (Tensor)": "the input tensor.", "dim (int)": "the dimension to reduce.", "keepdim (bool)": "whether the output tensor has dim retained or not."}, "description": "Tests if all elements in input evaluate to True."}, "torch.any": {"Parameters": {"input (Tensor)": "the input tensor.", "dim (int)": "the dimension to reduce.", "keepdim (bool)": "whether the output tensor has dim retained or not."}, "description": "Tests if any element in input evaluates to True."}, "torch.max": {"Parameters": {"input (Tensor)": "the input tensor.", "dim (int)": "the dimension to reduce.", "keepdim (bool)": "whether the output tensor has dim retained or not. Default: False."}, "description": "Returns the maximum value of all elements in the input tensor."}, "torch.min": {"Parameters": {"input (Tensor)": "the input tensor.", "dim (int)": "the dimension to reduce.", "keepdim (bool)": "whether the output tensor has dim retained or not."}, "description": "Returns the minimum value of all elements in the input tensor."}, "torch.dist": {"Parameters": {"input (Tensor)": "the input tensor.", "other (Tensor)": "the Right-hand-side input tensor", "p (float, optional)": "the norm to be computed"}, "description": "Returns the p-norm of (input - other)"}, "torch.logsumexp": {"Parameters": {"input (Tensor)": "the input tensor.", "dim (int or tuple of python:ints)": "the dimension or dimensions to reduce.", "keepdim (bool)": "whether the output tensor has dim retained or not."}, "description": "Returns the log of summed exponentials of each row of the input tensor in the given dimension dim."}, "torch.mean": {"Parameters": {"input (Tensor)": "the input tensor.", "dim (int or tuple of python:ints)": "the dimension or dimensions to reduce.", "keepdim (bool)": "whether the output tensor has dim retained or not."}, "description": "Returns the mean value of all elements in the input tensor."}, "torch.nanmean": {"Parameters": {"input (Tensor)": "the input tensor.", "dim (int or tuple of python:ints)": "the dimension or dimensions to reduce. If None, reduces all dimensions. Default is None.", "keepdim (bool)": "whether the output tensor has dim retained or not."}, "description": "Computes the mean of all non-NaN elements along the specified dimensions."}, "torch.median": {"Parameters": {"input (Tensor)": "the input tensor.", "dim (int)": "the dimension to reduce.", "keepdim (bool)": "whether the output tensor has dim retained or not."}, "description": "Returns the median of the values in input."}, "torch.nanmedian": {"Parameters": {"input (Tensor)": "the input tensor.", "dim (int)": "the dimension to reduce.", "keepdim (bool)": "whether the output tensor has dim retained or not."}, "description": "Returns the median of the values in input, ignoring NaN values."}, "torch.mode": {"Parameters": {"input (Tensor)": "the input tensor.", "dim (int)": "the dimension to reduce.", "keepdim (bool)": "whether the output tensor has dim retained or not."}, "description": "Returns a namedtuple (values, indices) where values is the mode value of each row of the input tensor in the given dimension dim, i.e. a value which appears most often in that row, and indices is the index location of each mode value found."}, "torch.norm": {"Parameters": {"input (Tensor)": "The input tensor. Its data type must be either a floating\npoint or complex type. For complex inputs, the norm is calculated using the\nabsolute value of each element. If the input is complex and neither\ndtype nor out is specified, the result\u2019s data type will\nbe the corresponding floating point type (e.g. float if input is\ncomplexfloat).", "p (int, float, inf, -inf, 'fro', 'nuc', optional)": "the order of norm. Default: 'fro'\nThe following norms can be calculated:\n\n\nord\nmatrix norm\nvector norm\n\n\n\n\u2019fro\u2019\nFrobenius norm\n\u2013\n\n\u2018nuc\u2019\nnuclear norm\n\u2013\n\nNumber\n\u2013\nsum(abs(x)**ord)**(1./ord)\n\n\n\nThe vector norm can be calculated across any number of dimensions.\nThe corresponding dimensions of input are flattened into\none dimension, and the norm is calculated on the flattened\ndimension.\nFrobenius norm produces the same result as p=2 in all cases\nexcept when dim is a list of three or more dims, in which\ncase Frobenius norm throws an error.\nNuclear norm can only be calculated across exactly two dimensions.", "dim (int, tuple of python:ints, list of python:ints, optional)": "Specifies which dimension or dimensions of input to\ncalculate the norm across. If dim is None, the norm will\nbe calculated across all dimensions of input. If the norm\ntype indicated by p does not support the specified number of\ndimensions, an error will occur.", "keepdim (bool, optional)": "whether the output tensors have dim\nretained or not. Ignored if dim = None and\nout = None. Default: False", "out (Tensor, optional)": "the output tensor. Ignored if\ndim = None and out = None.", "dtype (torch.dtype, optional)": "the desired data type of\nreturned tensor. If specified, the input tensor is casted to\ndtype while performing the operation. Default: None."}, "description": "Returns the matrix norm or vector norm of a given tensor."}, "torch.nansum": {"Parameters": {"input (Tensor)": "the input tensor.", "dim (int or tuple of python:ints)": "the dimension or dimensions to reduce.", "keepdim (bool)": "whether the output tensor has dim retained or not."}, "description": "Returns the sum of all elements, treating Not a Numbers (NaNs) as zero."}, "torch.prod": {"Parameters": {"input (Tensor)": "the input tensor.", "dim (int)": "the dimension to reduce.", "keepdim (bool)": "whether the output tensor has dim retained or not."}, "description": "Returns the product of all elements in the input tensor."}, "torch.quantile": {"Parameters": {"input (Tensor)": "the input tensor.", "q (float or Tensor)": "a scalar or 1D tensor of values in the range [0, 1].", "dim (int)": "the dimension to reduce.", "keepdim (bool)": "whether the output tensor has dim retained or not."}, "description": "Computes the q-th quantiles of each row of the input tensor along the dimension dim."}, "torch.nanquantile": {"Parameters": {"input (Tensor)": "the input tensor.", "q (float or Tensor)": "a scalar or 1D tensor of quantile values in the range [0, 1]", "dim (int)": "the dimension to reduce.", "keepdim (bool)": "whether the output tensor has dim retained or not."}, "description": "This is a variant of torch.quantile() that \u201cignores\u201d NaN values, computing the quantiles q as if NaN values in input did not exist."}, "torch.std": {"Parameters": {"input (Tensor)": "the input tensor.", "unbiased (bool)": "whether to use Bessel\u2019s correction (\u03b4N=1\\delta N = 1\u03b4N=1)."}, "description": "If unbiased is True, Bessel\u2019s correction will be used."}, "torch.std_mean": {"Parameters": {"input (Tensor)": "the input tensor.", "unbiased (bool)": "whether to use Bessel\u2019s correction (\u03b4N=1\\delta N = 1\u03b4N=1)."}, "Returns": "A tuple (std, mean) containing the standard deviation and mean.\n", "description": "If unbiased is True, Bessel\u2019s correction will be used to calculate the standard deviation."}, "torch.sum": {"Parameters": {"input (Tensor)": "the input tensor.", "dim (int or tuple of python:ints)": "the dimension or dimensions to reduce.", "keepdim (bool)": "whether the output tensor has dim retained or not."}, "description": "Returns the sum of all elements in the input tensor."}, "torch.unique": {"Parameters": {"input (Tensor)": "the input tensor", "sorted (bool)": "Whether to sort the unique elements in ascending order\nbefore returning as output.", "return_inverse (bool)": "Whether to also return the indices for where\nelements in the original input ended up in the returned unique list.", "return_counts (bool)": "Whether to also return the counts for each unique\nelement.", "dim (int)": "the dimension to apply unique. If None, the unique of the\nflattened input is returned. default: None"}, "Returns": "A tensor or a tuple of tensors containing\n\n\noutput (Tensor): the output list of unique scalar elements.\ninverse_indices (Tensor): (optional) if\nreturn_inverse is True, there will be an additional\nreturned tensor (same shape as input) representing the indices\nfor where elements in the original input map to in the output;\notherwise, this function will only return a single tensor.\ncounts (Tensor): (optional) if\nreturn_counts is True, there will be an additional\nreturned tensor (same shape as output or output.size(dim),\nif dim was specified) representing the number of occurrences\nfor each unique value or tensor.\n\n\n\n", "description": "Returns the unique elements of the input tensor."}, "torch.unique_consecutive": {"Parameters": {"input (Tensor)": "the input tensor", "return_inverse (bool)": "Whether to also return the indices for where\nelements in the original input ended up in the returned unique list.", "return_counts (bool)": "Whether to also return the counts for each unique\nelement.", "dim (int)": "the dimension to apply unique. If None, the unique of the\nflattened input is returned. default: None"}, "Returns": "A tensor or a tuple of tensors containing\n\n\noutput (Tensor): the output list of unique scalar elements.\ninverse_indices (Tensor): (optional) if\nreturn_inverse is True, there will be an additional\nreturned tensor (same shape as input) representing the indices\nfor where elements in the original input map to in the output;\notherwise, this function will only return a single tensor.\ncounts (Tensor): (optional) if\nreturn_counts is True, there will be an additional\nreturned tensor (same shape as output or output.size(dim),\nif dim was specified) representing the number of occurrences\nfor each unique value or tensor.\n\n\n\n", "description": "Eliminates all but the first element from every consecutive group of equivalent elements."}, "torch.var": {"Parameters": {"input (Tensor)": "the input tensor.", "unbiased (bool)": "whether to use Bessel\u2019s correction (\u03b4N=1\\delta N = 1\u03b4N=1)."}, "description": "If unbiased is True, Bessel\u2019s correction will be used."}, "torch.var_mean": {"Parameters": {"input (Tensor)": "the input tensor.", "unbiased (bool)": "whether to use Bessel\u2019s correction (\u03b4N=1\\delta N = 1\u03b4N=1)."}, "Returns": "A tuple (var, mean) containing the variance and mean.\n", "description": "If unbiased is True, Bessel\u2019s correction will be used to calculate the variance."}, "torch.count_nonzero": {"Parameters": {"input (Tensor)": "the input tensor.", "dim (int or tuple of python:ints, optional)": "Dim or tuple of dims along which to count non-zeros."}, "description": "Counts the number of non-zero values in the tensor input along the given dim."}, "torch.allclose": {"Parameters": {"input (Tensor)": "first tensor to compare", "other (Tensor)": "second tensor to compare", "atol (float, optional)": "absolute tolerance. Default: 1e-08", "rtol (float, optional)": "relative tolerance. Default: 1e-05", "equal_nan (bool, optional)": "if True, then two NaN s will be considered equal. Default: False"}, "description": "This function checks if all input and other satisfy the condition:"}, "torch.argsort": {"Parameters": {"input (Tensor)": "the input tensor.", "dim (int, optional)": "the dimension to sort along", "descending (bool, optional)": "controls the sorting order (ascending or descending)"}, "description": "Returns the indices that sort a tensor along a given dimension in ascending order by value."}, "torch.eq": {"Parameters": {"input (Tensor)": "the tensor to compare", "other (Tensor or float)": "the tensor or value to compare"}, "Returns": "A boolean tensor that is True where input is equal to other and False elsewhere\n", "description": "Computes element-wise equality"}, "torch.equal": {"description": "True if two tensors have the same size and elements, False otherwise."}, "torch.ge": {"Parameters": {"input (Tensor)": "the tensor to compare", "other (Tensor or float)": "the tensor or value to compare"}, "Returns": "A boolean tensor that is True where input is greater than or equal to other and False elsewhere\n", "description": "Computes input\u2265other\\text{input} \\geq \\text{other}input\u2265other element-wise."}, "torch.greater_equal": {"description": "Alias for torch.ge()."}, "torch.gt": {"Parameters": {"input (Tensor)": "the tensor to compare", "other (Tensor or float)": "the tensor or value to compare"}, "Returns": "A boolean tensor that is True where input is greater than other and False elsewhere\n", "description": "Computes input>other\\text{input} > \\text{other}input>other element-wise."}, "torch.greater": {"description": "Alias for torch.gt()."}, "torch.isclose": {"Parameters": {"input (Tensor)": "first tensor to compare", "other (Tensor)": "second tensor to compare", "atol (float, optional)": "absolute tolerance. Default: 1e-08", "rtol (float, optional)": "relative tolerance. Default: 1e-05", "equal_nan (bool, optional)": "if True, then two NaN s will be considered equal. Default: False"}, "description": "Returns a new tensor with boolean elements representing if each element of input is \u201cclose\u201d to the corresponding element of other."}, "torch.isfinite": {"Parameters": {"input (Tensor)": "the input tensor."}, "Returns": "A boolean tensor that is True where input is finite and False elsewhere\n", "description": "Returns a new tensor with boolean elements representing if each element is finite or not."}, "torch.isin": {"Parameters": {"elements (Tensor or Scalar)": "Input elements", "test_elements (Tensor or Scalar)": "Values against which to test for each input element", "assume_unique (bool, optional)": "If True, assumes both elements and\ntest_elements contain unique elements, which can speed up the\ncalculation. Default: False", "invert (bool, optional)": "If True, inverts the boolean return tensor, resulting in True\nvalues for elements not in test_elements. Default: False"}, "Returns": "A boolean tensor of the same shape as elements that is True for elements in\ntest_elements and False otherwise\n", "description": "Tests if each element of elements is in test_elements."}, "torch.isinf": {"Parameters": {"input (Tensor)": "the input tensor."}, "Returns": "A boolean tensor that is True where input is infinite and False elsewhere\n", "description": "Tests if each element of input is infinite (positive or negative infinity) or not."}, "torch.isposinf": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Tests if each element of input is positive infinity or not."}, "torch.isneginf": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Tests if each element of input is negative infinity or not."}, "torch.isnan": {"Parameters": {"input (Tensor)": "the input tensor."}, "Returns": "A boolean tensor that is True where input is NaN and False elsewhere\n", "description": "Returns a new tensor with boolean elements representing if each element of input is NaN or not."}, "torch.isreal": {"Parameters": {"input (Tensor)": "the input tensor."}, "Returns": "A boolean tensor that is True where input is real and False elsewhere\n", "description": "Returns a new tensor with boolean elements representing if each element of input is real-valued or not."}, "torch.kthvalue": {"Parameters": {"input (Tensor)": "the input tensor.", "k (int)": "k for the k-th smallest element", "dim (int, optional)": "the dimension to find the kth value along", "keepdim (bool)": "whether the output tensor has dim retained or not."}, "description": "Returns a namedtuple (values, indices) where values is the k th smallest element of each row of the input tensor in the given dimension dim."}, "torch.le": {"Parameters": {"input (Tensor)": "the tensor to compare", "other (Tensor or Scalar)": "the tensor or value to compare"}, "Returns": "A boolean tensor that is True where input is less than or equal to\nother and False elsewhere\n", "description": "Computes input\u2264other\\text{input} \\leq \\text{other}input\u2264other element-wise."}, "torch.less_equal": {"description": "Alias for torch.le()."}, "torch.lt": {"Parameters": {"input (Tensor)": "the tensor to compare", "other (Tensor or float)": "the tensor or value to compare"}, "Returns": "A boolean tensor that is True where input is less than other and False elsewhere\n", "description": "Computes input<other\\text{input} < \\text{other}input<other element-wise."}, "torch.less": {"description": "Alias for torch.lt()."}, "torch.maximum": {"Parameters": {"input (Tensor)": "the input tensor.", "other (Tensor)": "the second input tensor"}, "description": "Computes the element-wise maximum of input and other."}, "torch.minimum": {"Parameters": {"input (Tensor)": "the input tensor.", "other (Tensor)": "the second input tensor"}, "description": "Computes the element-wise minimum of input and other."}, "torch.fmax": {"Parameters": {"input (Tensor)": "the input tensor.", "other (Tensor)": "the second input tensor"}, "description": "Computes the element-wise maximum of input and other."}, "torch.fmin": {"Parameters": {"input (Tensor)": "the input tensor.", "other (Tensor)": "the second input tensor"}, "description": "Computes the element-wise minimum of input and other."}, "torch.ne": {"Parameters": {"input (Tensor)": "the tensor to compare", "other (Tensor or float)": "the tensor or value to compare"}, "Returns": "A boolean tensor that is True where input is not equal to other and False elsewhere\n", "description": "Computes input\u2260other\\text{input} \\neq \\text{other}input\ue020=other element-wise."}, "torch.not_equal": {"description": "Alias for torch.ne()."}, "torch.sort": {"Parameters": {"input (Tensor)": "the input tensor.", "dim (int, optional)": "the dimension to sort along", "descending (bool, optional)": "controls the sorting order (ascending or descending)", "stable (bool, optional)": "makes the sorting routine stable, which guarantees that the order\nof equivalent elements is preserved."}, "description": "Sorts the elements of the input tensor along a given dimension in ascending order by value."}, "torch.topk": {"Parameters": {"input (Tensor)": "the input tensor.", "k (int)": "the k in \u201ctop-k\u201d", "dim (int, optional)": "the dimension to sort along", "largest (bool, optional)": "controls whether to return largest or\nsmallest elements", "sorted (bool, optional)": "controls whether to return the elements\nin sorted order"}, "description": "Returns the k largest elements of the given input tensor along a given dimension."}, "torch.msort": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Sorts the elements of the input tensor along its first dimension in ascending order by value."}, "torch.stft": {"Parameters": {"input (Tensor)": "the input tensor", "n_fft (int)": "size of Fourier transform", "hop_length (int, optional)": "the distance between neighboring sliding window\nframes. Default: None (treated as equal to floor(n_fft / 4))", "win_length (int, optional)": "the size of window frame and STFT filter.\nDefault: None  (treated as equal to n_fft)", "window (Tensor, optional)": "the optional window function.\nDefault: None (treated as window of all 111 s)", "center (bool, optional)": "whether to pad input on both sides so\nthat the ttt-th frame is centered at time t\u00d7hop_lengtht \\times \\text{hop\\_length}t\u00d7hop_length.\nDefault: True", "pad_mode (string, optional)": "controls the padding method used when\ncenter is True. Default: \"reflect\"", "normalized (bool, optional)": "controls whether to return the normalized STFT results\nDefault: False", "onesided (bool, optional)": "controls whether to return half of results to\navoid redundancy for real inputs.\nDefault: True for real input and window, False otherwise.", "return_complex (bool, optional)": "whether to return a complex tensor, or\na real tensor with an extra last dimension for the real and\nimaginary components."}, "Returns": "A tensor containing the STFT result with shape described above\n", "description": "Short-time Fourier transform (STFT)."}, "torch.istft": {"Parameters": {"input (Tensor)": "The input tensor. Expected to be output of stft(),\ncan either be complex (channel, fft_size, n_frame), or real\n(channel, fft_size, n_frame, 2) where the channel\ndimension is optional.\n\nDeprecated since version 1.8.0: Real input is deprecated, use complex inputs as returned by\nstft(..., return_complex=True) instead.", "n_fft (int)": "Size of Fourier transform", "hop_length (Optional[int])": "The distance between neighboring sliding window frames.\n(Default: n_fft // 4)", "win_length (Optional[int])": "The size of window frame and STFT filter. (Default: n_fft)", "window (Optional[torch.Tensor])": "The optional window function.\n(Default: torch.ones(win_length))", "center (bool)": "Whether input was padded on both sides so that the ttt-th frame is\ncentered at time t\u00d7hop_lengtht \\times \\text{hop\\_length}t\u00d7hop_length.\n(Default: True)", "normalized (bool)": "Whether the STFT was normalized. (Default: False)", "onesided (Optional[bool])": "Whether the STFT was onesided.\n(Default: True if n_fft != fft_size in the input size)", "length (Optional[int])": "The amount to trim the signal by (i.e. the\noriginal signal length). (Default: whole signal)", "return_complex (Optional[bool])": "Whether the output should be complex, or if the input should be\nassumed to derive from a real signal and window.\nNote that this is incompatible with onesided=True.\n(Default: False)"}, "Returns": "Least squares estimation of the original signal of size (\u2026, signal_length)\n", "description": "Inverse short time Fourier Transform."}, "torch.bartlett_window": {"Parameters": {"window_length (int)": "the size of returned window", "periodic (bool, optional)": "If True, returns a window to be used as periodic\nfunction. If False, return a symmetric window."}, "Returns": "A 1-D tensor of size (window_length,)(\\text{window\\_length},)(window_length,) containing the window\n", "description": "Bartlett window function."}, "torch.blackman_window": {"Parameters": {"window_length (int)": "the size of returned window", "periodic (bool, optional)": "If True, returns a window to be used as periodic\nfunction. If False, return a symmetric window."}, "Returns": "A 1-D tensor of size (window_length,)(\\text{window\\_length},)(window_length,) containing the window\n", "description": "Blackman window function."}, "torch.hamming_window": {"Parameters": {"window_length (int)": "the size of returned window", "periodic (bool, optional)": "If True, returns a window to be used as periodic\nfunction. If False, return a symmetric window.", "alpha (float, optional)": "The coefficient \u03b1\\alpha\u03b1 in the equation above", "beta (float, optional)": "The coefficient \u03b2\\beta\u03b2 in the equation above"}, "Returns": "A 1-D tensor of size (window_length,)(\\text{window\\_length},)(window_length,) containing the window\n", "description": "Hamming window function."}, "torch.hann_window": {"Parameters": {"window_length (int)": "the size of returned window", "periodic (bool, optional)": "If True, returns a window to be used as periodic\nfunction. If False, return a symmetric window."}, "Returns": "A 1-D tensor of size (window_length,)(\\text{window\\_length},)(window_length,) containing the window\n", "description": "Hann window function."}, "torch.kaiser_window": {"Parameters": {"window_length (int)": "length of the window.", "periodic (bool, optional)": "If True, returns a periodic window suitable for use in spectral analysis.\nIf False, returns a symmetric window suitable for use in filter design.", "beta (float, optional)": "shape parameter for the window."}, "description": "Computes the Kaiser window with window length window_length and shape parameter beta."}, "torch.atleast_1d": {"Parameters": {"input (Tensor or list of Tensors)": ""}, "Returns": "output (Tensor or tuple of Tensors)\n", "description": "Returns a 1-dimensional view of each input tensor with zero dimensions."}, "torch.atleast_2d": {"Parameters": {"input (Tensor or list of Tensors)": ""}, "Returns": "output (Tensor or tuple of Tensors)\n", "description": "Returns a 2-dimensional view of each input tensor with zero dimensions."}, "torch.atleast_3d": {"Parameters": {"input (Tensor or list of Tensors)": ""}, "Returns": "output (Tensor or tuple of Tensors)\n", "description": "Returns a 3-dimensional view of each input tensor with zero dimensions."}, "torch.bincount": {"Parameters": {"input (Tensor)": "1-d int tensor", "weights (Tensor)": "optional, weight for each value in the input tensor.\nShould be of same size as input tensor.", "minlength (int)": "optional, minimum number of bins. Should be non-negative."}, "Returns": "a tensor of shape Size([max(input) + 1]) if\ninput is non-empty, else Size(0)\n", "description": "Count the frequency of each value in an array of non-negative ints."}, "torch.block_diag": {"Parameters": {"*tensors": "One or more tensors with 0, 1, or 2 dimensions."}, "Returns": "A 2 dimensional tensor with all the input tensors arranged in\norder such that their upper left and lower right corners are\ndiagonally adjacent. All other elements are set to 0.\n", "description": "Create a block diagonal matrix from provided tensors."}, "torch.broadcast_tensors": {"Parameters": {"*tensors": "any number of tensors of the same type"}, "description": "Broadcasts the given tensors according to Broadcasting semantics."}, "torch.broadcast_to": {"Parameters": {"input (Tensor)": "the input tensor.", "shape (list, tuple, or torch.Size)": "the new shape."}, "description": "Broadcasts input to the shape shape."}, "torch.broadcast_shapes": {"Parameters": {"*shapes (torch.Size)": "Shapes of tensors."}, "Returns": "A shape compatible with all input shapes.\n", "description": "Similar to broadcast_tensors() but for shapes."}, "torch.bucketize": {"Parameters": {"input (Tensor or Scalar)": "N-D tensor or a Scalar containing the search value(s).", "boundaries (Tensor)": "1-D tensor, must contain a monotonically increasing sequence."}, "description": "Returns the indices of the buckets to which each value in the input belongs, where the boundaries of the buckets are set by boundaries."}, "torch.cartesian_prod": {"Parameters": {"*tensors": "any number of 1 dimensional tensors."}, "Returns": "A tensor equivalent to converting all the input tensors into lists,\ndo itertools.product on these lists, and finally convert the resulting list\ninto tensor.\n", "description": "Do cartesian product of the given sequence of tensors."}, "torch.cdist": {"Parameters": {"x1 (Tensor)": "input tensor of shape B\u00d7P\u00d7MB \\times P \\times MB\u00d7P\u00d7M.", "x2 (Tensor)": "input tensor of shape B\u00d7R\u00d7MB \\times R \\times MB\u00d7R\u00d7M.", "p": "p value for the p-norm distance to calculate between each vector pair\n\u2208[0,\u221e]\\in [0, \\infty]\u2208[0,\u221e].", "compute_mode": "\u2018use_mm_for_euclid_dist_if_necessary\u2019 - will use matrix multiplication approach to calculate\neuclidean distance (p = 2) if P > 25 or R > 25\n\u2018use_mm_for_euclid_dist\u2019 - will always use matrix multiplication approach to calculate\neuclidean distance (p = 2)\n\u2018donot_use_mm_for_euclid_dist\u2019 - will never use matrix multiplication approach to calculate\neuclidean distance (p = 2)\nDefault: use_mm_for_euclid_dist_if_necessary."}, "description": "Computes batched the p-norm distance between each pair of the two collections of row vectors."}, "torch.clone": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Returns a copy of input."}, "torch.combinations": {"Parameters": {"input (Tensor)": "1D vector.", "r (int, optional)": "number of elements to combine", "with_replacement (boolean, optional)": "whether to allow duplication in combination"}, "Returns": "A tensor equivalent to converting all the input tensors into lists, do\nitertools.combinations or itertools.combinations_with_replacement on these\nlists, and finally convert the resulting list into tensor.\n", "description": "Compute combinations of length rrr of the given tensor."}, "torch.corrcoef": {"Parameters": {"input (Tensor)": "A 2D matrix containing multiple variables and observations, or a\nScalar or 1D vector representing a single variable."}, "Returns": "(Tensor) The correlation coefficient matrix of the variables.\n", "description": "Estimates the Pearson product-moment correlation coefficient matrix of the variables given by the input matrix, where rows are the variables and columns are the observations."}, "torch.cov": {"Parameters": {"input (Tensor)": "A 2D matrix containing multiple variables and observations, or a\nScalar or 1D vector representing a single variable."}, "Returns": "(Tensor) The covariance matrix of the variables.\n", "description": "Estimates the covariance matrix of the variables given by the input matrix, where rows are the variables and columns are the observations."}, "torch.cross": {"Parameters": {"input (Tensor)": "the input tensor.", "other (Tensor)": "the second input tensor", "dim (int, optional)": "the dimension to take the cross-product in."}, "description": "Returns the cross product of vectors in dimension dim of input and other."}, "torch.cummax": {"Parameters": {"input (Tensor)": "the input tensor.", "dim (int)": "the dimension to do the operation over"}, "description": "Returns a namedtuple (values, indices) where values is the cumulative maximum of elements of input in the dimension dim."}, "torch.cummin": {"Parameters": {"input (Tensor)": "the input tensor.", "dim (int)": "the dimension to do the operation over"}, "description": "Returns a namedtuple (values, indices) where values is the cumulative minimum of elements of input in the dimension dim."}, "torch.cumprod": {"Parameters": {"input (Tensor)": "the input tensor.", "dim (int)": "the dimension to do the operation over"}, "description": "Returns the cumulative product of elements of input in the dimension dim."}, "torch.cumsum": {"Parameters": {"input (Tensor)": "the input tensor.", "dim (int)": "the dimension to do the operation over"}, "description": "Returns the cumulative sum of elements of input in the dimension dim."}, "torch.diag": {"Parameters": {"input (Tensor)": "the input tensor.", "diagonal (int, optional)": "the diagonal to consider"}, "description": "\nIf input is a vector (1-D tensor), then returns a 2-D square tensor\n\n"}, "torch.diag_embed": {"Parameters": {"input (Tensor)": "the input tensor. Must be at least 1-dimensional.", "offset (int, optional)": "which diagonal to consider. Default: 0\n(main diagonal).", "dim1 (int, optional)": "first dimension with respect to which to\ntake diagonal. Default: -2.", "dim2 (int, optional)": "second dimension with respect to which to\ntake diagonal. Default: -1."}, "description": "Creates a tensor whose diagonals of certain 2D planes (specified by dim1 and dim2) are filled by input."}, "torch.diagflat": {"Parameters": {"input (Tensor)": "the input tensor.", "offset (int, optional)": "the diagonal to consider. Default: 0 (main\ndiagonal)."}, "description": "\nIf input is a vector (1-D tensor), then returns a 2-D square tensor\n\n"}, "torch.diagonal": {"Parameters": {"input (Tensor)": "the input tensor. Must be at least 2-dimensional.", "offset (int, optional)": "which diagonal to consider. Default: 0\n(main diagonal).", "dim1 (int, optional)": "first dimension with respect to which to\ntake diagonal. Default: 0.", "dim2 (int, optional)": "second dimension with respect to which to\ntake diagonal. Default: 1."}, "description": "Returns a partial view of input with the its diagonal elements with respect to dim1 and dim2 appended as a dimension at the end of the shape."}, "torch.diff": {"Parameters": {"input (Tensor)": "the tensor to compute the differences on", "n (int, optional)": "the number of times to recursively compute the difference", "dim (int, optional)": "the dimension to compute the difference along.\nDefault is the last dimension.", "prepend (Tensor, optional)": "values to prepend or append to\ninput along dim before computing the difference.\nTheir dimensions must be equivalent to that of input, and their shapes\nmust match input\u2019s shape except on dim.", "append (Tensor, optional)": "values to prepend or append to\ninput along dim before computing the difference.\nTheir dimensions must be equivalent to that of input, and their shapes\nmust match input\u2019s shape except on dim."}, "description": "Computes the n-th forward difference along the given dimension."}, "torch.einsum": {"Parameters": {"equation (string)": "The subscripts for the Einstein summation.", "operands (List[Tensor])": "The tensors to compute the Einstein summation of."}, "description": "Sums the product of the elements of the input operands along dimensions specified using a notation based on the Einstein summation convention."}, "torch.flatten": {"Parameters": {"input (Tensor)": "the input tensor.", "start_dim (int)": "the first dim to flatten", "end_dim (int)": "the last dim to flatten"}, "description": "Flattens input by reshaping it into a one-dimensional tensor."}, "torch.flip": {"Parameters": {"input (Tensor)": "the input tensor.", "dims (a list or tuple)": "axis to flip on"}, "description": "Reverse the order of a n-D tensor along given axis in dims."}, "torch.fliplr": {"Parameters": {"input (Tensor)": "Must be at least 2-dimensional."}, "description": "Flip tensor in the left/right direction, returning a new tensor."}, "torch.flipud": {"Parameters": {"input (Tensor)": "Must be at least 1-dimensional."}, "description": "Flip tensor in the up/down direction, returning a new tensor."}, "torch.kron": {"Parameters": {"input (Tensor)": "", "other (Tensor)": ""}, "description": "Computes the Kronecker product, denoted by \u2297\\otimes\u2297, of input and other."}, "torch.rot90": {"Parameters": {"input (Tensor)": "the input tensor.", "k (int)": "number of times to rotate", "dims (a list or tuple)": "axis to rotate"}, "description": "Rotate a n-D tensor by 90 degrees in the plane specified by dims axis."}, "torch.gcd": {"Parameters": {"input (Tensor)": "the input tensor.", "other (Tensor)": "the second input tensor"}, "description": "Computes the element-wise greatest common divisor (GCD) of input and other."}, "torch.histc": {"Parameters": {"input (Tensor)": "the input tensor.", "bins (int)": "number of histogram bins", "min (Scalar)": "lower end of the range (inclusive)", "max (Scalar)": "upper end of the range (inclusive)"}, "Returns": "Histogram represented as a tensor\n", "description": "Computes the histogram of a tensor."}, "torch.histogram": {"Parameters": {"input (Tensor)": "the input tensor.", "bins": "int or 1D Tensor. If int, defines the number of equal-width bins. If tensor,\ndefines the sequence of bin edges including the rightmost edge."}, "Returns": "1D Tensor containing the values of the histogram.\nbin_edges(Tensor): 1D Tensor containing the edges of the histogram bins.\n", "description": "Computes a histogram of the values in a tensor."}, "torch.histogramdd": {"Parameters": {"{input}": "", "bins": "Tensor[], int[], or int.\nIf Tensor[], defines the sequences of bin edges.\nIf int[], defines the number of equal-width bins in each dimension.\nIf int, defines the number of equal-width bins for all dimensions."}, "Returns": "N-dimensional Tensor containing the values of the histogram.\nbin_edges(Tensor[]): sequence of N 1D Tensors containing the bin edges.\n", "description": "Computes a multi-dimensional histogram of the values in a tensor."}, "torch.meshgrid": {"Parameters": {"tensors (list of Tensor)": "list of scalars or 1 dimensional tensors. Scalars will be\ntreated as tensors of size (1,)(1,)(1,) automatically", "indexing": "(str, optional): the indexing mode, either \u201cxy\u201d\nor \u201cij\u201d, defaults to \u201cij\u201d. See warning for future changes.\nIf \u201cxy\u201d is selected, the first dimension corresponds\nto the cardinality of the second input and the second\ndimension corresponds to the cardinality of the first\ninput.\nIf \u201cij\u201d is selected, the dimensions are in the same\norder as the cardinality of the inputs."}, "Returns": "If the input has NNN\ntensors of size S0\u2026SN\u22121S_0 \\ldots S_{N-1}S0\u200b\u2026SN\u22121\u200b, then the\noutput will also have NNN tensors, where each tensor\nis of shape (S0,...,SN\u22121)(S_0, ..., S_{N-1})(S0\u200b,...,SN\u22121\u200b).\n", "description": "Creates grids of coordinates specified by the 1D inputs in attr:tensors."}, "torch.lcm": {"Parameters": {"input (Tensor)": "the input tensor.", "other (Tensor)": "the second input tensor"}, "description": "Computes the element-wise least common multiple (LCM) of input and other."}, "torch.logcumsumexp": {"Parameters": {"input (Tensor)": "the input tensor.", "dim (int)": "the dimension to do the operation over"}, "description": "Returns the logarithm of the cumulative summation of the exponentiation of elements of input in the dimension dim."}, "torch.ravel": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Return a contiguous flattened tensor."}, "torch.renorm": {"Parameters": {"input (Tensor)": "the input tensor.", "p (float)": "the power for the norm computation", "dim (int)": "the dimension to slice over to get the sub-tensors", "maxnorm (float)": "the maximum norm to keep each sub-tensor under"}, "description": "Returns a tensor where each sub-tensor of input along dimension dim is normalized such that the p-norm of the sub-tensor is lower than the value maxnorm"}, "torch.repeat_interleave": {"Parameters": {"input (Tensor)": "the input tensor.", "repeats (Tensor or int)": "The number of repetitions for each element.\nrepeats is broadcasted to fit the shape of the given axis.", "dim (int, optional)": "The dimension along which to repeat values.\nBy default, use the flattened input array, and return a flat output\narray."}, "Returns": "Repeated tensor which has the same shape as input, except along the given axis.\n", "description": "Repeat elements of a tensor."}, "torch.roll": {"Parameters": {"input (Tensor)": "the input tensor.", "shifts (int or tuple of python:ints)": "The number of places by which the elements\nof the tensor are shifted. If shifts is a tuple, dims must be a tuple of\nthe same size, and each dimension will be rolled by the corresponding\nvalue", "dims (int or tuple of python:ints)": "Axis along which to roll"}, "description": "Roll the tensor along the given dimension(s)."}, "torch.searchsorted": {"Parameters": {"sorted_sequence (Tensor)": "N-D or 1-D tensor, containing monotonically increasing sequence on the innermost\ndimension unless sorter is provided, in which case the sequence does not\nneed to be sorted", "values (Tensor or Scalar)": "N-D tensor or a Scalar containing the search value(s)."}, "description": "Find the indices from the innermost dimension of sorted_sequence such that, if the corresponding values in values were inserted before the indices, when sorted, the order of the corresponding innermost dimension within sorted_sequence would be preserved."}, "torch.tensordot": {"Parameters": {"a (Tensor)": "Left tensor to contract", "b (Tensor)": "Right tensor to contract", "dims (int or Tuple[List[int], List[int]] or List[List[int]] containing two lists or Tensor)": "number of dimensions to\ncontract or explicit lists of dimensions for a and\nb respectively"}, "description": "Returns a contraction of a and b over multiple dimensions."}, "torch.trace": {"description": "Returns the sum of the elements of the diagonal of the input 2-D matrix."}, "torch.tril": {"Parameters": {"input (Tensor)": "the input tensor.", "diagonal (int, optional)": "the diagonal to consider"}, "description": "Returns the lower triangular part of the matrix (2-D tensor) or batch of matrices input, the other elements of the result tensor out are set to 0."}, "torch.tril_indices": {"Parameters": {"row (int)": "number of rows in the 2-D matrix.", "col (int)": "number of columns in the 2-D matrix.", "offset (int)": "diagonal offset from the main diagonal.\nDefault: if not provided, 0."}, "description": "Returns the indices of the lower triangular part of a row-by- col matrix in a 2-by-N Tensor, where the first row contains row coordinates of all indices and the second row contains column coordinates."}, "torch.triu": {"Parameters": {"input (Tensor)": "the input tensor.", "diagonal (int, optional)": "the diagonal to consider"}, "description": "Returns the upper triangular part of a matrix (2-D tensor) or batch of matrices input, the other elements of the result tensor out are set to 0."}, "torch.triu_indices": {"Parameters": {"row (int)": "number of rows in the 2-D matrix.", "col (int)": "number of columns in the 2-D matrix.", "offset (int)": "diagonal offset from the main diagonal.\nDefault: if not provided, 0."}, "description": "Returns the indices of the upper triangular part of a row by col matrix in a 2-by-N Tensor, where the first row contains row coordinates of all indices and the second row contains column coordinates."}, "torch.vander": {"Parameters": {"x (Tensor)": "1-D input tensor.", "N (int, optional)": "Number of columns in the output. If N is not specified,\na square array is returned (N=len(x))(N = len(x))(N=len(x)).", "increasing (bool, optional)": "Order of the powers of the columns. If True,\nthe powers increase from left to right, if False (the default) they are reversed."}, "Returns": "Vandermonde matrix. If increasing is False, the first column is x(N\u22121)x^{(N-1)}x(N\u22121),\nthe second x(N\u22122)x^{(N-2)}x(N\u22122) and so forth. If increasing is True, the columns\nare x0,x1,...,x(N\u22121)x^0, x^1, ..., x^{(N-1)}x0,x1,...,x(N\u22121).\n", "description": "Generates a Vandermonde matrix."}, "torch.view_as_real": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Returns a view of input as a real tensor."}, "torch.view_as_complex": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Returns a view of input as a complex tensor."}, "torch.resolve_conj": {"Parameters": {"input (Tensor)": "the input tensor."}, "description": "Returns a new tensor with materialized conjugation if input\u2019s conjugate bit is set to True, else returns input."}, "torch.resolve_neg": {"description": "Returns a new tensor with materialized negation if input\u2019s negative bit is set to True, else returns input."}, "torch.addbmm": {"Parameters": {"batch1 (Tensor)": "the first batch of matrices to be multiplied", "batch2 (Tensor)": "the second batch of matrices to be multiplied"}, "description": "Performs a batch matrix-matrix product of matrices stored in batch1 and batch2, with a reduced add step (all matrix multiplications get accumulated along the first dimension)."}, "torch.addmm": {"Parameters": {"input (Tensor)": "matrix to be added", "mat1 (Tensor)": "the first matrix to be matrix multiplied", "mat2 (Tensor)": "the second matrix to be matrix multiplied"}, "description": "Performs a matrix multiplication of the matrices mat1 and mat2."}, "torch.addmv": {"Parameters": {"input (Tensor)": "vector to be added", "mat (Tensor)": "matrix to be matrix multiplied", "vec (Tensor)": "vector to be matrix multiplied"}, "description": "Performs a matrix-vector product of the matrix mat and the vector vec."}, "torch.addr": {"Parameters": {"input (Tensor)": "matrix to be added", "vec1 (Tensor)": "the first vector of the outer product", "vec2 (Tensor)": "the second vector of the outer product"}, "description": "Performs the outer-product of vectors vec1 and vec2 and adds it to the matrix input."}, "torch.baddbmm": {"Parameters": {"input (Tensor)": "the tensor to be added", "batch1 (Tensor)": "the first batch of matrices to be multiplied", "batch2 (Tensor)": "the second batch of matrices to be multiplied"}, "description": "Performs a batch matrix-matrix product of matrices in batch1 and batch2."}, "torch.bmm": {"Parameters": {"input (Tensor)": "the first batch of matrices to be multiplied", "mat2 (Tensor)": "the second batch of matrices to be multiplied"}, "description": "Performs a batch matrix-matrix product of matrices stored in input and mat2."}, "torch.chain_matmul": {"Parameters": {"matrices (Tensors...)": "a sequence of 2 or more 2-D tensors whose product is to be determined.", "out (Tensor, optional)": "the output tensor. Ignored if out = None."}, "Returns": "if the ithi^{th}ith tensor was of dimensions pi\u00d7pi+1p_{i} \\times p_{i + 1}pi\u200b\u00d7pi+1\u200b, then the product\nwould be of dimensions p1\u00d7pN+1p_{1} \\times p_{N + 1}p1\u200b\u00d7pN+1\u200b.\n", "description": "Returns the matrix product of the NNN 2-D tensors."}, "torch.cholesky": {"Parameters": {"input (Tensor)": "the input tensor AAA of size (\u2217,n,n)(*, n, n)(\u2217,n,n) where * is zero or more\nbatch dimensions consisting of symmetric positive-definite matrices.", "upper (bool, optional)": "flag that indicates whether to return a\nupper or lower triangular matrix. Default: False"}, "description": "Computes the Cholesky decomposition of a symmetric positive-definite matrix AAA or for batches of symmetric positive-definite matrices."}, "torch.cholesky_inverse": {"Parameters": {"input (Tensor)": "the input tensor AAA of size (\u2217,n,n)(*, n, n)(\u2217,n,n),\nconsisting of symmetric positive-definite matrices\nwhere \u2217*\u2217 is zero or more batch dimensions.", "upper (bool, optional)": "flag that indicates whether to return a\nupper or lower triangular matrix. Default: False"}, "description": "Computes the inverse of a symmetric positive-definite matrix AAA using its Cholesky factor uuu: returns matrix inv."}, "torch.cholesky_solve": {"Parameters": {"input (Tensor)": "input matrix bbb of size (\u2217,m,k)(*, m, k)(\u2217,m,k),\nwhere \u2217*\u2217 is zero or more batch dimensions", "input2 (Tensor)": "input matrix uuu of size (\u2217,m,m)(*, m, m)(\u2217,m,m),\nwhere \u2217*\u2217 is zero of more batch dimensions composed of\nupper or lower triangular Cholesky factor", "upper (bool, optional)": "whether to consider the Cholesky factor as a\nlower or upper triangular matrix. Default: False."}, "description": "Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrix uuu."}, "torch.dot": {"Parameters": {"input (Tensor)": "first tensor in the dot product, must be 1D.", "other (Tensor)": "second tensor in the dot product, must be 1D."}, "description": "Computes the dot product of two 1D tensors."}, "torch.eig": {"Parameters": {"input (Tensor)": "the square matrix of shape (n\u00d7n)(n \\times n)(n\u00d7n) for which the eigenvalues and eigenvectors\nwill be computed", "eigenvectors (bool)": "True to compute both eigenvalues and eigenvectors;\notherwise, only eigenvalues will be computed"}, "Returns": "A namedtuple (eigenvalues, eigenvectors) containing\n\n\neigenvalues (Tensor): Shape (n\u00d72)(n \\times 2)(n\u00d72). Each row is an eigenvalue of input,\nwhere the first element is the real part and the second element is the imaginary part.\nThe eigenvalues are not necessarily ordered.\neigenvectors (Tensor): If eigenvectors=False, it\u2019s an empty tensor.\nOtherwise, this tensor of shape (n\u00d7n)(n \\times n)(n\u00d7n) can be used to compute normalized (unit length)\neigenvectors of corresponding eigenvalues as follows.\nIf the corresponding eigenvalues[j] is a real number, column eigenvectors[:, j] is the eigenvector\ncorresponding to eigenvalues[j].\nIf the corresponding eigenvalues[j] and eigenvalues[j + 1] form a complex conjugate pair, then the\ntrue eigenvectors can be computed as\ntrue\u00a0eigenvector[j]=eigenvectors[:,j]+i\u00d7eigenvectors[:,j+1]\\text{true eigenvector}[j] = eigenvectors[:, j] + i \\times eigenvectors[:, j + 1]true\u00a0eigenvector[j]=eigenvectors[:,j]+i\u00d7eigenvectors[:,j+1],\ntrue\u00a0eigenvector[j+1]=eigenvectors[:,j]\u2212i\u00d7eigenvectors[:,j+1]\\text{true eigenvector}[j + 1] = eigenvectors[:, j] - i \\times eigenvectors[:, j + 1]true\u00a0eigenvector[j+1]=eigenvectors[:,j]\u2212i\u00d7eigenvectors[:,j+1].\n\n\n\n", "description": "Computes the eigenvalues and eigenvectors of a real square matrix."}, "torch.geqrf": {"Parameters": {"input (Tensor)": "the input matrix"}, "description": "This is a low-level function for calling LAPACK\u2019s geqrf directly."}, "torch.ger": {"description": "Alias of torch.outer()."}, "torch.inner": {"Parameters": {"input (Tensor)": "First input tensor", "other (Tensor)": "Second input tensor"}, "description": "Computes the dot product for 1D tensors."}, "torch.inverse": {"description": "Alias for torch.linalg.inv()"}, "torch.det": {"description": "Alias for torch.linalg.det()"}, "torch.logdet": {"Parameters": {"input (Tensor)": "the input tensor of size (*, n, n) where * is zero or more\nbatch dimensions."}, "description": "Calculates log determinant of a square matrix or batches of square matrices."}, "torch.slogdet": {"description": "Alias for torch.linalg.slogdet()"}, "torch.lstsq": {"Parameters": {"input (Tensor)": "the matrix BBB", "A (Tensor)": "the mmm by nnn matrix AAA"}, "Returns": "A namedtuple (solution, QR) containing:\n\n\nsolution (Tensor): the least squares solution\nQR (Tensor): the details of the QR factorization\n\n\n\n", "description": "Computes the solution to the least squares and least norm problems for a full rank matrix AAA of size (m\u00d7n)(m \\times n)(m\u00d7n) and a matrix BBB of size (m\u00d7k)(m \\times k)(m\u00d7k)."}, "torch.lu": {"Parameters": {"A (Tensor)": "the tensor to factor of size (\u2217,m,n)(*, m, n)(\u2217,m,n)", "pivot (bool, optional)": "controls whether pivoting is done. Default: True", "get_infos (bool, optional)": "if set to True, returns an info IntTensor.\nDefault: False", "out (tuple, optional)": "optional output tuple. If get_infos is True,\nthen the elements in the tuple are Tensor, IntTensor,\nand IntTensor. If get_infos is False, then the\nelements in the tuple are Tensor, IntTensor. Default: None"}, "Returns": "A tuple of tensors containing\n\n\nfactorization (Tensor): the factorization of size (\u2217,m,n)(*, m, n)(\u2217,m,n)\npivots (IntTensor): the pivots of size (\u2217,min(m,n))(*, \\text{min}(m, n))(\u2217,min(m,n)).\npivots stores all the intermediate transpositions of rows.\nThe final permutation perm could be reconstructed by\napplying swap(perm[i], perm[pivots[i] - 1]) for i = 0, ..., pivots.size(-1) - 1,\nwhere perm is initially the identity permutation of mmm elements\n(essentially this is what torch.lu_unpack() is doing).\ninfos (IntTensor, optional): if get_infos is True, this is a tensor of\nsize (\u2217)(*)(\u2217) where non-zero values indicate whether factorization for the matrix or\neach minibatch has succeeded or failed\n\n\n\n", "description": "Computes the LU factorization of a matrix or batches of matrices A."}, "torch.lu_solve": {"Parameters": {"b (Tensor)": "the RHS tensor of size (\u2217,m,k)(*, m, k)(\u2217,m,k), where \u2217*\u2217\nis zero or more batch dimensions.", "LU_data (Tensor)": "the pivoted LU factorization of A from torch.lu() of size (\u2217,m,m)(*, m, m)(\u2217,m,m),\nwhere \u2217*\u2217 is zero or more batch dimensions.", "LU_pivots (IntTensor)": "the pivots of the LU factorization from torch.lu() of size (\u2217,m)(*, m)(\u2217,m),\nwhere \u2217*\u2217 is zero or more batch dimensions.\nThe batch dimensions of LU_pivots must be equal to the batch dimensions of\nLU_data."}, "description": "Returns the LU solve of the linear system Ax=bAx = bAx=b using the partially pivoted LU factorization of A from torch.lu()."}, "torch.lu_unpack": {"Parameters": {"LU_data (Tensor)": "the packed LU factorization data", "LU_pivots (Tensor)": "the packed LU factorization pivots", "unpack_data (bool)": "flag indicating if the data should be unpacked.\nIf False, then the returned L and U are None.\nDefault: True", "unpack_pivots (bool)": "flag indicating if the pivots should be unpacked into a permutation matrix P.\nIf False, then the returned P is  None.\nDefault: True", "out (tuple, optional)": "a tuple of three tensors to use for the outputs (P, L, U)."}, "description": "Unpacks the data and pivots from a LU factorization of a tensor into tensors L and U and a permutation tensor P such that LU_data, LU_pivots = (P @ L @ U).lu()."}, "torch.matmul": {"Parameters": {"input (Tensor)": "the first tensor to be multiplied", "other (Tensor)": "the second tensor to be multiplied"}, "description": "Matrix product of two tensors."}, "torch.matrix_power": {"description": "Alias for torch.linalg.matrix_power()"}, "torch.matrix_rank": {"Parameters": {"input (Tensor)": "the input 2-D tensor", "tol (float, optional)": "the tolerance value. Default: None", "symmetric (bool, optional)": "indicates whether input is symmetric.\nDefault: False"}, "description": "Returns the numerical rank of a 2-D tensor."}, "torch.matrix_exp": {"description": "Alias for torch.linalg.matrix_exp()."}, "torch.mm": {"Parameters": {"input (Tensor)": "the first matrix to be matrix multiplied", "mat2 (Tensor)": "the second matrix to be matrix multiplied"}, "description": "Performs a matrix multiplication of the matrices input and mat2."}, "torch.mv": {"Parameters": {"input (Tensor)": "matrix to be multiplied", "vec (Tensor)": "vector to be multiplied"}, "description": "Performs a matrix-vector product of the matrix input and the vector vec."}, "torch.orgqr": {"description": "Alias for torch.linalg.householder_product()."}, "torch.ormqr": {"Parameters": {"input (Tensor)": "tensor of shape (*, mn, k) where * is zero or more batch dimensions\nand mn equals to m or n depending on the left.", "tau (Tensor)": "tensor of shape (*, min(mn, k)) where * is zero or more batch dimensions.", "other (Tensor)": "tensor of shape (*, m, n) where * is zero or more batch dimensions.", "left (bool)": "controls the order of multiplication.", "transpose (bool)": "controls whether the matrix Q is conjugate transposed or not."}, "description": "Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix."}, "torch.outer": {"Parameters": {"input (Tensor)": "1-D input vector", "vec2 (Tensor)": "1-D input vector"}, "description": "Outer product of input and vec2."}, "torch.pinverse": {"description": "Alias for torch.linalg.pinv()"}, "torch.qr": {"Parameters": {"input (Tensor)": "the input tensor of size (\u2217,m,n)(*, m, n)(\u2217,m,n) where * is zero or more\nbatch dimensions consisting of matrices of dimension m\u00d7nm \\times nm\u00d7n.", "some (bool, optional)": "Set to True for reduced QR decomposition and False for\ncomplete QR decomposition. If k = min(m, n) then:\n\n\nsome=True : returns (Q, R) with dimensions (m, k), (k, n) (default)\n'some=False': returns (Q, R) with dimensions (m, m), (m, n)"}, "description": "Computes the QR decomposition of a matrix or a batch of matrices input, and returns a namedtuple (Q, R) of tensors such that input=QR\\text{input} = Q Rinput=QR with QQQ being an orthogonal matrix or batch of orthogonal matrices and RRR being an upper triangular matrix or batch of upper triangular matrices."}, "torch.solve": {"Parameters": {"input (Tensor)": "input matrix BBB of size (\u2217,m,k)(*, m, k)(\u2217,m,k) , where \u2217*\u2217\nis zero or more batch dimensions.", "A (Tensor)": "input square matrix of size (\u2217,m,m)(*, m, m)(\u2217,m,m), where\n\u2217*\u2217 is zero or more batch dimensions."}, "description": "This function returns the solution to the system of linear equations represented by AX=BAX = BAX=B and the LU factorization of A, in order as a namedtuple solution, LU."}, "torch.svd": {"Parameters": {"input (Tensor)": "the input tensor of size (*, m, n) where * is zero or more\nbatch dimensions consisting of (m, n) matrices.", "some (bool, optional)": "controls whether to compute the reduced or full decomposition, and\nconsequently, the shape of returned U and V. Default: True.", "compute_uv (bool, optional)": "controls whether to compute U and V. Default: True."}, "description": "Computes the singular value decomposition of either a matrix or batch of matrices input."}, "torch.svd_lowrank": {"description": "Return the singular value decomposition (U, S, V) of a matrix, batches of matrices, or a sparse matrix AAA such that A\u2248Udiag(S)VTA \\approx U diag(S) V^TA\u2248Udiag(S)VT."}, "torch.pca_lowrank": {"Parameters": {"A (Tensor)": "the input tensor of size (\u2217,m,n)(*, m, n)(\u2217,m,n)", "q (int, optional)": "a slightly overestimated rank of\nAAA. By default, q = min(6, m,\nn).", "center (bool, optional)": "if True, center the input tensor,\notherwise, assume that the input is\ncentered.", "niter (int, optional)": "the number of subspace iterations to\nconduct; niter must be a nonnegative\ninteger, and defaults to 2."}, "description": "Performs linear Principal Component Analysis (PCA) on a low-rank matrix, batches of such matrices, or sparse matrix."}, "torch.symeig": {"Parameters": {"input (Tensor)": "the input tensor of size (\u2217,n,n)(*, n, n)(\u2217,n,n) where * is zero or more\nbatch dimensions consisting of symmetric or Hermitian matrices.", "eigenvectors (bool, optional)": "controls whether eigenvectors have to be computed", "upper (boolean, optional)": "controls whether to consider upper-triangular or lower-triangular region"}, "Returns": "A namedtuple (eigenvalues, eigenvectors) containing\n\n\neigenvalues (Tensor): Shape (\u2217,m)(*, m)(\u2217,m). The eigenvalues in ascending order.\neigenvectors (Tensor): Shape (\u2217,m,m)(*, m, m)(\u2217,m,m).\nIf eigenvectors=False, it\u2019s an empty tensor.\nOtherwise, this tensor contains the orthonormal eigenvectors of the input.\n\n\n\n", "description": "This function returns eigenvalues and eigenvectors of a real symmetric or complex Hermitian matrix input or a batch thereof, represented by a namedtuple (eigenvalues, eigenvectors)."}, "torch.lobpcg": {"Parameters": {"A (Tensor)": "the input tensor of size (\u2217,m,m)(*, m, m)(\u2217,m,m)", "B (Tensor, optional)": "the input tensor of size (\u2217,m,m)(*, m,\nm)(\u2217,m,m). When not specified, B is interpereted as\nidentity matrix.", "X (tensor, optional)": "the input tensor of size (\u2217,m,n)(*, m, n)(\u2217,m,n)\nwhere k <= n <= m. When specified, it is used as\ninitial approximation of eigenvectors. X must be a\ndense tensor.", "iK (tensor, optional)": "the input tensor of size (\u2217,m,m)(*, m,\nm)(\u2217,m,m). When specified, it will be used as preconditioner.", "k (integer, optional)": "the number of requested\neigenpairs. Default is the number of XXX\ncolumns (when specified) or 1.", "n (integer, optional)": "if XXX is not specified then n\nspecifies the size of the generated random\napproximation of eigenvectors. Default value for n\nis k. If XXX is specified, the value of n\n(when specified) must be the number of XXX\ncolumns.", "tol (float, optional)": "residual tolerance for stopping\ncriterion. Default is feps ** 0.5 where feps is\nsmallest non-zero floating-point number of the given\ninput tensor A data type.", "largest (bool, optional)": "when True, solve the eigenproblem for\nthe largest eigenvalues. Otherwise, solve the\neigenproblem for smallest eigenvalues. Default is\nTrue.", "method (str, optional)": "select LOBPCG method. See the\ndescription of the function above. Default is\n\u201cortho\u201d.", "niter (int, optional)": "maximum number of iterations. When\nreached, the iteration process is hard-stopped and\nthe current approximation of eigenpairs is returned.\nFor infinite iteration but until convergence criteria\nis met, use -1.", "tracker (callable, optional)": "a function for tracing the\niteration process. When specified, it is called at\neach iteration step with LOBPCG instance as an\nargument. The LOBPCG instance holds the full state of\nthe iteration process in the following attributes:\n\niparams, fparams, bparams - dictionaries of\ninteger, float, and boolean valued input\nparameters, respectively\nivars, fvars, bvars, tvars - dictionaries\nof integer, float, boolean, and Tensor valued\niteration variables, respectively.\nA, B, iK - input Tensor arguments.\nE, X, S, R - iteration Tensor variables.\n\nFor instance:\n\nivars[\u201cistep\u201d] - the current iteration step\nX - the current approximation of eigenvectors\nE - the current approximation of eigenvalues\nR - the current residual\nivars[\u201cconverged_count\u201d] - the current number of converged eigenpairs\ntvars[\u201crerr\u201d] - the current state of convergence criteria\n\nNote that when tracker stores Tensor objects from\nthe LOBPCG instance, it must make copies of these.\nIf tracker sets bvars[\u201cforce_stop\u201d] = True, the\niteration process will be hard-stopped.", "ortho_iparams (dict, optional)": "various parameters to LOBPCG algorithm when using\nmethod=\u201dortho\u201d.", "ortho_fparams (dict, optional)": "various parameters to LOBPCG algorithm when using\nmethod=\u201dortho\u201d.", "ortho_bparams (dict, optional)": "various parameters to LOBPCG algorithm when using\nmethod=\u201dortho\u201d."}, "Returns": "tensor of eigenvalues of size (\u2217,k)(*, k)(\u2217,k)\nX (Tensor): tensor of eigenvectors of size (\u2217,m,k)(*, m, k)(\u2217,m,k)\n\n", "description": "Find the k largest (or smallest) eigenvalues and the corresponding eigenvectors of a symmetric positive definite generalized eigenvalue problem using matrix-free LOBPCG methods."}, "torch.trapz": {"description": "Alias for torch.trapezoid()."}, "torch.trapezoid": {"Parameters": {"y (Tensor)": "Values to use when computing the trapezoidal rule.", "x (Tensor)": "If specified, defines spacing between values as specified above."}, "description": "Computes the trapezoidal rule along dim."}, "torch.cumulative_trapezoid": {"Parameters": {"y (Tensor)": "Values to use when computing the trapezoidal rule.", "x (Tensor)": "If specified, defines spacing between values as specified above."}, "description": "Cumulatively computes the trapezoidal rule along dim.\n"}, "torch.triangular_solve": {"Parameters": {"b (Tensor)": "multiple right-hand sides of size (\u2217,m,k)(*, m, k)(\u2217,m,k) where\n\u2217*\u2217 is zero of more batch dimensions", "A (Tensor)": "the input triangular coefficient matrix of size (\u2217,m,m)(*, m, m)(\u2217,m,m)\nwhere \u2217*\u2217 is zero or more batch dimensions", "upper (bool, optional)": "whether AAA is upper or lower triangular. Default: True.", "transpose (bool, optional)": "solves op(A)X = b where op(A) = A^T if this flag is True,\nand op(A) = A if it is False. Default: False.", "unitriangular (bool, optional)": "whether AAA is unit triangular.\nIf True, the diagonal elements of AAA are assumed to be\n1 and not referenced from AAA. Default: False."}, "Returns": "A namedtuple (solution, cloned_coefficient) where cloned_coefficient\nis a clone of AAA and solution is the solution XXX to AX=bAX = bAX=b\n(or whatever variant of the system of equations, depending on the keyword arguments.)\n", "description": "Solves a system of equations with a square upper or lower triangular invertible matrix AAA and multiple right-hand sides bbb."}, "torch.vdot": {"Parameters": {"input (Tensor)": "first tensor in the dot product, must be 1D. Its conjugate is used if it\u2019s complex.", "other (Tensor)": "second tensor in the dot product, must be 1D."}, "description": "Computes the dot product of two 1D tensors."}, "torch.compiled_with_cxx11_abi": {"description": "Returns whether PyTorch was built with _GLIBCXX_USE_CXX11_ABI=1"}, "torch.result_type": {"Parameters": {"tensor1 (Tensor or Number)": "an input tensor or number", "tensor2 (Tensor or Number)": "an input tensor or number"}, "description": "Returns the torch.dtype that would result from performing an arithmetic operation on the provided input tensors."}, "torch.can_cast": {"Parameters": {"from (dpython:type)": "The original torch.dtype.", "to (dpython:type)": "The target torch.dtype."}, "description": "Determines if a type conversion is allowed under PyTorch casting rules described in the type promotion documentation."}, "torch.promote_types": {"Parameters": {"type1 (torch.dtype)": "", "type2 (torch.dtype)": ""}, "description": "Returns the torch.dtype with the smallest size and scalar kind that is not smaller nor of lower kind than either type1 or type2."}, "torch.use_deterministic_algorithms": {"Parameters": {"mode (bool)": "If True, makes potentially nondeterministic\noperations switch to a deterministic algorithm or throw a runtime\nerror. If False, allows nondeterministic operations."}, "description": "Sets whether PyTorch operations must use \u201cdeterministic\u201d algorithms."}, "torch.are_deterministic_algorithms_enabled": {"description": "Returns True if the global deterministic flag is turned on."}, "torch.is_deterministic_algorithms_warn_only_enabled": {"description": "Returns True if the global deterministic flag is set to warn only."}, "torch.set_deterministic_debug_mode": {"Parameters": {"debug_mode (str or int)": "If \u201cdefault\u201d or 0, don\u2019t error or warn on\nnondeterministic operations. If \u201cwarn\u201d or 1, warn on\nnondeterministic operations. If \u201cerror\u201d or 2, error on\nnondeterministic operations."}, "description": "Sets the debug mode for deterministic operations."}, "torch.get_deterministic_debug_mode": {"description": "Returns the current value of the debug mode for deterministic operations."}, "torch.set_warn_always": {"Parameters": {"b (bool)": "If True, force warnings to always be emitted\nIf False, set to the default behaviour"}, "description": "When this flag is False (default) then some PyTorch warnings may only appear once per process."}, "torch.is_warn_always_enabled": {"description": "Returns True if the global warn_always flag is turned on."}, "torch._assert": {"description": "A wrapper around Python\u2019s assert which is symbolically traceable."}, "torch.nn.parameter.Parameter": {"Parameters": {"data (Tensor)": "parameter tensor.", "requires_grad (bool, optional)": "if the parameter requires gradient. See\nLocally disabling gradient computation for more details. Default: True"}, "description": "A kind of Tensor that is to be considered a module parameter."}, "torch.nn.parameter.UninitializedParameter": {"description": "A parameter that is not initialized."}, "torch.nn.parameter.UninitializedBuffer": {"description": "A buffer that is not initialized."}, "torch.nn.Module": {"method": {"torch.nn.Module.add_module": {"Parameters": {"name (string)": "name of the child module. The child module can be\naccessed from this module using the given name", "module (Module)": "child module to be added to the module."}, "description": "Adds a child module to the current module."}, "torch.nn.Module.apply": {"Parameters": {"fn (Module -> None)": "function to be applied to each submodule"}, "Returns": "self\n", "description": null}, "torch.nn.Module.bfloat16": {"Returns": "self\n", "description": null}, "torch.nn.Module.buffers": {"Parameters": {"recurse (bool)": "if True, then yields buffers of this module\nand all submodules. Otherwise, yields only buffers that\nare direct members of this module."}, "description": "Returns an iterator over module buffers."}, "torch.nn.Module.children": {"description": "Returns an iterator over immediate children modules."}, "torch.nn.Module.cpu": {"Returns": "self\n", "description": "Moves all model parameters and buffers to the CPU."}, "torch.nn.Module.cuda": {"Parameters": {"device (int, optional)": "if specified, all parameters will be\ncopied to that device"}, "Returns": "self\n", "description": "Moves all model parameters and buffers to the GPU."}, "torch.nn.Module.double": {"Returns": "self\n", "description": null}, "torch.nn.Module.eval": {"Returns": "self\n", "description": "Sets the module in evaluation mode."}, "torch.nn.Module.float": {"Returns": "self\n", "description": null}, "torch.nn.Module.get_buffer": {"Parameters": {"target": "The fully-qualified string name of the buffer\nto look for. (See get_submodule for how to specify a\nfully-qualified string.)"}, "Returns": "The buffer referenced by target\n", "description": null}, "torch.nn.Module.get_extra_state": {"Returns": "Any extra state to store in the module\u2019s state_dict\n", "description": null}, "torch.nn.Module.get_parameter": {"Parameters": {"target": "The fully-qualified string name of the Parameter\nto look for. (See get_submodule for how to specify a\nfully-qualified string.)"}, "Returns": "The Parameter referenced by target\n", "description": null}, "torch.nn.Module.get_submodule": {"Parameters": {"target": "The fully-qualified string name of the submodule\nto look for. (See above example for how to specify a\nfully-qualified string.)"}, "Returns": "The submodule referenced by target\n", "description": null}, "torch.nn.Module.half": {"Returns": "self\n", "description": null}, "torch.nn.Module.load_state_dict": {"Parameters": {"state_dict (dict)": "a dict containing parameters and\npersistent buffers.", "strict (bool, optional)": "whether to strictly enforce that the keys\nin state_dict match the keys returned by this module\u2019s\nstate_dict() function. Default: True"}, "Returns": "\nmissing_keys is a list of str containing the missing keys\nunexpected_keys is a list of str containing the unexpected keys\n\n\n", "description": null}, "torch.nn.Module.modules": {"description": "Returns an iterator over all modules in the network."}, "torch.nn.Module.named_buffers": {"Parameters": {"prefix (str)": "prefix to prepend to all buffer names.", "recurse (bool)": "if True, then yields buffers of this module\nand all submodules. Otherwise, yields only buffers that\nare direct members of this module."}, "description": "Returns an iterator over module buffers, yielding both the\nname of the buffer as well as the buffer itself."}, "torch.nn.Module.named_children": {"description": "Returns an iterator over immediate children modules, yielding both\nthe name of the module as well as the module itself."}, "torch.nn.Module.named_modules": {"Parameters": {"memo": "a memo to store the set of modules already added to the result", "prefix": "a prefix that will be added to the name of the module", "remove_duplicate": "whether to remove the duplicated module instances in the result\nor not"}, "description": "Returns an iterator over all modules in the network, yielding\nboth the name of the module as well as the module itself."}, "torch.nn.Module.named_parameters": {"Parameters": {"prefix (str)": "prefix to prepend to all parameter names.", "recurse (bool)": "if True, then yields parameters of this module\nand all submodules. Otherwise, yields only parameters that\nare direct members of this module."}, "description": "Returns an iterator over module parameters, yielding both the\nname of the parameter as well as the parameter itself."}, "torch.nn.Module.parameters": {"Parameters": {"recurse (bool)": "if True, then yields parameters of this module\nand all submodules. Otherwise, yields only parameters that\nare direct members of this module."}, "description": "Returns an iterator over module parameters."}, "torch.nn.Module.register_backward_hook": {"Returns": "a handle that can be used to remove the added hook by calling\nhandle.remove()\n", "description": "Registers a backward hook on the module."}, "torch.nn.Module.register_buffer": {"Parameters": {"name (string)": "name of the buffer. The buffer can be accessed\nfrom this module using the given name", "tensor (Tensor or None)": "buffer to be registered. If None, then operations\nthat run on buffers, such as cuda, are ignored. If None,\nthe buffer is not included in the module\u2019s state_dict.", "persistent (bool)": "whether the buffer is part of this module\u2019s\nstate_dict."}, "description": "Adds a buffer to the module."}, "torch.nn.Module.register_forward_hook": {"Returns": "a handle that can be used to remove the added hook by calling\nhandle.remove()\n", "description": "Registers a forward hook on the module."}, "torch.nn.Module.register_forward_pre_hook": {"Returns": "a handle that can be used to remove the added hook by calling\nhandle.remove()\n", "description": "Registers a forward pre-hook on the module."}, "torch.nn.Module.register_full_backward_hook": {"Returns": "a handle that can be used to remove the added hook by calling\nhandle.remove()\n", "description": "Registers a backward hook on the module."}, "torch.nn.Module.register_parameter": {"Parameters": {"name (string)": "name of the parameter. The parameter can be accessed\nfrom this module using the given name", "param (Parameter or None)": "parameter to be added to the module. If\nNone, then operations that run on parameters, such as cuda,\nare ignored. If None, the parameter is not included in the\nmodule\u2019s state_dict."}, "description": "Adds a parameter to the module."}, "torch.nn.Module.requires_grad_": {"Parameters": {"requires_grad (bool)": "whether autograd should record operations on\nparameters in this module. Default: True."}, "Returns": "self\n", "description": "Change if autograd should record operations on parameters in this\nmodule."}, "torch.nn.Module.set_extra_state": {"Parameters": {"state (dict)": "Extra state from the state_dict"}, "description": null}, "torch.nn.Module.state_dict": {"Returns": "a dictionary containing a whole state of the module\n", "description": "Returns a dictionary containing a whole state of the module."}, "torch.nn.Module.to": {"Parameters": {"device (torch.device)": "the desired device of the parameters\nand buffers in this module", "dtype (torch.dtype)": "the desired floating point or complex dtype of\nthe parameters and buffers in this module", "tensor (torch.Tensor)": "Tensor whose dtype and device are the desired\ndtype and device for all parameters and buffers in this module", "memory_format (torch.memory_format)": "the desired memory\nformat for 4D parameters and buffers in this module (keyword\nonly argument)"}, "Returns": "self\n", "description": "Moves and/or casts the parameters and buffers."}, "torch.nn.Module.to_empty": {"Parameters": {"device (torch.device)": "The desired device of the parameters\nand buffers in this module."}, "Returns": "self\n", "description": "Moves the parameters and buffers to the specified device without copying storage."}, "torch.nn.Module.train": {"Parameters": {"mode (bool)": "whether to set training mode (True) or evaluation\nmode (False). Default: True."}, "Returns": "self\n", "description": "Sets the module in training mode."}, "torch.nn.Module.type": {"Parameters": {"dst_type (type or string)": "the desired type"}, "Returns": "self\n", "description": null}, "torch.nn.Module.xpu": {"Parameters": {"device (int, optional)": "if specified, all parameters will be\ncopied to that device"}, "Returns": "self\n", "description": "Moves all model parameters and buffers to the XPU."}, "torch.nn.Module.zero_grad": {"Parameters": {"set_to_none (bool)": "instead of setting to zero, set the grads to None.\nSee torch.optim.Optimizer.zero_grad() for details."}, "description": null}}, "description": "Base class for all neural network modules."}, "torch.nn.Sequential": {"method": {"torch.nn.Sequential.append": {"Parameters": {"module (nn.Module)": "module to append"}, "description": "Appends a given module to the end."}}, "description": "A sequential container."}, "torch.nn.ModuleList": {"Parameters": {"modules (iterable, optional)": "an iterable of modules to add"}, "method": {"torch.nn.ModuleList.append": {"Parameters": {"module (nn.Module)": "module to append"}, "description": "Appends a given module to the end of the list."}, "torch.nn.ModuleList.extend": {"Parameters": {"modules (iterable)": "iterable of modules to append"}, "description": "Appends modules from a Python iterable to the end of the list."}, "torch.nn.ModuleList.insert": {"Parameters": {"index (int)": "index to insert.", "module (nn.Module)": "module to insert"}, "description": "Insert a given module before a given index in the list."}}, "description": "Holds submodules in a list."}, "torch.nn.ModuleDict": {"Parameters": {"modules (iterable, optional)": "a mapping (dictionary) of (string: module)\nor an iterable of key-value pairs of type (string, module)"}, "method": {"torch.nn.ModuleDict.pop": {"Parameters": {"key (string)": "key to pop from the ModuleDict"}, "description": "Remove key from the ModuleDict and return its module."}, "torch.nn.ModuleDict.update": {"Parameters": {"modules (iterable)": "a mapping (dictionary) from string to Module,\nor an iterable of key-value pairs of type (string, Module)"}, "description": null}}, "description": "Holds submodules in a dictionary."}, "torch.nn.ParameterList": {"Parameters": {"parameters (iterable, optional)": "an iterable of Parameter to add"}, "method": {"torch.nn.ParameterList.append": {"Parameters": {"parameter (nn.Parameter)": "parameter to append"}, "description": "Appends a given parameter at the end of the list."}, "torch.nn.ParameterList.extend": {"Parameters": {"parameters (iterable)": "iterable of parameters to append"}, "description": "Appends parameters from a Python iterable to the end of the list."}}, "description": "Holds parameters in a list."}, "torch.nn.ParameterDict": {"Parameters": {"parameters (iterable, optional)": "a mapping (dictionary) of\n(string : Parameter) or an iterable of key-value pairs\nof type (string, Parameter)"}, "method": {"torch.nn.ParameterDict.fromkeys": {"Parameters": {"keys (iterable, string)": "keys to make the new ParameterDict from", "default (Parameter, optional)": "value to set for all keys"}, "description": "Return a new ParameterDict with the keys provided"}, "torch.nn.ParameterDict.get": {"Parameters": {"key (string)": "key to get from the ParameterDict", "default (Parameter, optional)": "value to return if key not present"}, "description": "Return the parameter associated with key if present.\nOtherwise return default if provided, None if not."}, "torch.nn.ParameterDict.pop": {"Parameters": {"key (string)": "key to pop from the ParameterDict"}, "description": "Remove key from the ParameterDict and return its parameter."}, "torch.nn.ParameterDict.setdefault": {"Parameters": {"key (string)": "key to set default for", "default (Parameter)": "the parameter set to the key"}, "description": null}, "torch.nn.ParameterDict.update": {"Parameters": {"parameters (iterable)": "a mapping (dictionary) from string to\nParameter, or an iterable of\nkey-value pairs of type (string, Parameter)"}, "description": null}}, "description": "Holds parameters in a dictionary."}, "torch.nn.modules.module.register_module_forward_pre_hook": {"Returns": "a handle that can be used to remove the added hook by calling\nhandle.remove()\n", "description": "Registers a forward pre-hook common to all modules."}, "torch.nn.modules.module.register_module_forward_hook": {"Returns": "a handle that can be used to remove the added hook by calling\nhandle.remove()\n", "description": "Registers a global forward hook for all the modules"}, "torch.nn.modules.module.register_module_backward_hook": {"Returns": "a handle that can be used to remove the added hook by calling\nhandle.remove()\n", "description": "Registers a backward hook common to all the modules."}, "torch.nn.modules.module.register_module_full_backward_hook": {"Returns": "a handle that can be used to remove the added hook by calling\nhandle.remove()\n", "description": "Registers a backward hook common to all the modules."}, "torch.nn.Conv1d": {"Parameters": {"in_channels (int)": "Number of channels in the input image", "out_channels (int)": "Number of channels produced by the convolution", "kernel_size (int or tuple)": "Size of the convolving kernel", "stride (int or tuple, optional)": "Stride of the convolution. Default: 1", "padding (int, tuple or str, optional)": "Padding added to both sides of\nthe input. Default: 0", "padding_mode (string, optional)": "'zeros', 'reflect',\n'replicate' or 'circular'. Default: 'zeros'", "dilation (int or tuple, optional)": "Spacing between kernel\nelements. Default: 1", "groups (int, optional)": "Number of blocked connections from input\nchannels to output channels. Default: 1", "bias (bool, optional)": "If True, adds a learnable bias to the\noutput. Default: True"}, "description": "Applies a 1D convolution over an input signal composed of several input planes."}, "torch.nn.Conv2d": {"Parameters": {"in_channels (int)": "Number of channels in the input image", "out_channels (int)": "Number of channels produced by the convolution", "kernel_size (int or tuple)": "Size of the convolving kernel", "stride (int or tuple, optional)": "Stride of the convolution. Default: 1", "padding (int, tuple or str, optional)": "Padding added to all four sides of\nthe input. Default: 0", "padding_mode (string, optional)": "'zeros', 'reflect',\n'replicate' or 'circular'. Default: 'zeros'", "dilation (int or tuple, optional)": "Spacing between kernel elements. Default: 1", "groups (int, optional)": "Number of blocked connections from input\nchannels to output channels. Default: 1", "bias (bool, optional)": "If True, adds a learnable bias to the\noutput. Default: True"}, "description": "Applies a 2D convolution over an input signal composed of several input planes."}, "torch.nn.Conv3d": {"Parameters": {"in_channels (int)": "Number of channels in the input image", "out_channels (int)": "Number of channels produced by the convolution", "kernel_size (int or tuple)": "Size of the convolving kernel", "stride (int or tuple, optional)": "Stride of the convolution. Default: 1", "padding (int, tuple or str, optional)": "Padding added to all six sides of\nthe input. Default: 0", "padding_mode (string, optional)": "'zeros', 'reflect', 'replicate' or 'circular'. Default: 'zeros'", "dilation (int or tuple, optional)": "Spacing between kernel elements. Default: 1", "groups (int, optional)": "Number of blocked connections from input channels to output channels. Default: 1", "bias (bool, optional)": "If True, adds a learnable bias to the output. Default: True"}, "description": "Applies a 3D convolution over an input signal composed of several input planes."}, "torch.nn.ConvTranspose1d": {"Parameters": {"in_channels (int)": "Number of channels in the input image", "out_channels (int)": "Number of channels produced by the convolution", "kernel_size (int or tuple)": "Size of the convolving kernel", "stride (int or tuple, optional)": "Stride of the convolution. Default: 1", "padding (int or tuple, optional)": "dilation * (kernel_size - 1) - padding zero-padding\nwill be added to both sides of the input. Default: 0", "output_padding (int or tuple, optional)": "Additional size added to one side\nof the output shape. Default: 0", "groups (int, optional)": "Number of blocked connections from input channels to output channels. Default: 1", "bias (bool, optional)": "If True, adds a learnable bias to the output. Default: True", "dilation (int or tuple, optional)": "Spacing between kernel elements. Default: 1"}, "description": "Applies a 1D transposed convolution operator over an input image composed of several input planes."}, "torch.nn.ConvTranspose2d": {"Parameters": {"in_channels (int)": "Number of channels in the input image", "out_channels (int)": "Number of channels produced by the convolution", "kernel_size (int or tuple)": "Size of the convolving kernel", "stride (int or tuple, optional)": "Stride of the convolution. Default: 1", "padding (int or tuple, optional)": "dilation * (kernel_size - 1) - padding zero-padding\nwill be added to both sides of each dimension in the input. Default: 0", "output_padding (int or tuple, optional)": "Additional size added to one side\nof each dimension in the output shape. Default: 0", "groups (int, optional)": "Number of blocked connections from input channels to output channels. Default: 1", "bias (bool, optional)": "If True, adds a learnable bias to the output. Default: True", "dilation (int or tuple, optional)": "Spacing between kernel elements. Default: 1"}, "description": "Applies a 2D transposed convolution operator over an input image composed of several input planes."}, "torch.nn.ConvTranspose3d": {"Parameters": {"in_channels (int)": "Number of channels in the input image", "out_channels (int)": "Number of channels produced by the convolution", "kernel_size (int or tuple)": "Size of the convolving kernel", "stride (int or tuple, optional)": "Stride of the convolution. Default: 1", "padding (int or tuple, optional)": "dilation * (kernel_size - 1) - padding zero-padding\nwill be added to both sides of each dimension in the input. Default: 0", "output_padding (int or tuple, optional)": "Additional size added to one side\nof each dimension in the output shape. Default: 0", "groups (int, optional)": "Number of blocked connections from input channels to output channels. Default: 1", "bias (bool, optional)": "If True, adds a learnable bias to the output. Default: True", "dilation (int or tuple, optional)": "Spacing between kernel elements. Default: 1"}, "description": "Applies a 3D transposed convolution operator over an input image composed of several input planes."}, "torch.nn.LazyConv1d": {"Parameters": {"out_channels (int)": "Number of channels produced by the convolution", "kernel_size (int or tuple)": "Size of the convolving kernel", "stride (int or tuple, optional)": "Stride of the convolution. Default: 1", "padding (int or tuple, optional)": "Zero-padding added to both sides of\nthe input. Default: 0", "padding_mode (string, optional)": "'zeros', 'reflect',\n'replicate' or 'circular'. Default: 'zeros'", "dilation (int or tuple, optional)": "Spacing between kernel\nelements. Default: 1", "groups (int, optional)": "Number of blocked connections from input\nchannels to output channels. Default: 1", "bias (bool, optional)": "If True, adds a learnable bias to the\noutput. Default: True"}, "description": "A torch.nn.Conv1d module with lazy initialization of the in_channels argument of the Conv1d that is inferred from the input.size(1)."}, "torch.nn.LazyConv2d": {"Parameters": {"out_channels (int)": "Number of channels produced by the convolution", "kernel_size (int or tuple)": "Size of the convolving kernel", "stride (int or tuple, optional)": "Stride of the convolution. Default: 1", "padding (int or tuple, optional)": "Zero-padding added to both sides of\nthe input. Default: 0", "padding_mode (string, optional)": "'zeros', 'reflect',\n'replicate' or 'circular'. Default: 'zeros'", "dilation (int or tuple, optional)": "Spacing between kernel\nelements. Default: 1", "groups (int, optional)": "Number of blocked connections from input\nchannels to output channels. Default: 1", "bias (bool, optional)": "If True, adds a learnable bias to the\noutput. Default: True"}, "description": "A torch.nn.Conv2d module with lazy initialization of the in_channels argument of the Conv2d that is inferred from the input.size(1)."}, "torch.nn.LazyConv3d": {"Parameters": {"out_channels (int)": "Number of channels produced by the convolution", "kernel_size (int or tuple)": "Size of the convolving kernel", "stride (int or tuple, optional)": "Stride of the convolution. Default: 1", "padding (int or tuple, optional)": "Zero-padding added to both sides of\nthe input. Default: 0", "padding_mode (string, optional)": "'zeros', 'reflect',\n'replicate' or 'circular'. Default: 'zeros'", "dilation (int or tuple, optional)": "Spacing between kernel\nelements. Default: 1", "groups (int, optional)": "Number of blocked connections from input\nchannels to output channels. Default: 1", "bias (bool, optional)": "If True, adds a learnable bias to the\noutput. Default: True"}, "description": "A torch.nn.Conv3d module with lazy initialization of the in_channels argument of the Conv3d that is inferred from the input.size(1)."}, "torch.nn.LazyConvTranspose1d": {"Parameters": {"out_channels (int)": "Number of channels produced by the convolution", "kernel_size (int or tuple)": "Size of the convolving kernel", "stride (int or tuple, optional)": "Stride of the convolution. Default: 1", "padding (int or tuple, optional)": "dilation * (kernel_size - 1) - padding zero-padding\nwill be added to both sides of the input. Default: 0", "output_padding (int or tuple, optional)": "Additional size added to one side\nof the output shape. Default: 0", "groups (int, optional)": "Number of blocked connections from input channels to output channels. Default: 1", "bias (bool, optional)": "If True, adds a learnable bias to the output. Default: True", "dilation (int or tuple, optional)": "Spacing between kernel elements. Default: 1"}, "description": "A torch.nn.ConvTranspose1d module with lazy initialization of the in_channels argument of the ConvTranspose1d that is inferred from the input.size(1)."}, "torch.nn.LazyConvTranspose2d": {"Parameters": {"out_channels (int)": "Number of channels produced by the convolution", "kernel_size (int or tuple)": "Size of the convolving kernel", "stride (int or tuple, optional)": "Stride of the convolution. Default: 1", "padding (int or tuple, optional)": "dilation * (kernel_size - 1) - padding zero-padding\nwill be added to both sides of each dimension in the input. Default: 0", "output_padding (int or tuple, optional)": "Additional size added to one side\nof each dimension in the output shape. Default: 0", "groups (int, optional)": "Number of blocked connections from input channels to output channels. Default: 1", "bias (bool, optional)": "If True, adds a learnable bias to the output. Default: True", "dilation (int or tuple, optional)": "Spacing between kernel elements. Default: 1"}, "description": "A torch.nn.ConvTranspose2d module with lazy initialization of the in_channels argument of the ConvTranspose2d that is inferred from the input.size(1)."}, "torch.nn.LazyConvTranspose3d": {"Parameters": {"out_channels (int)": "Number of channels produced by the convolution", "kernel_size (int or tuple)": "Size of the convolving kernel", "stride (int or tuple, optional)": "Stride of the convolution. Default: 1", "padding (int or tuple, optional)": "dilation * (kernel_size - 1) - padding zero-padding\nwill be added to both sides of each dimension in the input. Default: 0", "output_padding (int or tuple, optional)": "Additional size added to one side\nof each dimension in the output shape. Default: 0", "groups (int, optional)": "Number of blocked connections from input channels to output channels. Default: 1", "bias (bool, optional)": "If True, adds a learnable bias to the output. Default: True", "dilation (int or tuple, optional)": "Spacing between kernel elements. Default: 1"}, "description": "A torch.nn.ConvTranspose3d module with lazy initialization of the in_channels argument of the ConvTranspose3d that is inferred from the input.size(1)."}, "torch.nn.Unfold": {"Parameters": {"kernel_size (int or tuple)": "the size of the sliding blocks", "stride (int or tuple, optional)": "the stride of the sliding blocks in the input\nspatial dimensions. Default: 1", "padding (int or tuple, optional)": "implicit zero padding to be added on\nboth sides of input. Default: 0", "dilation (int or tuple, optional)": "a parameter that controls the\nstride of elements within the\nneighborhood. Default: 1"}, "description": "Extracts sliding local blocks from a batched input tensor."}, "torch.nn.Fold": {"Parameters": {"output_size (int or tuple)": "the shape of the spatial dimensions of the\noutput (i.e., output.sizes()[2:])", "kernel_size (int or tuple)": "the size of the sliding blocks", "stride (int or tuple)": "the stride of the sliding blocks in the input\nspatial dimensions. Default: 1", "padding (int or tuple, optional)": "implicit zero padding to be added on\nboth sides of input. Default: 0", "dilation (int or tuple, optional)": "a parameter that controls the\nstride of elements within the\nneighborhood. Default: 1"}, "description": "Combines an array of sliding local blocks into a large containing tensor."}, "torch.nn.MaxPool1d": {"Parameters": {"kernel_size": "The size of the sliding window, must be > 0.", "stride": "The stride of the sliding window, must be > 0. Default value is kernel_size.", "padding": "Implicit negative infinity padding to be added on both sides, must be >= 0 and <= kernel_size / 2.", "dilation": "The stride between elements within a sliding window, must be > 0.", "return_indices": "If True, will return the argmax along with the max values.\nUseful for torch.nn.MaxUnpool1d later", "ceil_mode": "If True, will use ceil instead of floor to compute the output shape. This\nensures that every element in the input tensor is covered by a sliding window."}, "description": "Applies a 1D max pooling over an input signal composed of several input planes."}, "torch.nn.MaxPool2d": {"Parameters": {"kernel_size": "the size of the window to take a max over", "stride": "the stride of the window. Default value is kernel_size", "padding": "implicit zero padding to be added on both sides", "dilation": "a parameter that controls the stride of elements in the window", "return_indices": "if True, will return the max indices along with the outputs.\nUseful for torch.nn.MaxUnpool2d later", "ceil_mode": "when True, will use ceil instead of floor to compute the output shape"}, "description": "Applies a 2D max pooling over an input signal composed of several input planes."}, "torch.nn.MaxPool3d": {"Parameters": {"kernel_size": "the size of the window to take a max over", "stride": "the stride of the window. Default value is kernel_size", "padding": "implicit zero padding to be added on all three sides", "dilation": "a parameter that controls the stride of elements in the window", "return_indices": "if True, will return the max indices along with the outputs.\nUseful for torch.nn.MaxUnpool3d later", "ceil_mode": "when True, will use ceil instead of floor to compute the output shape"}, "description": "Applies a 3D max pooling over an input signal composed of several input planes."}, "torch.nn.MaxUnpool1d": {"Parameters": {"kernel_size (int or tuple)": "Size of the max pooling window.", "stride (int or tuple)": "Stride of the max pooling window.\nIt is set to kernel_size by default.", "padding (int or tuple)": "Padding that was added to the input"}, "description": "Computes a partial inverse of MaxPool1d."}, "torch.nn.MaxUnpool2d": {"Parameters": {"kernel_size (int or tuple)": "Size of the max pooling window.", "stride (int or tuple)": "Stride of the max pooling window.\nIt is set to kernel_size by default.", "padding (int or tuple)": "Padding that was added to the input"}, "description": "Computes a partial inverse of MaxPool2d."}, "torch.nn.MaxUnpool3d": {"Parameters": {"kernel_size (int or tuple)": "Size of the max pooling window.", "stride (int or tuple)": "Stride of the max pooling window.\nIt is set to kernel_size by default.", "padding (int or tuple)": "Padding that was added to the input"}, "description": "Computes a partial inverse of MaxPool3d."}, "torch.nn.AvgPool1d": {"Parameters": {"kernel_size": "the size of the window", "stride": "the stride of the window. Default value is kernel_size", "padding": "implicit zero padding to be added on both sides", "ceil_mode": "when True, will use ceil instead of floor to compute the output shape", "count_include_pad": "when True, will include the zero-padding in the averaging calculation"}, "description": "Applies a 1D average pooling over an input signal composed of several input planes."}, "torch.nn.AvgPool2d": {"Parameters": {"kernel_size": "the size of the window", "stride": "the stride of the window. Default value is kernel_size", "padding": "implicit zero padding to be added on both sides", "ceil_mode": "when True, will use ceil instead of floor to compute the output shape", "count_include_pad": "when True, will include the zero-padding in the averaging calculation", "divisor_override": "if specified, it will be used as divisor, otherwise size of the pooling region will be used."}, "description": "Applies a 2D average pooling over an input signal composed of several input planes."}, "torch.nn.AvgPool3d": {"Parameters": {"kernel_size": "the size of the window", "stride": "the stride of the window. Default value is kernel_size", "padding": "implicit zero padding to be added on all three sides", "ceil_mode": "when True, will use ceil instead of floor to compute the output shape", "count_include_pad": "when True, will include the zero-padding in the averaging calculation", "divisor_override": "if specified, it will be used as divisor, otherwise kernel_size will be used"}, "description": "Applies a 3D average pooling over an input signal composed of several input planes."}, "torch.nn.FractionalMaxPool2d": {"Parameters": {"kernel_size": "the size of the window to take a max over.\nCan be a single number k (for a square kernel of k x k) or a tuple (kh, kw)", "output_size": "the target output size of the image of the form oH x oW.\nCan be a tuple (oH, oW) or a single number oH for a square image oH x oH", "output_ratio": "If one wants to have an output size as a ratio of the input size, this option can be given.\nThis has to be a number or tuple in the range (0, 1)", "return_indices": "if True, will return the indices along with the outputs.\nUseful to pass to nn.MaxUnpool2d(). Default: False"}, "description": "Applies a 2D fractional max pooling over an input signal composed of several input planes."}, "torch.nn.FractionalMaxPool3d": {"Parameters": {"kernel_size": "the size of the window to take a max over.\nCan be a single number k (for a square kernel of k x k x k) or a tuple (kt x kh x kw)", "output_size": "the target output size of the image of the form oT x oH x oW.\nCan be a tuple (oT, oH, oW) or a single number oH for a square image oH x oH x oH", "output_ratio": "If one wants to have an output size as a ratio of the input size, this option can be given.\nThis has to be a number or tuple in the range (0, 1)", "return_indices": "if True, will return the indices along with the outputs.\nUseful to pass to nn.MaxUnpool3d(). Default: False"}, "description": "Applies a 3D fractional max pooling over an input signal composed of several input planes."}, "torch.nn.LPPool1d": {"Parameters": {"kernel_size": "a single int, the size of the window", "stride": "a single int, the stride of the window. Default value is kernel_size", "ceil_mode": "when True, will use ceil instead of floor to compute the output shape"}, "description": "Applies a 1D power-average pooling over an input signal composed of several input planes."}, "torch.nn.LPPool2d": {"Parameters": {"kernel_size": "the size of the window", "stride": "the stride of the window. Default value is kernel_size", "ceil_mode": "when True, will use ceil instead of floor to compute the output shape"}, "description": "Applies a 2D power-average pooling over an input signal composed of several input planes."}, "torch.nn.AdaptiveMaxPool1d": {"Parameters": {"output_size": "the target output size LoutL_{out}Lout\u200b.", "return_indices": "if True, will return the indices along with the outputs.\nUseful to pass to nn.MaxUnpool1d. Default: False"}, "description": "Applies a 1D adaptive max pooling over an input signal composed of several input planes."}, "torch.nn.AdaptiveMaxPool2d": {"Parameters": {"output_size": "the target output size of the image of the form Hout\u00d7WoutH_{out} \\times W_{out}Hout\u200b\u00d7Wout\u200b.\nCan be a tuple (Hout,Wout)(H_{out}, W_{out})(Hout\u200b,Wout\u200b) or a single HoutH_{out}Hout\u200b for a\nsquare image Hout\u00d7HoutH_{out} \\times H_{out}Hout\u200b\u00d7Hout\u200b. HoutH_{out}Hout\u200b and WoutW_{out}Wout\u200b\ncan be either a int, or None which means the size will be the same as that\nof the input.", "return_indices": "if True, will return the indices along with the outputs.\nUseful to pass to nn.MaxUnpool2d. Default: False"}, "description": "Applies a 2D adaptive max pooling over an input signal composed of several input planes."}, "torch.nn.AdaptiveMaxPool3d": {"Parameters": {"output_size": "the target output size of the image of the form Dout\u00d7Hout\u00d7WoutD_{out} \\times H_{out} \\times W_{out}Dout\u200b\u00d7Hout\u200b\u00d7Wout\u200b.\nCan be a tuple (Dout,Hout,Wout)(D_{out}, H_{out}, W_{out})(Dout\u200b,Hout\u200b,Wout\u200b) or a single\nDoutD_{out}Dout\u200b for a cube Dout\u00d7Dout\u00d7DoutD_{out} \\times D_{out} \\times D_{out}Dout\u200b\u00d7Dout\u200b\u00d7Dout\u200b.\nDoutD_{out}Dout\u200b, HoutH_{out}Hout\u200b and WoutW_{out}Wout\u200b can be either a\nint, or None which means the size will be the same as that of the input.", "return_indices": "if True, will return the indices along with the outputs.\nUseful to pass to nn.MaxUnpool3d. Default: False"}, "description": "Applies a 3D adaptive max pooling over an input signal composed of several input planes."}, "torch.nn.AdaptiveAvgPool1d": {"Parameters": {"output_size": "the target output size LoutL_{out}Lout\u200b."}, "description": "Applies a 1D adaptive average pooling over an input signal composed of several input planes."}, "torch.nn.AdaptiveAvgPool2d": {"Parameters": {"output_size": "the target output size of the image of the form H x W.\nCan be a tuple (H, W) or a single H for a square image H x H.\nH and W can be either a int, or None which means the size will\nbe the same as that of the input."}, "description": "Applies a 2D adaptive average pooling over an input signal composed of several input planes."}, "torch.nn.AdaptiveAvgPool3d": {"Parameters": {"output_size": "the target output size of the form D x H x W.\nCan be a tuple (D, H, W) or a single number D for a cube D x D x D.\nD, H and W can be either a int, or None which means the size will\nbe the same as that of the input."}, "description": "Applies a 3D adaptive average pooling over an input signal composed of several input planes."}, "torch.nn.ReflectionPad1d": {"Parameters": {"padding (int, tuple)": "the size of the padding. If is int, uses the same\npadding in all boundaries. If a 2-tuple, uses\n(padding_left\\text{padding\\_left}padding_left, padding_right\\text{padding\\_right}padding_right)"}, "description": "Pads the input tensor using the reflection of the input boundary."}, "torch.nn.ReflectionPad2d": {"Parameters": {"padding (int, tuple)": "the size of the padding. If is int, uses the same\npadding in all boundaries. If a 4-tuple, uses (padding_left\\text{padding\\_left}padding_left,\npadding_right\\text{padding\\_right}padding_right, padding_top\\text{padding\\_top}padding_top, padding_bottom\\text{padding\\_bottom}padding_bottom)"}, "description": "Pads the input tensor using the reflection of the input boundary."}, "torch.nn.ReflectionPad3d": {"Parameters": {"padding (int, tuple)": "the size of the padding. If is int, uses the same\npadding in all boundaries. If a 6-tuple, uses\n(padding_left\\text{padding\\_left}padding_left, padding_right\\text{padding\\_right}padding_right,\npadding_top\\text{padding\\_top}padding_top, padding_bottom\\text{padding\\_bottom}padding_bottom,\npadding_front\\text{padding\\_front}padding_front, padding_back\\text{padding\\_back}padding_back)"}, "description": "Pads the input tensor using the reflection of the input boundary."}, "torch.nn.ReplicationPad1d": {"Parameters": {"padding (int, tuple)": "the size of the padding. If is int, uses the same\npadding in all boundaries. If a 2-tuple, uses\n(padding_left\\text{padding\\_left}padding_left, padding_right\\text{padding\\_right}padding_right)"}, "description": "Pads the input tensor using replication of the input boundary."}, "torch.nn.ReplicationPad2d": {"Parameters": {"padding (int, tuple)": "the size of the padding. If is int, uses the same\npadding in all boundaries. If a 4-tuple, uses (padding_left\\text{padding\\_left}padding_left,\npadding_right\\text{padding\\_right}padding_right, padding_top\\text{padding\\_top}padding_top, padding_bottom\\text{padding\\_bottom}padding_bottom)"}, "description": "Pads the input tensor using replication of the input boundary."}, "torch.nn.ReplicationPad3d": {"Parameters": {"padding (int, tuple)": "the size of the padding. If is int, uses the same\npadding in all boundaries. If a 6-tuple, uses\n(padding_left\\text{padding\\_left}padding_left, padding_right\\text{padding\\_right}padding_right,\npadding_top\\text{padding\\_top}padding_top, padding_bottom\\text{padding\\_bottom}padding_bottom,\npadding_front\\text{padding\\_front}padding_front, padding_back\\text{padding\\_back}padding_back)"}, "description": "Pads the input tensor using replication of the input boundary."}, "torch.nn.ZeroPad2d": {"Parameters": {"padding (int, tuple)": "the size of the padding. If is int, uses the same\npadding in all boundaries. If a 4-tuple, uses (padding_left\\text{padding\\_left}padding_left,\npadding_right\\text{padding\\_right}padding_right, padding_top\\text{padding\\_top}padding_top, padding_bottom\\text{padding\\_bottom}padding_bottom)"}, "description": "Pads the input tensor boundaries with zero."}, "torch.nn.ConstantPad1d": {"Parameters": {"padding (int, tuple)": "the size of the padding. If is int, uses the same\npadding in both boundaries. If a 2-tuple, uses\n(padding_left\\text{padding\\_left}padding_left, padding_right\\text{padding\\_right}padding_right)"}, "description": "Pads the input tensor boundaries with a constant value."}, "torch.nn.ConstantPad2d": {"Parameters": {"padding (int, tuple)": "the size of the padding. If is int, uses the same\npadding in all boundaries. If a 4-tuple, uses (padding_left\\text{padding\\_left}padding_left,\npadding_right\\text{padding\\_right}padding_right, padding_top\\text{padding\\_top}padding_top, padding_bottom\\text{padding\\_bottom}padding_bottom)"}, "description": "Pads the input tensor boundaries with a constant value."}, "torch.nn.ConstantPad3d": {"Parameters": {"padding (int, tuple)": "the size of the padding. If is int, uses the same\npadding in all boundaries. If a 6-tuple, uses\n(padding_left\\text{padding\\_left}padding_left, padding_right\\text{padding\\_right}padding_right,\npadding_top\\text{padding\\_top}padding_top, padding_bottom\\text{padding\\_bottom}padding_bottom,\npadding_front\\text{padding\\_front}padding_front, padding_back\\text{padding\\_back}padding_back)"}, "description": "Pads the input tensor boundaries with a constant value."}, "torch.nn.ELU": {"Parameters": {"alpha": "the \u03b1\\alpha\u03b1 value for the ELU formulation. Default: 1.0", "inplace": "can optionally do the operation in-place. Default: False"}, "description": "Applies the Exponential Linear Unit (ELU) function, element-wise, as described in the paper: Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)."}, "torch.nn.Hardshrink": {"Parameters": {"lambd": "the \u03bb\\lambda\u03bb value for the Hardshrink formulation. Default: 0.5"}, "description": "Applies the Hard Shrinkage (Hardshrink) function element-wise."}, "torch.nn.Hardsigmoid": {"Parameters": {"inplace": "can optionally do the operation in-place. Default: False"}, "description": "Applies the Hardsigmoid function element-wise."}, "torch.nn.Hardtanh": {"Parameters": {"min_val": "minimum value of the linear region range. Default: -1", "max_val": "maximum value of the linear region range. Default: 1", "inplace": "can optionally do the operation in-place. Default: False"}, "description": "Applies the HardTanh function element-wise."}, "torch.nn.Hardswish": {"Parameters": {"inplace": "can optionally do the operation in-place. Default: False"}, "description": "Applies the hardswish function, element-wise, as described in the paper:"}, "torch.nn.LeakyReLU": {"Parameters": {"negative_slope": "Controls the angle of the negative slope. Default: 1e-2", "inplace": "can optionally do the operation in-place. Default: False"}, "description": "Applies the element-wise function:"}, "torch.nn.LogSigmoid": {"description": "Applies the element-wise function:"}, "torch.nn.MultiheadAttention": {"Parameters": {"embed_dim": "Total dimension of the model.", "num_heads": "Number of parallel attention heads. Note that embed_dim will be split\nacross num_heads (i.e. each head will have dimension embed_dim // num_heads).", "dropout": "Dropout probability on attn_output_weights. Default: 0.0 (no dropout).", "bias": "If specified, adds bias to input / output projection layers. Default: True.", "add_bias_kv": "If specified, adds bias to the key and value sequences at dim=0. Default: False.", "add_zero_attn": "If specified, adds a new batch of zeros to the key and value sequences at dim=1.\nDefault: False.", "kdim": "Total number of features for keys. Default: None (uses kdim=embed_dim).", "vdim": "Total number of features for values. Default: None (uses vdim=embed_dim).", "batch_first": "If True, then the input and output tensors are provided\nas (batch, seq, feature). Default: False (seq, batch, feature)."}, "method": {"torch.nn.MultiheadAttention.forward": {"description": null}}, "description": "Allows the model to jointly attend to information from different representation subspaces as described in the paper: Attention Is All You Need."}, "torch.nn.PReLU": {"Parameters": {"num_parameters (int)": "number of aaa to learn.\nAlthough it takes an int as input, there is only two values are legitimate:\n1, or the number of channels at input. Default: 1", "init (float)": "the initial value of aaa. Default: 0.25"}, "description": "Applies the element-wise function:"}, "torch.nn.ReLU": {"Parameters": {"inplace": "can optionally do the operation in-place. Default: False"}, "description": "Applies the rectified linear unit function element-wise:"}, "torch.nn.ReLU6": {"Parameters": {"inplace": "can optionally do the operation in-place. Default: False"}, "description": "Applies the element-wise function:"}, "torch.nn.RReLU": {"Parameters": {"lower": "lower bound of the uniform distribution. Default: 18\\frac{1}{8}81\u200b", "upper": "upper bound of the uniform distribution. Default: 13\\frac{1}{3}31\u200b", "inplace": "can optionally do the operation in-place. Default: False"}, "description": "Applies the randomized leaky rectified liner unit function, element-wise, as described in the paper:"}, "torch.nn.SELU": {"Parameters": {"inplace (bool, optional)": "can optionally do the operation in-place. Default: False"}, "description": "Applied element-wise, as:"}, "torch.nn.CELU": {"Parameters": {"alpha": "the \u03b1\\alpha\u03b1 value for the CELU formulation. Default: 1.0", "inplace": "can optionally do the operation in-place. Default: False"}, "description": "Applies the element-wise function:"}, "torch.nn.GELU": {"description": "Applies the Gaussian Error Linear Units function:"}, "torch.nn.Sigmoid": {"description": "Applies the element-wise function:"}, "torch.nn.SiLU": {"description": "Applies the Sigmoid Linear Unit (SiLU) function, element-wise."}, "torch.nn.Mish": {"description": "Applies the Mish function, element-wise."}, "torch.nn.Softplus": {"Parameters": {"beta": "the \u03b2\\beta\u03b2 value for the Softplus formulation. Default: 1", "threshold": "values above this revert to a linear function. Default: 20"}, "description": "Applies the Softplus function Softplus(x)=1\u03b2\u2217log\u2061(1+exp\u2061(\u03b2\u2217x))\\text{Softplus}(x) = \\frac{1}{\\beta} * \\log(1 + \\exp(\\beta * x))Softplus(x)=\u03b21\u200b\u2217log(1+exp(\u03b2\u2217x)) element-wise."}, "torch.nn.Softshrink": {"Parameters": {"lambd": "the \u03bb\\lambda\u03bb (must be no less than zero) value for the Softshrink formulation. Default: 0.5"}, "description": "Applies the soft shrinkage function elementwise:"}, "torch.nn.Softsign": {"description": "Applies the element-wise function:"}, "torch.nn.Tanh": {"description": "Applies the Hyperbolic Tangent (Tanh) function element-wise."}, "torch.nn.Tanhshrink": {"description": "Applies the element-wise function:"}, "torch.nn.Threshold": {"Parameters": {"threshold": "The value to threshold at", "value": "The value to replace with", "inplace": "can optionally do the operation in-place. Default: False"}, "description": "Thresholds each element of the input Tensor."}, "torch.nn.GLU": {"Parameters": {"dim (int)": "the dimension on which to split the input. Default: -1"}, "description": "Applies the gated linear unit function GLU(a,b)=a\u2297\u03c3(b){GLU}(a, b)= a \\otimes \\sigma(b)GLU(a,b)=a\u2297\u03c3(b) where aaa is the first half of the input matrices and bbb is the second half."}, "torch.nn.Softmin": {"Parameters": {"dim (int)": "A dimension along which Softmin will be computed (so every slice\nalong dim will sum to 1)."}, "Returns": "a Tensor of the same dimension and shape as the input, with\nvalues in the range [0, 1]\n", "description": "Applies the Softmin function to an n-dimensional input Tensor rescaling them so that the elements of the n-dimensional output Tensor lie in the range [0, 1] and sum to 1."}, "torch.nn.Softmax": {"Returns": "a Tensor of the same dimension and shape as the input with\nvalues in the range [0, 1]\n", "Parameters": {"dim (int)": "A dimension along which Softmax will be computed (so every slice\nalong dim will sum to 1)."}, "description": "Applies the Softmax function to an n-dimensional input Tensor rescaling them so that the elements of the n-dimensional output Tensor lie in the range [0,1] and sum to 1."}, "torch.nn.Softmax2d": {"Returns": "a Tensor of the same dimension and shape as the input with\nvalues in the range [0, 1]\n", "description": "Applies SoftMax over features to each spatial location."}, "torch.nn.LogSoftmax": {"Parameters": {"dim (int)": "A dimension along which LogSoftmax will be computed."}, "Returns": "a Tensor of the same dimension and shape as the input with\nvalues in the range [-inf, 0)\n", "description": "Applies the log\u2061(Softmax(x))\\log(\\text{Softmax}(x))log(Softmax(x)) function to an n-dimensional input Tensor."}, "torch.nn.AdaptiveLogSoftmaxWithLoss": {"Parameters": {"in_features (int)": "Number of features in the input tensor", "n_classes (int)": "Number of classes in the dataset", "cutoffs (Sequence)": "Cutoffs used to assign targets to their buckets", "div_value (float, optional)": "value used as an exponent to compute sizes\nof the clusters. Default: 4.0", "head_bias (bool, optional)": "If True, adds a bias term to the \u2018head\u2019 of the\nadaptive softmax. Default: False"}, "Returns": "\noutput is a Tensor of size N containing computed target\nlog probabilities for each example\nloss is a Scalar representing the computed negative\nlog likelihood loss\n\n\n", "method": {"torch.nn.AdaptiveLogSoftmaxWithLoss.log_prob": {"description": null}, "torch.nn.AdaptiveLogSoftmaxWithLoss.predict": {"description": null}}, "description": "Efficient softmax approximation as described in Efficient softmax approximation for GPUs by Edouard Grave, Armand Joulin, Moustapha Ciss\u00e9, David Grangier, and Herv\u00e9 J\u00e9gou."}, "torch.nn.BatchNorm1d": {"Parameters": {"num_features": "number of features or channels CCC of the input", "eps": "a value added to the denominator for numerical stability.\nDefault: 1e-5", "momentum": "the value used for the running_mean and running_var\ncomputation. Can be set to None for cumulative moving average\n(i.e. simple average). Default: 0.1", "affine": "a boolean value that when set to True, this module has\nlearnable affine parameters. Default: True", "track_running_stats": "a boolean value that when set to True, this\nmodule tracks the running mean and variance, and when set to False,\nthis module does not track such statistics, and initializes statistics\nbuffers running_mean and running_var as None.\nWhen these buffers are None, this module always uses batch statistics.\nin both training and eval modes. Default: True"}, "description": "Applies Batch Normalization over a 2D or 3D input as described in the paper Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift ."}, "torch.nn.BatchNorm2d": {"Parameters": {"num_features": "CCC from an expected input of size\n(N,C,H,W)(N, C, H, W)(N,C,H,W)", "eps": "a value added to the denominator for numerical stability.\nDefault: 1e-5", "momentum": "the value used for the running_mean and running_var\ncomputation. Can be set to None for cumulative moving average\n(i.e. simple average). Default: 0.1", "affine": "a boolean value that when set to True, this module has\nlearnable affine parameters. Default: True", "track_running_stats": "a boolean value that when set to True, this\nmodule tracks the running mean and variance, and when set to False,\nthis module does not track such statistics, and initializes statistics\nbuffers running_mean and running_var as None.\nWhen these buffers are None, this module always uses batch statistics.\nin both training and eval modes. Default: True"}, "description": "Applies Batch Normalization over a 4D input (a mini-batch of 2D inputs with additional channel dimension) as described in the paper Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift ."}, "torch.nn.BatchNorm3d": {"Parameters": {"num_features": "CCC from an expected input of size\n(N,C,D,H,W)(N, C, D, H, W)(N,C,D,H,W)", "eps": "a value added to the denominator for numerical stability.\nDefault: 1e-5", "momentum": "the value used for the running_mean and running_var\ncomputation. Can be set to None for cumulative moving average\n(i.e. simple average). Default: 0.1", "affine": "a boolean value that when set to True, this module has\nlearnable affine parameters. Default: True", "track_running_stats": "a boolean value that when set to True, this\nmodule tracks the running mean and variance, and when set to False,\nthis module does not track such statistics, and initializes statistics\nbuffers running_mean and running_var as None.\nWhen these buffers are None, this module always uses batch statistics.\nin both training and eval modes. Default: True"}, "description": "Applies Batch Normalization over a 5D input (a mini-batch of 3D inputs with additional channel dimension) as described in the paper Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift ."}, "torch.nn.LazyBatchNorm1d": {"Parameters": {"eps": "a value added to the denominator for numerical stability.\nDefault: 1e-5", "momentum": "the value used for the running_mean and running_var\ncomputation. Can be set to None for cumulative moving average\n(i.e. simple average). Default: 0.1", "affine": "a boolean value that when set to True, this module has\nlearnable affine parameters. Default: True", "track_running_stats": "a boolean value that when set to True, this\nmodule tracks the running mean and variance, and when set to False,\nthis module does not track such statistics, and initializes statistics\nbuffers running_mean and running_var as None.\nWhen these buffers are None, this module always uses batch statistics.\nin both training and eval modes. Default: True"}, "description": "A torch.nn.BatchNorm1d module with lazy initialization of the num_features argument of the BatchNorm1d that is inferred from the input.size(1)."}, "torch.nn.LazyBatchNorm2d": {"Parameters": {"eps": "a value added to the denominator for numerical stability.\nDefault: 1e-5", "momentum": "the value used for the running_mean and running_var\ncomputation. Can be set to None for cumulative moving average\n(i.e. simple average). Default: 0.1", "affine": "a boolean value that when set to True, this module has\nlearnable affine parameters. Default: True", "track_running_stats": "a boolean value that when set to True, this\nmodule tracks the running mean and variance, and when set to False,\nthis module does not track such statistics, and initializes statistics\nbuffers running_mean and running_var as None.\nWhen these buffers are None, this module always uses batch statistics.\nin both training and eval modes. Default: True"}, "description": "A torch.nn.BatchNorm2d module with lazy initialization of the num_features argument of the BatchNorm2d that is inferred from the input.size(1)."}, "torch.nn.LazyBatchNorm3d": {"Parameters": {"eps": "a value added to the denominator for numerical stability.\nDefault: 1e-5", "momentum": "the value used for the running_mean and running_var\ncomputation. Can be set to None for cumulative moving average\n(i.e. simple average). Default: 0.1", "affine": "a boolean value that when set to True, this module has\nlearnable affine parameters. Default: True", "track_running_stats": "a boolean value that when set to True, this\nmodule tracks the running mean and variance, and when set to False,\nthis module does not track such statistics, and initializes statistics\nbuffers running_mean and running_var as None.\nWhen these buffers are None, this module always uses batch statistics.\nin both training and eval modes. Default: True"}, "description": "A torch.nn.BatchNorm3d module with lazy initialization of the num_features argument of the BatchNorm3d that is inferred from the input.size(1)."}, "torch.nn.GroupNorm": {"Parameters": {"num_groups (int)": "number of groups to separate the channels into", "num_channels (int)": "number of channels expected in input", "eps": "a value added to the denominator for numerical stability. Default: 1e-5", "affine": "a boolean value that when set to True, this module\nhas learnable per-channel affine parameters initialized to ones (for weights)\nand zeros (for biases). Default: True."}, "description": "Applies Group Normalization over a mini-batch of inputs as described in the paper Group Normalization"}, "torch.nn.SyncBatchNorm": {"Parameters": {"num_features": "CCC from an expected input of size\n(N,C,+)(N, C, +)(N,C,+)", "eps": "a value added to the denominator for numerical stability.\nDefault: 1e-5", "momentum": "the value used for the running_mean and running_var\ncomputation. Can be set to None for cumulative moving average\n(i.e. simple average). Default: 0.1", "affine": "a boolean value that when set to True, this module has\nlearnable affine parameters. Default: True", "track_running_stats": "a boolean value that when set to True, this\nmodule tracks the running mean and variance, and when set to False,\nthis module does not track such statistics, and initializes statistics\nbuffers running_mean and running_var as None.\nWhen these buffers are None, this module always uses batch statistics.\nin both training and eval modes. Default: True", "process_group": "synchronization of stats happen within each process group\nindividually. Default behavior is synchronization across the whole\nworld"}, "method": {"torch.nn.SyncBatchNorm.convert_sync_batchnorm": {"Parameters": {"module (nn.Module)": "module containing one or more BatchNorm*D layers", "process_group (optional)": "process group to scope synchronization,\ndefault is the whole world"}, "Returns": "The original module with the converted torch.nn.SyncBatchNorm\nlayers. If the original module is a BatchNorm*D layer,\na new torch.nn.SyncBatchNorm layer object will be returned\ninstead.\n", "description": null}}, "description": "Applies Batch Normalization over a N-Dimensional input (a mini-batch of [N-2]D inputs with additional channel dimension) as described in the paper Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift ."}, "torch.nn.InstanceNorm1d": {"Parameters": {"num_features": "number of features or channels CCC of the input", "eps": "a value added to the denominator for numerical stability. Default: 1e-5", "momentum": "the value used for the running_mean and running_var computation. Default: 0.1", "affine": "a boolean value that when set to True, this module has\nlearnable affine parameters, initialized the same way as done for batch normalization.\nDefault: False.", "track_running_stats": "a boolean value that when set to True, this\nmodule tracks the running mean and variance, and when set to False,\nthis module does not track such statistics and always uses batch\nstatistics in both training and eval modes. Default: False"}, "description": "Applies Instance Normalization over a 2D (unbatched) or 3D (batched) input as described in the paper Instance Normalization: The Missing Ingredient for Fast Stylization."}, "torch.nn.InstanceNorm2d": {"Parameters": {"num_features": "CCC from an expected input of size\n(N,C,H,W)(N, C, H, W)(N,C,H,W) or (C,H,W)(C, H, W)(C,H,W)", "eps": "a value added to the denominator for numerical stability. Default: 1e-5", "momentum": "the value used for the running_mean and running_var computation. Default: 0.1", "affine": "a boolean value that when set to True, this module has\nlearnable affine parameters, initialized the same way as done for batch normalization.\nDefault: False.", "track_running_stats": "a boolean value that when set to True, this\nmodule tracks the running mean and variance, and when set to False,\nthis module does not track such statistics and always uses batch\nstatistics in both training and eval modes. Default: False"}, "description": "Applies Instance Normalization over a 4D input (a mini-batch of 2D inputs with additional channel dimension) as described in the paper Instance Normalization: The Missing Ingredient for Fast Stylization."}, "torch.nn.InstanceNorm3d": {"Parameters": {"num_features": "CCC from an expected input of size\n(N,C,D,H,W)(N, C, D, H, W)(N,C,D,H,W) or (C,D,H,W)(C, D, H, W)(C,D,H,W)", "eps": "a value added to the denominator for numerical stability. Default: 1e-5", "momentum": "the value used for the running_mean and running_var computation. Default: 0.1", "affine": "a boolean value that when set to True, this module has\nlearnable affine parameters, initialized the same way as done for batch normalization.\nDefault: False.", "track_running_stats": "a boolean value that when set to True, this\nmodule tracks the running mean and variance, and when set to False,\nthis module does not track such statistics and always uses batch\nstatistics in both training and eval modes. Default: False"}, "description": "Applies Instance Normalization over a 5D input (a mini-batch of 3D inputs with additional channel dimension) as described in the paper Instance Normalization: The Missing Ingredient for Fast Stylization."}, "torch.nn.LazyInstanceNorm1d": {"Parameters": {"num_features": "CCC from an expected input of size\n(N,C,L)(N, C, L)(N,C,L) or (C,L)(C, L)(C,L)", "eps": "a value added to the denominator for numerical stability. Default: 1e-5", "momentum": "the value used for the running_mean and running_var computation. Default: 0.1", "affine": "a boolean value that when set to True, this module has\nlearnable affine parameters, initialized the same way as done for batch normalization.\nDefault: False.", "track_running_stats": "a boolean value that when set to True, this\nmodule tracks the running mean and variance, and when set to False,\nthis module does not track such statistics and always uses batch\nstatistics in both training and eval modes. Default: False"}, "description": "A torch.nn.InstanceNorm1d module with lazy initialization of the num_features argument of the InstanceNorm1d that is inferred from the input.size(1)."}, "torch.nn.LazyInstanceNorm2d": {"Parameters": {"num_features": "CCC from an expected input of size\n(N,C,H,W)(N, C, H, W)(N,C,H,W) or (C,H,W)(C, H, W)(C,H,W)", "eps": "a value added to the denominator for numerical stability. Default: 1e-5", "momentum": "the value used for the running_mean and running_var computation. Default: 0.1", "affine": "a boolean value that when set to True, this module has\nlearnable affine parameters, initialized the same way as done for batch normalization.\nDefault: False.", "track_running_stats": "a boolean value that when set to True, this\nmodule tracks the running mean and variance, and when set to False,\nthis module does not track such statistics and always uses batch\nstatistics in both training and eval modes. Default: False"}, "description": "A torch.nn.InstanceNorm2d module with lazy initialization of the num_features argument of the InstanceNorm2d that is inferred from the input.size(1)."}, "torch.nn.LazyInstanceNorm3d": {"Parameters": {"num_features": "CCC from an expected input of size\n(N,C,D,H,W)(N, C, D, H, W)(N,C,D,H,W) or (C,D,H,W)(C, D, H, W)(C,D,H,W)", "eps": "a value added to the denominator for numerical stability. Default: 1e-5", "momentum": "the value used for the running_mean and running_var computation. Default: 0.1", "affine": "a boolean value that when set to True, this module has\nlearnable affine parameters, initialized the same way as done for batch normalization.\nDefault: False.", "track_running_stats": "a boolean value that when set to True, this\nmodule tracks the running mean and variance, and when set to False,\nthis module does not track such statistics and always uses batch\nstatistics in both training and eval modes. Default: False"}, "description": "A torch.nn.InstanceNorm3d module with lazy initialization of the num_features argument of the InstanceNorm3d that is inferred from the input.size(1)."}, "torch.nn.LayerNorm": {"Parameters": {"normalized_shape (int or list or torch.Size)": "input shape from an expected input\nof size\n\n[\u2217\u00d7normalized_shape[0]\u00d7normalized_shape[1]\u00d7\u2026\u00d7normalized_shape[\u22121]][* \\times \\text{normalized\\_shape}[0] \\times \\text{normalized\\_shape}[1]\n    \\times \\ldots \\times \\text{normalized\\_shape}[-1]]\n\n[\u2217\u00d7normalized_shape[0]\u00d7normalized_shape[1]\u00d7\u2026\u00d7normalized_shape[\u22121]]If a single integer is used, it is treated as a singleton list, and this module will\nnormalize over the last dimension which is expected to be of that specific size.", "eps": "a value added to the denominator for numerical stability. Default: 1e-5", "elementwise_affine": "a boolean value that when set to True, this module\nhas learnable per-element affine parameters initialized to ones (for weights)\nand zeros (for biases). Default: True."}, "description": "Applies Layer Normalization over a mini-batch of inputs as described in the paper Layer Normalization"}, "torch.nn.LocalResponseNorm": {"Parameters": {"size": "amount of neighbouring channels used for normalization", "alpha": "multiplicative factor. Default: 0.0001", "beta": "exponent. Default: 0.75", "k": "additive factor. Default: 1"}, "description": "Applies local response normalization over an input signal composed of several input planes, where channels occupy the second dimension."}, "torch.nn.RNNBase": {"description": ""}, "torch.nn.RNN": {"Parameters": {"input_size": "The number of expected features in the input x", "hidden_size": "The number of features in the hidden state h", "num_layers": "Number of recurrent layers. E.g., setting num_layers=2\nwould mean stacking two RNNs together to form a stacked RNN,\nwith the second RNN taking in outputs of the first RNN and\ncomputing the final results. Default: 1", "nonlinearity": "The non-linearity to use. Can be either 'tanh' or 'relu'. Default: 'tanh'", "bias": "If False, then the layer does not use bias weights b_ih and b_hh.\nDefault: True", "batch_first": "If True, then the input and output tensors are provided\nas (batch, seq, feature) instead of (seq, batch, feature).\nNote that this does not apply to hidden or cell states. See the\nInputs/Outputs sections below for details.  Default: False", "dropout": "If non-zero, introduces a Dropout layer on the outputs of each\nRNN layer except the last layer, with dropout probability equal to\ndropout. Default: 0", "bidirectional": "If True, becomes a bidirectional RNN. Default: False"}, "description": "Applies a multi-layer Elman RNN with tanh\u2061\\tanhtanh or ReLU\\text{ReLU}ReLU non-linearity to an input sequence."}, "torch.nn.LSTM": {"Parameters": {"input_size": "The number of expected features in the input x", "hidden_size": "The number of features in the hidden state h", "num_layers": "Number of recurrent layers. E.g., setting num_layers=2\nwould mean stacking two LSTMs together to form a stacked LSTM,\nwith the second LSTM taking in outputs of the first LSTM and\ncomputing the final results. Default: 1", "bias": "If False, then the layer does not use bias weights b_ih and b_hh.\nDefault: True", "batch_first": "If True, then the input and output tensors are provided\nas (batch, seq, feature) instead of (seq, batch, feature).\nNote that this does not apply to hidden or cell states. See the\nInputs/Outputs sections below for details.  Default: False", "dropout": "If non-zero, introduces a Dropout layer on the outputs of each\nLSTM layer except the last layer, with dropout probability equal to\ndropout. Default: 0", "bidirectional": "If True, becomes a bidirectional LSTM. Default: False", "proj_size": "If > 0, will use LSTM with projections of corresponding size. Default: 0"}, "description": "Applies a multi-layer long short-term memory (LSTM) RNN to an input sequence."}, "torch.nn.GRU": {"Parameters": {"input_size": "The number of expected features in the input x", "hidden_size": "The number of features in the hidden state h", "num_layers": "Number of recurrent layers. E.g., setting num_layers=2\nwould mean stacking two GRUs together to form a stacked GRU,\nwith the second GRU taking in outputs of the first GRU and\ncomputing the final results. Default: 1", "bias": "If False, then the layer does not use bias weights b_ih and b_hh.\nDefault: True", "batch_first": "If True, then the input and output tensors are provided\nas (batch, seq, feature) instead of (seq, batch, feature).\nNote that this does not apply to hidden or cell states. See the\nInputs/Outputs sections below for details.  Default: False", "dropout": "If non-zero, introduces a Dropout layer on the outputs of each\nGRU layer except the last layer, with dropout probability equal to\ndropout. Default: 0", "bidirectional": "If True, becomes a bidirectional GRU. Default: False"}, "description": "Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence."}, "torch.nn.RNNCell": {"Parameters": {"input_size": "The number of expected features in the input x", "hidden_size": "The number of features in the hidden state h", "bias": "If False, then the layer does not use bias weights b_ih and b_hh.\nDefault: True", "nonlinearity": "The non-linearity to use. Can be either 'tanh' or 'relu'. Default: 'tanh'"}, "description": "An Elman RNN cell with tanh or ReLU non-linearity."}, "torch.nn.LSTMCell": {"Parameters": {"input_size": "The number of expected features in the input x", "hidden_size": "The number of features in the hidden state h", "bias": "If False, then the layer does not use bias weights b_ih and\nb_hh. Default: True"}, "description": "A long short-term memory (LSTM) cell."}, "torch.nn.GRUCell": {"Parameters": {"input_size": "The number of expected features in the input x", "hidden_size": "The number of features in the hidden state h", "bias": "If False, then the layer does not use bias weights b_ih and\nb_hh. Default: True"}, "description": "A gated recurrent unit (GRU) cell"}, "torch.nn.Transformer": {"Parameters": {"d_model": "the number of expected features in the encoder/decoder inputs (default=512).", "nhead": "the number of heads in the multiheadattention models (default=8).", "num_encoder_layers": "the number of sub-encoder-layers in the encoder (default=6).", "num_decoder_layers": "the number of sub-decoder-layers in the decoder (default=6).", "dim_feedforward": "the dimension of the feedforward network model (default=2048).", "dropout": "the dropout value (default=0.1).", "activation": "the activation function of encoder/decoder intermediate layer, can be a string\n(\u201crelu\u201d or \u201cgelu\u201d) or a unary callable. Default: relu", "custom_encoder": "custom encoder (default=None).", "custom_decoder": "custom decoder (default=None).", "layer_norm_eps": "the eps value in layer normalization components (default=1e-5).", "batch_first": "If True, then the input and output tensors are provided\nas (batch, seq, feature). Default: False (seq, batch, feature).", "norm_first": "if True, encoder and decoder layers will perform LayerNorms before\nother attention and feedforward operations, otherwise after. Default: False (after)."}, "method": {"torch.nn.Transformer.forward": {"description": "Take in and process masked source/target sequences."}}, "description": "A transformer model."}, "torch.nn.TransformerEncoder": {"Parameters": {"encoder_layer": "an instance of the TransformerEncoderLayer() class (required).", "num_layers": "the number of sub-encoder-layers in the encoder (required).", "norm": "the layer normalization component (optional)."}, "method": {"torch.nn.TransformerEncoder.forward": {"description": "Pass the input through the encoder layers in turn."}}, "description": "TransformerEncoder is a stack of N encoder layers"}, "torch.nn.TransformerDecoder": {"Parameters": {"decoder_layer": "an instance of the TransformerDecoderLayer() class (required).", "num_layers": "the number of sub-decoder-layers in the decoder (required).", "norm": "the layer normalization component (optional)."}, "method": {"torch.nn.TransformerDecoder.forward": {"description": "Pass the inputs (and mask) through the decoder layer in turn."}}, "description": "TransformerDecoder is a stack of N decoder layers"}, "torch.nn.TransformerEncoderLayer": {"Parameters": {"d_model": "the number of expected features in the input (required).", "nhead": "the number of heads in the multiheadattention models (required).", "dim_feedforward": "the dimension of the feedforward network model (default=2048).", "dropout": "the dropout value (default=0.1).", "activation": "the activation function of the intermediate layer, can be a string\n(\u201crelu\u201d or \u201cgelu\u201d) or a unary callable. Default: relu", "layer_norm_eps": "the eps value in layer normalization components (default=1e-5).", "batch_first": "If True, then the input and output tensors are provided\nas (batch, seq, feature). Default: False (seq, batch, feature).", "norm_first": "if True, layer norm is done prior to attention and feedforward\noperations, respectivaly. Otherwise it\u2019s done after. Default: False (after)."}, "method": {"torch.nn.TransformerEncoderLayer.forward": {"description": "Pass the input through the encoder layer."}}, "description": "TransformerEncoderLayer is made up of self-attn and feedforward network."}, "torch.nn.TransformerDecoderLayer": {"Parameters": {"d_model": "the number of expected features in the input (required).", "nhead": "the number of heads in the multiheadattention models (required).", "dim_feedforward": "the dimension of the feedforward network model (default=2048).", "dropout": "the dropout value (default=0.1).", "activation": "the activation function of the intermediate layer, can be a string\n(\u201crelu\u201d or \u201cgelu\u201d) or a unary callable. Default: relu", "layer_norm_eps": "the eps value in layer normalization components (default=1e-5).", "batch_first": "If True, then the input and output tensors are provided\nas (batch, seq, feature). Default: False (seq, batch, feature).", "norm_first": "if True, layer norm is done prior to self attention, multihead\nattention and feedforward operations, respectivaly. Otherwise it\u2019s done after.\nDefault: False (after)."}, "method": {"torch.nn.TransformerDecoderLayer.forward": {"description": "Pass the inputs (and mask) through the decoder layer."}}, "description": "TransformerDecoderLayer is made up of self-attn, multi-head-attn and feedforward network."}, "torch.nn.Identity": {"Parameters": {"args": "any argument (unused)", "kwargs": "any keyword argument (unused)"}, "description": "A placeholder identity operator that is argument-insensitive."}, "torch.nn.Linear": {"Parameters": {"in_features": "size of each input sample", "out_features": "size of each output sample", "bias": "If set to False, the layer will not learn an additive bias.\nDefault: True"}, "description": "Applies a linear transformation to the incoming data: y=xAT+by = xA^T + by=xAT+b"}, "torch.nn.Bilinear": {"Parameters": {"in1_features": "size of each first input sample", "in2_features": "size of each second input sample", "out_features": "size of each output sample", "bias": "If set to False, the layer will not learn an additive bias.\nDefault: True"}, "description": "Applies a bilinear transformation to the incoming data: y=x1TAx2+by = x_1^T A x_2 + by=x1T\u200bAx2\u200b+b"}, "torch.nn.LazyLinear": {"Parameters": {"out_features": "size of each output sample", "bias": "If set to False, the layer will not learn an additive bias.\nDefault: True"}, "description": "A torch.nn.Linear module where in_features is inferred."}, "torch.nn.Dropout": {"Parameters": {"p": "probability of an element to be zeroed. Default: 0.5", "inplace": "If set to True, will do this operation in-place. Default: False"}, "description": "During training, randomly zeroes some of the elements of the input tensor with probability p using samples from a Bernoulli distribution."}, "torch.nn.Dropout2d": {"Parameters": {"p (float, optional)": "probability of an element to be zero-ed.", "inplace (bool, optional)": "If set to True, will do this operation\nin-place"}, "description": "Randomly zero out entire channels (a channel is a 2D feature map, e.g., the jjj-th channel of the iii-th sample in the batched input is a 2D tensor input[i,j]\\text{input}[i, j]input[i,j])."}, "torch.nn.Dropout3d": {"Parameters": {"p (float, optional)": "probability of an element to be zeroed.", "inplace (bool, optional)": "If set to True, will do this operation\nin-place"}, "description": "Randomly zero out entire channels (a channel is a 3D feature map, e.g., the jjj-th channel of the iii-th sample in the batched input is a 3D tensor input[i,j]\\text{input}[i, j]input[i,j])."}, "torch.nn.AlphaDropout": {"Parameters": {"p (float)": "probability of an element to be dropped. Default: 0.5", "inplace (bool, optional)": "If set to True, will do this operation\nin-place"}, "description": "Applies Alpha Dropout over the input."}, "torch.nn.FeatureAlphaDropout": {"Parameters": {"p (float, optional)": "probability of an element to be zeroed. Default: 0.5", "inplace (bool, optional)": "If set to True, will do this operation\nin-place"}, "description": "Randomly masks out entire channels (a channel is a feature map, e.g."}, "torch.nn.Embedding": {"Parameters": {"num_embeddings (int)": "size of the dictionary of embeddings", "embedding_dim (int)": "the size of each embedding vector", "padding_idx (int, optional)": "If specified, the entries at padding_idx do not contribute to the gradient;\ntherefore, the embedding vector at padding_idx is not updated during training,\ni.e. it remains as a fixed \u201cpad\u201d. For a newly constructed Embedding,\nthe embedding vector at padding_idx will default to all zeros,\nbut can be updated to another value to be used as the padding vector.", "max_norm (float, optional)": "If given, each embedding vector with norm larger than max_norm\nis renormalized to have norm max_norm.", "norm_type (float, optional)": "The p of the p-norm to compute for the max_norm option. Default 2.", "scale_grad_by_freq (boolean, optional)": "If given, this will scale gradients by the inverse of frequency of\nthe words in the mini-batch. Default False.", "sparse (bool, optional)": "If True, gradient w.r.t. weight matrix will be a sparse tensor.\nSee Notes for more details regarding sparse gradients."}, "method": {"torch.nn.Embedding.from_pretrained": {"Parameters": {"embeddings (Tensor)": "FloatTensor containing weights for the Embedding.\nFirst dimension is being passed to Embedding as num_embeddings, second as embedding_dim.", "freeze (boolean, optional)": "If True, the tensor does not get updated in the learning process.\nEquivalent to embedding.weight.requires_grad = False. Default: True", "padding_idx (int, optional)": "If specified, the entries at padding_idx do not contribute to the gradient;\ntherefore, the embedding vector at padding_idx is not updated during training,\ni.e. it remains as a fixed \u201cpad\u201d.", "max_norm (float, optional)": "See module initialization documentation.", "norm_type (float, optional)": "See module initialization documentation. Default 2.", "scale_grad_by_freq (boolean, optional)": "See module initialization documentation. Default False.", "sparse (bool, optional)": "See module initialization documentation."}, "description": "Creates Embedding instance from given 2-dimensional FloatTensor."}}, "description": "A simple lookup table that stores embeddings of a fixed dictionary and size."}, "torch.nn.EmbeddingBag": {"Parameters": {"num_embeddings (int)": "size of the dictionary of embeddings", "embedding_dim (int)": "the size of each embedding vector", "max_norm (float, optional)": "If given, each embedding vector with norm larger than max_norm\nis renormalized to have norm max_norm.", "norm_type (float, optional)": "The p of the p-norm to compute for the max_norm option. Default 2.", "scale_grad_by_freq (boolean, optional)": "if given, this will scale gradients by the inverse of frequency of\nthe words in the mini-batch. Default False.\nNote: this option is not supported when mode=\"max\".", "mode (string, optional)": "\"sum\", \"mean\" or \"max\". Specifies the way to reduce the bag.\n\"sum\" computes the weighted sum, taking per_sample_weights\ninto consideration. \"mean\" computes the average of the values\nin the bag, \"max\" computes the max value over each bag.\nDefault: \"mean\"", "sparse (bool, optional)": "if True, gradient w.r.t. weight matrix will be a sparse tensor. See\nNotes for more details regarding sparse gradients. Note: this option is not\nsupported when mode=\"max\".", "include_last_offset (bool, optional)": "if True, offsets has one additional element, where the last element\nis equivalent to the size of indices. This matches the CSR format.", "padding_idx (int, optional)": "If specified, the entries at padding_idx do not contribute to the\ngradient; therefore, the embedding vector at padding_idx is not updated\nduring training, i.e. it remains as a fixed \u201cpad\u201d. For a newly constructed\nEmbeddingBag, the embedding vector at padding_idx will default to all\nzeros, but can be updated to another value to be used as the padding vector.\nNote that the embedding vector at padding_idx is excluded from the\nreduction."}, "method": {"torch.nn.EmbeddingBag.forward": {"Parameters": {"input (Tensor)": "Tensor containing bags of indices into the embedding matrix.", "offsets (Tensor, optional)": "Only used when input is 1D. offsets determines\nthe starting index position of each bag (sequence) in input.", "per_sample_weights (Tensor, optional)": "a tensor of float / double weights, or None\nto indicate all weights should be taken to be 1. If specified, per_sample_weights\nmust have exactly the same shape as input and is treated as having the same\noffsets, if those are not None. Only supported for mode='sum'."}, "Returns": "Tensor output shape of (B, embedding_dim).\n", "description": "Forward pass of EmbeddingBag."}, "torch.nn.EmbeddingBag.from_pretrained": {"Parameters": {"embeddings (Tensor)": "FloatTensor containing weights for the EmbeddingBag.\nFirst dimension is being passed to EmbeddingBag as \u2018num_embeddings\u2019, second as \u2018embedding_dim\u2019.", "freeze (boolean, optional)": "If True, the tensor does not get updated in the learning process.\nEquivalent to embeddingbag.weight.requires_grad = False. Default: True", "max_norm (float, optional)": "See module initialization documentation. Default: None", "norm_type (float, optional)": "See module initialization documentation. Default 2.", "scale_grad_by_freq (boolean, optional)": "See module initialization documentation. Default False.", "mode (string, optional)": "See module initialization documentation. Default: \"mean\"", "sparse (bool, optional)": "See module initialization documentation. Default: False.", "include_last_offset (bool, optional)": "See module initialization documentation. Default: False.", "padding_idx (int, optional)": "See module initialization documentation. Default: None."}, "description": "Creates EmbeddingBag instance from given 2-dimensional FloatTensor."}}, "description": "Computes sums or means of \u2018bags\u2019 of embeddings, without instantiating the intermediate embeddings."}, "torch.nn.CosineSimilarity": {"Parameters": {"dim (int, optional)": "Dimension where cosine similarity is computed. Default: 1", "eps (float, optional)": "Small value to avoid division by zero.\nDefault: 1e-8"}, "description": "Returns cosine similarity between x1x_1x1\u200b and x2x_2x2\u200b, computed along dim."}, "torch.nn.PairwiseDistance": {"Parameters": {"p (real)": "the norm degree. Default: 2", "eps (float, optional)": "Small value to avoid division by zero.\nDefault: 1e-6", "keepdim (bool, optional)": "Determines whether or not to keep the vector dimension.\nDefault: False"}, "description": "Computes the pairwise distance between vectors v1v_1v1\u200b, v2v_2v2\u200b using the p-norm:"}, "torch.nn.L1Loss": {"Parameters": {"size_average (bool, optional)": "Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True", "reduce (bool, optional)": "Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True", "reduction (string, optional)": "Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override reduction. Default: 'mean'"}, "description": "Creates a criterion that measures the mean absolute error (MAE) between each element in the input xxx and target yyy."}, "torch.nn.MSELoss": {"Parameters": {"size_average (bool, optional)": "Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True", "reduce (bool, optional)": "Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True", "reduction (string, optional)": "Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override reduction. Default: 'mean'"}, "description": "Creates a criterion that measures the mean squared error (squared L2 norm) between each element in the input xxx and target yyy."}, "torch.nn.CrossEntropyLoss": {"Parameters": {"weight (Tensor, optional)": "a manual rescaling weight given to each class.\nIf given, has to be a Tensor of size C", "size_average (bool, optional)": "Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True", "ignore_index (int, optional)": "Specifies a target value that is ignored\nand does not contribute to the input gradient. When size_average is\nTrue, the loss is averaged over non-ignored targets. Note that\nignore_index is only applicable when the target contains class indices.", "reduce (bool, optional)": "Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True", "reduction (string, optional)": "Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will\nbe applied, 'mean': the weighted mean of the output is taken,\n'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in\nthe meantime, specifying either of those two args will override\nreduction. Default: 'mean'", "label_smoothing (float, optional)": "A float in [0.0, 1.0]. Specifies the amount\nof smoothing when computing the loss, where 0.0 means no smoothing. The targets\nbecome a mixture of the original ground truth and a uniform distribution as described in\nRethinking the Inception Architecture for Computer Vision. Default: 0.00.00.0."}, "description": "This criterion computes the cross entropy loss between input and target."}, "torch.nn.CTCLoss": {"Parameters": {"blank (int, optional)": "blank label. Default 000.", "reduction (string, optional)": "Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the output losses will be divided by the target lengths and\nthen the mean over the batch is taken. Default: 'mean'", "zero_infinity (bool, optional)": "Whether to zero infinite losses and the associated gradients.\nDefault: False\nInfinite losses mainly occur when the inputs are too short\nto be aligned to the targets."}, "description": "The Connectionist Temporal Classification loss."}, "torch.nn.NLLLoss": {"Parameters": {"weight (Tensor, optional)": "a manual rescaling weight given to each\nclass. If given, it has to be a Tensor of size C. Otherwise, it is\ntreated as if having all ones.", "size_average (bool, optional)": "Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: None", "ignore_index (int, optional)": "Specifies a target value that is ignored\nand does not contribute to the input gradient. When\nsize_average is True, the loss is averaged over\nnon-ignored targets.", "reduce (bool, optional)": "Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: None", "reduction (string, optional)": "Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will\nbe applied, 'mean': the weighted mean of the output is taken,\n'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in\nthe meantime, specifying either of those two args will override\nreduction. Default: 'mean'"}, "description": "The negative log likelihood loss."}, "torch.nn.PoissonNLLLoss": {"Parameters": {"log_input (bool, optional)": "if True the loss is computed as\nexp\u2061(input)\u2212target\u2217input\\exp(\\text{input}) - \\text{target}*\\text{input}exp(input)\u2212target\u2217input, if False the loss is\ninput\u2212target\u2217log\u2061(input+eps)\\text{input} - \\text{target}*\\log(\\text{input}+\\text{eps})input\u2212target\u2217log(input+eps).", "full (bool, optional)": "whether to compute full loss, i. e. to add the\nStirling approximation term\n\ntarget\u2217log\u2061(target)\u2212target+0.5\u2217log\u2061(2\u03c0target).\\text{target}*\\log(\\text{target}) - \\text{target} + 0.5 * \\log(2\\pi\\text{target}).\n\ntarget\u2217log(target)\u2212target+0.5\u2217log(2\u03c0target).", "size_average (bool, optional)": "Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True", "eps (float, optional)": "Small value to avoid evaluation of log\u2061(0)\\log(0)log(0) when\nlog_input = False. Default: 1e-8", "reduce (bool, optional)": "Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True", "reduction (string, optional)": "Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override reduction. Default: 'mean'"}, "description": "Negative log likelihood loss with Poisson distribution of target."}, "torch.nn.GaussianNLLLoss": {"Parameters": {"full (bool, optional)": "include the constant term in the loss\ncalculation. Default: False.", "eps (float, optional)": "value used to clamp var (see note below), for\nstability. Default: 1e-6.", "reduction (string, optional)": "specifies the reduction to apply to the\noutput:'none' | 'mean' | 'sum'. 'none': no reduction\nwill be applied, 'mean': the output is the average of all batch\nmember losses, 'sum': the output is the sum of all batch member\nlosses. Default: 'mean'."}, "description": "Gaussian negative log likelihood loss."}, "torch.nn.KLDivLoss": {"Parameters": {"size_average (bool, optional)": "Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True", "reduce (bool, optional)": "Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True", "reduction (string, optional)": "Specifies the reduction to apply to the output. Default: \u201cmean\u201d", "log_target (bool, optional)": "Specifies whether target is the log space. Default: False"}, "description": "The Kullback-Leibler divergence loss."}, "torch.nn.BCELoss": {"Parameters": {"weight (Tensor, optional)": "a manual rescaling weight given to the loss\nof each batch element. If given, has to be a Tensor of size nbatch.", "size_average (bool, optional)": "Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True", "reduce (bool, optional)": "Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True", "reduction (string, optional)": "Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override reduction. Default: 'mean'"}, "description": "Creates a criterion that measures the Binary Cross Entropy between the target and the input probabilities:"}, "torch.nn.BCEWithLogitsLoss": {"Parameters": {"weight (Tensor, optional)": "a manual rescaling weight given to the loss\nof each batch element. If given, has to be a Tensor of size nbatch.", "size_average (bool, optional)": "Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True", "reduce (bool, optional)": "Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True", "reduction (string, optional)": "Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override reduction. Default: 'mean'", "pos_weight (Tensor, optional)": "a weight of positive examples.\nMust be a vector with length equal to the number of classes."}, "description": "This loss combines a Sigmoid layer and the BCELoss in one single class."}, "torch.nn.MarginRankingLoss": {"Parameters": {"margin (float, optional)": "Has a default value of 000.", "size_average (bool, optional)": "Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True", "reduce (bool, optional)": "Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True", "reduction (string, optional)": "Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override reduction. Default: 'mean'"}, "description": "Creates a criterion that measures the loss given inputs x1x1x1, x2x2x2, two 1D mini-batch or 0D Tensors, and a label 1D mini-batch or 0D Tensor yyy (containing 1 or -1)."}, "torch.nn.HingeEmbeddingLoss": {"Parameters": {"margin (float, optional)": "Has a default value of 1.", "size_average (bool, optional)": "Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True", "reduce (bool, optional)": "Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True", "reduction (string, optional)": "Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override reduction. Default: 'mean'"}, "description": "Measures the loss given an input tensor xxx and a labels tensor yyy (containing 1 or -1)."}, "torch.nn.MultiLabelMarginLoss": {"Parameters": {"size_average (bool, optional)": "Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True", "reduce (bool, optional)": "Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True", "reduction (string, optional)": "Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override reduction. Default: 'mean'"}, "description": "Creates a criterion that optimizes a multi-class multi-classification hinge loss (margin-based loss) between input xxx (a 2D mini-batch Tensor) and output yyy (which is a 2D Tensor of target class indices)."}, "torch.nn.HuberLoss": {"Parameters": {"reduction (string, optional)": "Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Default: 'mean'", "delta (float, optional)": "Specifies the threshold at which to change between delta-scaled L1 and L2 loss.\nThe value must be positive.  Default: 1.0"}, "description": "Creates a criterion that uses a squared term if the absolute element-wise error falls below delta and a delta-scaled L1 term otherwise."}, "torch.nn.SmoothL1Loss": {"Parameters": {"size_average (bool, optional)": "Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True", "reduce (bool, optional)": "Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True", "reduction (string, optional)": "Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override reduction. Default: 'mean'", "beta (float, optional)": "Specifies the threshold at which to change between L1 and L2 loss.\nThe value must be non-negative. Default: 1.0"}, "description": "Creates a criterion that uses a squared term if the absolute element-wise error falls below beta and an L1 term otherwise."}, "torch.nn.SoftMarginLoss": {"Parameters": {"size_average (bool, optional)": "Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True", "reduce (bool, optional)": "Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True", "reduction (string, optional)": "Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override reduction. Default: 'mean'"}, "description": "Creates a criterion that optimizes a two-class classification logistic loss between input tensor xxx and target tensor yyy (containing 1 or -1)."}, "torch.nn.MultiLabelSoftMarginLoss": {"Parameters": {"weight (Tensor, optional)": "a manual rescaling weight given to each\nclass. If given, it has to be a Tensor of size C. Otherwise, it is\ntreated as if having all ones.", "size_average (bool, optional)": "Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True", "reduce (bool, optional)": "Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True", "reduction (string, optional)": "Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override reduction. Default: 'mean'"}, "description": "Creates a criterion that optimizes a multi-label one-versus-all loss based on max-entropy, between input xxx and target yyy of size (N,C)(N, C)(N,C)."}, "torch.nn.CosineEmbeddingLoss": {"Parameters": {"margin (float, optional)": "Should be a number from \u22121-1\u22121 to 111,\n000 to 0.50.50.5 is suggested. If margin is missing, the\ndefault value is 000.", "size_average (bool, optional)": "Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True", "reduce (bool, optional)": "Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True", "reduction (string, optional)": "Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override reduction. Default: 'mean'"}, "description": "Creates a criterion that measures the loss given input tensors x1x_1x1\u200b, x2x_2x2\u200b and a Tensor label yyy with values 1 or -1."}, "torch.nn.MultiMarginLoss": {"Parameters": {"p (int, optional)": "Has a default value of 111. 111 and 222\nare the only supported values.", "margin (float, optional)": "Has a default value of 111.", "weight (Tensor, optional)": "a manual rescaling weight given to each\nclass. If given, it has to be a Tensor of size C. Otherwise, it is\ntreated as if having all ones.", "size_average (bool, optional)": "Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True", "reduce (bool, optional)": "Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True", "reduction (string, optional)": "Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override reduction. Default: 'mean'"}, "description": "Creates a criterion that optimizes a multi-class classification hinge loss (margin-based loss) between input xxx (a 2D mini-batch Tensor) and output yyy (which is a 1D tensor of target class indices, 0\u2264y\u2264x.size(1)\u221210 \\leq y \\leq \\text{x.size}(1)-10\u2264y\u2264x.size(1)\u22121):"}, "torch.nn.TripletMarginLoss": {"Parameters": {"margin (float, optional)": "Default: 111.", "p (int, optional)": "The norm degree for pairwise distance. Default: 222.", "swap (bool, optional)": "The distance swap is described in detail in the paper\nLearning shallow convolutional feature descriptors with triplet losses by\nV. Balntas, E. Riba et al. Default: False.", "size_average (bool, optional)": "Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there are multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True", "reduce (bool, optional)": "Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True", "reduction (string, optional)": "Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override reduction. Default: 'mean'"}, "description": "Creates a criterion that measures the triplet loss given an input tensors x1x1x1, x2x2x2, x3x3x3 and a margin with a value greater than 000."}, "torch.nn.TripletMarginWithDistanceLoss": {"Parameters": {"distance_function (callable, optional)": "A nonnegative, real-valued function that\nquantifies the closeness of two tensors. If not specified,\nnn.PairwiseDistance will be used.  Default: None", "margin (float, optional)": "A nonnegative margin representing the minimum difference\nbetween the positive and negative distances required for the loss to be 0. Larger\nmargins penalize cases where the negative examples are not distant enough from the\nanchors, relative to the positives. Default: 111.", "swap (bool, optional)": "Whether to use the distance swap described in the paper\nLearning shallow convolutional feature descriptors with triplet losses by\nV. Balntas, E. Riba et al. If True, and if the positive example is closer to the\nnegative example than the anchor is, swaps the positive example and the anchor in\nthe loss computation. Default: False.", "reduction (string, optional)": "Specifies the (optional) reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Default: 'mean'"}, "description": "Creates a criterion that measures the triplet loss given input tensors aaa, ppp, and nnn (representing anchor, positive, and negative examples, respectively), and a nonnegative, real-valued function (\u201cdistance function\u201d) used to compute the relationship between the anchor and positive example (\u201cpositive distance\u201d) and the anchor and negative example (\u201cnegative distance\u201d)."}, "torch.nn.PixelShuffle": {"Parameters": {"upscale_factor (int)": "factor to increase spatial resolution by"}, "description": "Rearranges elements in a tensor of shape (\u2217,C\u00d7r2,H,W)(*, C \\times r^2, H, W)(\u2217,C\u00d7r2,H,W) to a tensor of shape (\u2217,C,H\u00d7r,W\u00d7r)(*, C, H \\times r, W \\times r)(\u2217,C,H\u00d7r,W\u00d7r), where r is an upscale factor."}, "torch.nn.PixelUnshuffle": {"Parameters": {"downscale_factor (int)": "factor to decrease spatial resolution by"}, "description": "Reverses the PixelShuffle operation by rearranging elements in a tensor of shape (\u2217,C,H\u00d7r,W\u00d7r)(*, C, H \\times r, W \\times r)(\u2217,C,H\u00d7r,W\u00d7r) to a tensor of shape (\u2217,C\u00d7r2,H,W)(*, C \\times r^2, H, W)(\u2217,C\u00d7r2,H,W), where r is a downscale factor."}, "torch.nn.Upsample": {"Parameters": {"size (int or Tuple[int] or Tuple[int, int] or Tuple[int, int, int], optional)": "output spatial sizes", "scale_factor (float or Tuple[float] or Tuple[float, float] or Tuple[float, float, float], optional)": "multiplier for spatial size. Has to match input size if it is a tuple.", "mode (str, optional)": "the upsampling algorithm: one of 'nearest',\n'linear', 'bilinear', 'bicubic' and 'trilinear'.\nDefault: 'nearest'", "align_corners (bool, optional)": "if True, the corner pixels of the input\nand output tensors are aligned, and thus preserving the values at\nthose pixels. This only has effect when mode is\n'linear', 'bilinear', 'bicubic', or 'trilinear'.\nDefault: False", "recompute_scale_factor (bool, optional)": "recompute the scale_factor for use in the\ninterpolation calculation. If recompute_scale_factor is True, then\nscale_factor must be passed in and scale_factor is used to compute the\noutput size. The computed output size will be used to infer new scales for\nthe interpolation. Note that when scale_factor is floating-point, it may differ\nfrom the recomputed scale_factor due to rounding and precision issues.\nIf recompute_scale_factor is False, then size or scale_factor will\nbe used directly for interpolation."}, "description": "Upsamples a given multi-channel 1D (temporal), 2D (spatial) or 3D (volumetric) data."}, "torch.nn.UpsamplingNearest2d": {"Parameters": {"size (int or Tuple[int, int], optional)": "output spatial sizes", "scale_factor (float or Tuple[float, float], optional)": "multiplier for\nspatial size."}, "description": "Applies a 2D nearest neighbor upsampling to an input signal composed of several input channels."}, "torch.nn.UpsamplingBilinear2d": {"Parameters": {"size (int or Tuple[int, int], optional)": "output spatial sizes", "scale_factor (float or Tuple[float, float], optional)": "multiplier for\nspatial size."}, "description": "Applies a 2D bilinear upsampling to an input signal composed of several input channels."}, "torch.nn.ChannelShuffle": {"Parameters": {"groups (int)": "number of groups to divide channels in."}, "description": "Divide the channels in a tensor of shape (\u2217,C,H,W)(*, C , H, W)(\u2217,C,H,W) into g groups and rearrange them as (\u2217,Cg,g,H,W)(*, C \\frac g, g, H, W)(\u2217,C,g\u200bg,H,W), while keeping the original tensor shape."}, "torch.nn.DataParallel": {"Parameters": {"module (Module)": "module to be parallelized", "device_ids (list of python:int or torch.device)": "CUDA devices (default: all devices)", "output_device (int or torch.device)": "device location of output (default: device_ids[0])"}, "description": "Implements data parallelism at the module level."}, "torch.nn.parallel.DistributedDataParallel": {"Parameters": {"module (Module)": "module to be parallelized", "device_ids (list of python:int or torch.device)": "CUDA devices.\n1) For single-device modules, device_ids can\ncontain exactly one device id, which represents the only\nCUDA device where the input module corresponding to this process resides.\nAlternatively, device_ids can also be None.\n2) For multi-device modules and CPU modules,\ndevice_ids must be None.\nWhen device_ids is None for both cases,\nboth the input data for the forward pass and the actual module\nmust be placed on the correct device.\n(default: None)", "output_device (int or torch.device)": "Device location of output for\nsingle-device CUDA modules. For multi-device modules and\nCPU modules, it must be None, and the module itself\ndictates the output location. (default: device_ids[0]\nfor single-device modules)", "broadcast_buffers (bool)": "Flag that enables syncing (broadcasting)\nbuffers of the module at beginning of the forward\nfunction. (default: True)", "process_group": "The process group to be used for distributed data\nall-reduction. If None, the default process group, which\nis created by torch.distributed.init_process_group(),\nwill be used. (default: None)", "bucket_cap_mb": "DistributedDataParallel will bucket parameters into\nmultiple buckets so that gradient reduction of each\nbucket can potentially overlap with backward computation.\nbucket_cap_mb controls the bucket size in\nMegaBytes (MB). (default: 25)", "find_unused_parameters (bool)": "Traverse the autograd graph from all\ntensors contained in the return value of the\nwrapped module\u2019s forward function. Parameters\nthat don\u2019t receive gradients as part of this\ngraph are preemptively marked as being ready to\nbe reduced. In addition, parameters that may have\nbeen used in the wrapped module\u2019s forward\nfunction but were not part of loss computation and\nthus would also not receive gradients are\npreemptively marked as ready to be reduced.\n(default: False)", "check_reduction": "This argument is deprecated.", "gradient_as_bucket_view (bool)": "When set to True, gradients will be views\npointing to different offsets of allreduce communication\nbuckets. This can reduce peak memory usage, where the\nsaved memory size will be equal to the total gradients\nsize. Moreover, it avoids the overhead of copying between\ngradients and allreduce communication buckets. When\ngradients are views, detach_() cannot be called on the\ngradients. If hitting such errors, please fix it by\nreferring to the zero_grad()\nfunction in torch/optim/optimizer.py as a solution.\nNote that gradients will be views after first iteration, so\nthe peak memory saving should be checked after first iteration.", "static_graph (bool)": "When set to True, DDP knows the trained graph is\nstatic. Static graph means 1) The set of used and unused\nparameters will not change during the whole training loop; in\nthis case, it does not matter whether users set\nfind_unused_parameters = True or not. 2) How the graph is trained\nwill not change during the whole training loop (meaning there is\nno control flow depending on iterations).\nWhen static_graph is set to be True, DDP will support cases that\ncan not be supported in the past:\n1) Reentrant backwards.\n2) Activation checkpointing multiple times.\n3) Activation checkpointing when model has unused parameters.\n4) There are model parameters that are outside of forward function.\n5) Potentially improve performance when there are unused parameters,\nas DDP will not search graph in each iteraton to detect unused\nparameters when static_graph is set to be True.\nTo check whether you can set static_graph to be True, one way is to\ncheck ddp logging data at the end of your previous model training,\nif ddp_logging_data.get(\"can_set_static_graph\") == True, mostly you\ncan set static_graph = True as well.\n\nExample::>>> model_DDP = torch.nn.parallel.DistributedDataParallel(model)\n>>> # Training loop\n>>> .....\n>>> ddp_logging_data = model_DDP._get_ddp_logging_data()\n>>> static_graph = ddp_logging_data.get(\"can_set_static_graph\")"}, "method": {"torch.nn.parallel.DistributedDataParallel.join": {"Parameters": {"divide_by_initial_world_size (bool)": "If True, will divide\ngradients by the initial world_size DDP training was launched\nwith. If False, will compute the effective world size\n(number of ranks that have not depleted their inputs yet) and\ndivide gradients by that during allreduce. Set\ndivide_by_initial_world_size=True to ensure every input\nsample including the uneven inputs have equal weight in terms of\nhow much they contribute to the global gradient. This is\nachieved by always dividing the gradient by the initial\nworld_size even when we encounter uneven inputs. If you set\nthis to False, we divide the gradient by the remaining\nnumber of nodes. This ensures parity with training on a smaller\nworld_size although it also means the uneven inputs would\ncontribute more towards the global gradient. Typically, you\nwould want to set this to True for cases where the last few\ninputs of your training job are uneven. In extreme cases, where\nthere is a large discrepancy in the number of inputs, setting\nthis to False might provide better results.", "enable (bool)": "Whether to enable uneven input detection or not. Pass\nin enable=False to disable in cases where you know that\ninputs are even across participating processes. Default is\nTrue.", "throw_on_early_termination (bool)": "Whether to throw an error\nor continue training when at least one rank has exhausted\ninputs. If True, will throw upon the first rank reaching end\nof data. If False, will continue training with a smaller\neffective world size until all ranks are joined. Note that if\nthis flag is specified, then the flag\ndivide_by_initial_world_size would be ignored. Default\nis False."}, "description": null}, "torch.nn.parallel.DistributedDataParallel.join_hook": {"description": "Returns the DDP join hook, which enables training on uneven inputs by\nshadowing the collective communications in the forward and backward\npasses."}, "torch.nn.parallel.DistributedDataParallel.register_comm_hook": {"description": "Registers a communication hook which is an enhancement that provides a\nflexible hook to users where they can specify how DDP aggregates gradients\nacross multiple workers."}}, "description": "Implements distributed data parallelism that is based on torch.distributed package at the module level."}, "torch.nn.utils.clip_grad_norm_": {"Parameters": {"parameters (Iterable[Tensor] or Tensor)": "an iterable of Tensors or a\nsingle Tensor that will have gradients normalized", "max_norm (float or int)": "max norm of the gradients", "norm_type (float or int)": "type of the used p-norm. Can be 'inf' for\ninfinity norm.", "error_if_nonfinite (bool)": "if True, an error is thrown if the total\nnorm of the gradients from parameters is nan,\ninf, or -inf. Default: False (will switch to True in the future)"}, "Returns": "Total norm of the parameters (viewed as a single vector).\n", "description": "Clips gradient norm of an iterable of parameters."}, "torch.nn.utils.clip_grad_value_": {"Parameters": {"parameters (Iterable[Tensor] or Tensor)": "an iterable of Tensors or a\nsingle Tensor that will have gradients normalized", "clip_value (float or int)": "maximum allowed value of the gradients.\nThe gradients are clipped in the range\n[-clip_value,clip_value]\\left[\\text{-clip\\_value}, \\text{clip\\_value}\\right][-clip_value,clip_value]"}, "description": "Clips gradient of an iterable of parameters at specified value."}, "torch.nn.utils.parameters_to_vector": {"Parameters": {"parameters (Iterable[Tensor])": "an iterator of Tensors that are the\nparameters of a model."}, "Returns": "The parameters represented by a single vector\n", "description": "Convert parameters to one vector"}, "torch.nn.utils.vector_to_parameters": {"Parameters": {"vec (Tensor)": "a single vector represents the parameters of a model.", "parameters (Iterable[Tensor])": "an iterator of Tensors that are the\nparameters of a model."}, "description": "Convert one vector to the parameters"}, "torch.nn.utils.prune.BasePruningMethod": {"method": {"torch.nn.utils.prune.BasePruningMethod.apply": {"Parameters": {"module (nn.Module)": "module containing the tensor to prune", "name (str)": "parameter name within module on which pruning\nwill act.", "args": "arguments passed on to a subclass of\nBasePruningMethod", "importance_scores (torch.Tensor)": "tensor of importance scores (of\nsame shape as module parameter) used to compute mask for pruning.\nThe values in this tensor indicate the importance of the\ncorresponding elements in the parameter being pruned.\nIf unspecified or None, the parameter will be used in its place.", "kwargs": "keyword arguments passed on to a subclass of a\nBasePruningMethod"}, "description": "Adds the forward pre-hook that enables pruning on the fly and\nthe reparametrization of a tensor in terms of the original tensor\nand the pruning mask."}, "torch.nn.utils.prune.BasePruningMethod.apply_mask": {"Parameters": {"module (nn.Module)": "module containing the tensor to prune"}, "Returns": "pruned version of the input tensor\n", "description": "Simply handles the multiplication between the parameter being\npruned and the generated mask.\nFetches the mask and the original tensor from the module\nand returns the pruned version of the tensor."}, "torch.nn.utils.prune.BasePruningMethod.compute_mask": {"Parameters": {"t (torch.Tensor)": "tensor representing the importance scores of the", "to prune. (parameter)": "", "default_mask (torch.Tensor)": "Base mask from previous pruning", "iterations": "", "need to be respected after the new mask is (that)": "", "Same dims as t. (applied.)": ""}, "Returns": "mask to apply to t, of same dims as t\n", "description": null}, "torch.nn.utils.prune.BasePruningMethod.prune": {"Parameters": {"t (torch.Tensor)": "tensor to prune (of same dimensions as\ndefault_mask).", "importance_scores (torch.Tensor)": "tensor of importance scores (of\nsame shape as t) used to compute mask for pruning t.\nThe values in this tensor indicate the importance of the\ncorresponding elements in the t that is being pruned.\nIf unspecified or None, the tensor t will be used in its place.", "default_mask (torch.Tensor, optional)": "mask from previous pruning\niteration, if any. To be considered when determining what\nportion of the tensor that pruning should act on. If None,\ndefault to a mask of ones."}, "Returns": "pruned version of tensor t.\n", "description": null}}, "description": "Abstract base class for creation of new pruning techniques."}, "torch.nn.utils.prune.PruningContainer": {"method": {"torch.nn.utils.prune.PruningContainer.add_pruning_method": {"Parameters": {"method (subclass of BasePruningMethod)": "child pruning method\nto be added to the container."}, "description": null}, "torch.nn.utils.prune.PruningContainer.apply": {"Parameters": {"module (nn.Module)": "module containing the tensor to prune", "name (str)": "parameter name within module on which pruning\nwill act.", "args": "arguments passed on to a subclass of\nBasePruningMethod", "importance_scores (torch.Tensor)": "tensor of importance scores (of\nsame shape as module parameter) used to compute mask for pruning.\nThe values in this tensor indicate the importance of the\ncorresponding elements in the parameter being pruned.\nIf unspecified or None, the parameter will be used in its place.", "kwargs": "keyword arguments passed on to a subclass of a\nBasePruningMethod"}, "description": "Adds the forward pre-hook that enables pruning on the fly and\nthe reparametrization of a tensor in terms of the original tensor\nand the pruning mask."}, "torch.nn.utils.prune.PruningContainer.apply_mask": {"Parameters": {"module (nn.Module)": "module containing the tensor to prune"}, "Returns": "pruned version of the input tensor\n", "description": "Simply handles the multiplication between the parameter being\npruned and the generated mask.\nFetches the mask and the original tensor from the module\nand returns the pruned version of the tensor."}, "torch.nn.utils.prune.PruningContainer.compute_mask": {"Parameters": {"t (torch.Tensor)": "tensor representing the parameter to prune\n(of same dimensions as default_mask).", "default_mask (torch.Tensor)": "mask from previous pruning iteration."}, "Returns": "new mask that combines the effects\nof the default_mask and the new mask from the current\npruning method (of same dimensions as default_mask and\nt).\n", "description": null}, "torch.nn.utils.prune.PruningContainer.prune": {"Parameters": {"t (torch.Tensor)": "tensor to prune (of same dimensions as\ndefault_mask).", "importance_scores (torch.Tensor)": "tensor of importance scores (of\nsame shape as t) used to compute mask for pruning t.\nThe values in this tensor indicate the importance of the\ncorresponding elements in the t that is being pruned.\nIf unspecified or None, the tensor t will be used in its place.", "default_mask (torch.Tensor, optional)": "mask from previous pruning\niteration, if any. To be considered when determining what\nportion of the tensor that pruning should act on. If None,\ndefault to a mask of ones."}, "Returns": "pruned version of tensor t.\n", "description": null}}, "description": "Container holding a sequence of pruning methods for iterative pruning."}, "torch.nn.utils.prune.Identity": {"method": {"torch.nn.utils.prune.Identity.apply": {"Parameters": {"module (nn.Module)": "module containing the tensor to prune", "name (str)": "parameter name within module on which pruning\nwill act."}, "description": "Adds the forward pre-hook that enables pruning on the fly and\nthe reparametrization of a tensor in terms of the original tensor\nand the pruning mask."}, "torch.nn.utils.prune.Identity.apply_mask": {"Parameters": {"module (nn.Module)": "module containing the tensor to prune"}, "Returns": "pruned version of the input tensor\n", "description": "Simply handles the multiplication between the parameter being\npruned and the generated mask.\nFetches the mask and the original tensor from the module\nand returns the pruned version of the tensor."}, "torch.nn.utils.prune.Identity.prune": {"Parameters": {"t (torch.Tensor)": "tensor to prune (of same dimensions as\ndefault_mask).", "importance_scores (torch.Tensor)": "tensor of importance scores (of\nsame shape as t) used to compute mask for pruning t.\nThe values in this tensor indicate the importance of the\ncorresponding elements in the t that is being pruned.\nIf unspecified or None, the tensor t will be used in its place.", "default_mask (torch.Tensor, optional)": "mask from previous pruning\niteration, if any. To be considered when determining what\nportion of the tensor that pruning should act on. If None,\ndefault to a mask of ones."}, "Returns": "pruned version of tensor t.\n", "description": null}}, "description": "Applies pruning reparametrization to the tensor corresponding to the parameter called name in module without actually pruning any units."}, "torch.nn.utils.prune.RandomUnstructured": {"Parameters": {"name (str)": "parameter name within module on which pruning\nwill act.", "amount (int or float)": "quantity of parameters to prune.\nIf float, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune. If int, it represents the\nabsolute number of parameters to prune."}, "method": {"torch.nn.utils.prune.RandomUnstructured.apply": {"Parameters": {"module (nn.Module)": "module containing the tensor to prune", "name (str)": "parameter name within module on which pruning\nwill act.", "amount (int or float)": "quantity of parameters to prune.\nIf float, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune. If int, it represents the\nabsolute number of parameters to prune."}, "description": "Adds the forward pre-hook that enables pruning on the fly and\nthe reparametrization of a tensor in terms of the original tensor\nand the pruning mask."}, "torch.nn.utils.prune.RandomUnstructured.apply_mask": {"Parameters": {"module (nn.Module)": "module containing the tensor to prune"}, "Returns": "pruned version of the input tensor\n", "description": "Simply handles the multiplication between the parameter being\npruned and the generated mask.\nFetches the mask and the original tensor from the module\nand returns the pruned version of the tensor."}, "torch.nn.utils.prune.RandomUnstructured.prune": {"Parameters": {"t (torch.Tensor)": "tensor to prune (of same dimensions as\ndefault_mask).", "importance_scores (torch.Tensor)": "tensor of importance scores (of\nsame shape as t) used to compute mask for pruning t.\nThe values in this tensor indicate the importance of the\ncorresponding elements in the t that is being pruned.\nIf unspecified or None, the tensor t will be used in its place.", "default_mask (torch.Tensor, optional)": "mask from previous pruning\niteration, if any. To be considered when determining what\nportion of the tensor that pruning should act on. If None,\ndefault to a mask of ones."}, "Returns": "pruned version of tensor t.\n", "description": null}}, "description": "Prune (currently unpruned) units in a tensor at random."}, "torch.nn.utils.prune.L1Unstructured": {"Parameters": {"amount (int or float)": "quantity of parameters to prune.\nIf float, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune. If int, it represents the\nabsolute number of parameters to prune."}, "method": {"torch.nn.utils.prune.L1Unstructured.apply": {"Parameters": {"module (nn.Module)": "module containing the tensor to prune", "name (str)": "parameter name within module on which pruning\nwill act.", "amount (int or float)": "quantity of parameters to prune.\nIf float, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune. If int, it represents the\nabsolute number of parameters to prune.", "importance_scores (torch.Tensor)": "tensor of importance scores (of same\nshape as module parameter) used to compute mask for pruning.\nThe values in this tensor indicate the importance of the corresponding\nelements in the parameter being pruned.\nIf unspecified or None, the module parameter will be used in its place."}, "description": "Adds the forward pre-hook that enables pruning on the fly and\nthe reparametrization of a tensor in terms of the original tensor\nand the pruning mask."}, "torch.nn.utils.prune.L1Unstructured.apply_mask": {"Parameters": {"module (nn.Module)": "module containing the tensor to prune"}, "Returns": "pruned version of the input tensor\n", "description": "Simply handles the multiplication between the parameter being\npruned and the generated mask.\nFetches the mask and the original tensor from the module\nand returns the pruned version of the tensor."}, "torch.nn.utils.prune.L1Unstructured.prune": {"Parameters": {"t (torch.Tensor)": "tensor to prune (of same dimensions as\ndefault_mask).", "importance_scores (torch.Tensor)": "tensor of importance scores (of\nsame shape as t) used to compute mask for pruning t.\nThe values in this tensor indicate the importance of the\ncorresponding elements in the t that is being pruned.\nIf unspecified or None, the tensor t will be used in its place.", "default_mask (torch.Tensor, optional)": "mask from previous pruning\niteration, if any. To be considered when determining what\nportion of the tensor that pruning should act on. If None,\ndefault to a mask of ones."}, "Returns": "pruned version of tensor t.\n", "description": null}}, "description": "Prune (currently unpruned) units in a tensor by zeroing out the ones with the lowest L1-norm."}, "torch.nn.utils.prune.RandomStructured": {"Parameters": {"amount (int or float)": "quantity of parameters to prune.\nIf float, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune. If int, it represents the\nabsolute number of parameters to prune.", "dim (int, optional)": "index of the dim along which we define\nchannels to prune. Default: -1."}, "method": {"torch.nn.utils.prune.RandomStructured.apply": {"Parameters": {"module (nn.Module)": "module containing the tensor to prune", "name (str)": "parameter name within module on which pruning\nwill act.", "amount (int or float)": "quantity of parameters to prune.\nIf float, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune. If int, it represents the\nabsolute number of parameters to prune.", "dim (int, optional)": "index of the dim along which we define\nchannels to prune. Default: -1."}, "description": "Adds the forward pre-hook that enables pruning on the fly and\nthe reparametrization of a tensor in terms of the original tensor\nand the pruning mask."}, "torch.nn.utils.prune.RandomStructured.apply_mask": {"Parameters": {"module (nn.Module)": "module containing the tensor to prune"}, "Returns": "pruned version of the input tensor\n", "description": "Simply handles the multiplication between the parameter being\npruned and the generated mask.\nFetches the mask and the original tensor from the module\nand returns the pruned version of the tensor."}, "torch.nn.utils.prune.RandomStructured.compute_mask": {"Parameters": {"t (torch.Tensor)": "tensor representing the parameter to prune", "default_mask (torch.Tensor)": "Base mask from previous pruning\niterations, that need to be respected after the new mask is\napplied. Same dims as t."}, "Returns": "mask to apply to t, of same dims as t\n", "description": null}, "torch.nn.utils.prune.RandomStructured.prune": {"Parameters": {"t (torch.Tensor)": "tensor to prune (of same dimensions as\ndefault_mask).", "importance_scores (torch.Tensor)": "tensor of importance scores (of\nsame shape as t) used to compute mask for pruning t.\nThe values in this tensor indicate the importance of the\ncorresponding elements in the t that is being pruned.\nIf unspecified or None, the tensor t will be used in its place.", "default_mask (torch.Tensor, optional)": "mask from previous pruning\niteration, if any. To be considered when determining what\nportion of the tensor that pruning should act on. If None,\ndefault to a mask of ones."}, "Returns": "pruned version of tensor t.\n", "description": null}}, "description": "Prune entire (currently unpruned) channels in a tensor at random."}, "torch.nn.utils.prune.LnStructured": {"Parameters": {"amount (int or float)": "quantity of channels to prune.\nIf float, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune. If int, it represents the\nabsolute number of parameters to prune.", "n (int, float, inf, -inf, 'fro', 'nuc')": "See documentation of valid\nentries for argument p in torch.norm().", "dim (int, optional)": "index of the dim along which we define\nchannels to prune. Default: -1."}, "method": {"torch.nn.utils.prune.LnStructured.apply": {"Parameters": {"module (nn.Module)": "module containing the tensor to prune", "name (str)": "parameter name within module on which pruning\nwill act.", "amount (int or float)": "quantity of parameters to prune.\nIf float, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune. If int, it represents the\nabsolute number of parameters to prune.", "n (int, float, inf, -inf, 'fro', 'nuc')": "See documentation of valid\nentries for argument p in torch.norm().", "dim (int)": "index of the dim along which we define channels to\nprune.", "importance_scores (torch.Tensor)": "tensor of importance scores (of same\nshape as module parameter) used to compute mask for pruning.\nThe values in this tensor indicate the importance of the corresponding\nelements in the parameter being pruned.\nIf unspecified or None, the module parameter will be used in its place."}, "description": "Adds the forward pre-hook that enables pruning on the fly and\nthe reparametrization of a tensor in terms of the original tensor\nand the pruning mask."}, "torch.nn.utils.prune.LnStructured.apply_mask": {"Parameters": {"module (nn.Module)": "module containing the tensor to prune"}, "Returns": "pruned version of the input tensor\n", "description": "Simply handles the multiplication between the parameter being\npruned and the generated mask.\nFetches the mask and the original tensor from the module\nand returns the pruned version of the tensor."}, "torch.nn.utils.prune.LnStructured.compute_mask": {"Parameters": {"t (torch.Tensor)": "tensor representing the parameter to prune", "default_mask (torch.Tensor)": "Base mask from previous pruning\niterations, that need to be respected after the new mask is\napplied.  Same dims as t."}, "Returns": "mask to apply to t, of same dims as t\n", "description": null}, "torch.nn.utils.prune.LnStructured.prune": {"Parameters": {"t (torch.Tensor)": "tensor to prune (of same dimensions as\ndefault_mask).", "importance_scores (torch.Tensor)": "tensor of importance scores (of\nsame shape as t) used to compute mask for pruning t.\nThe values in this tensor indicate the importance of the\ncorresponding elements in the t that is being pruned.\nIf unspecified or None, the tensor t will be used in its place.", "default_mask (torch.Tensor, optional)": "mask from previous pruning\niteration, if any. To be considered when determining what\nportion of the tensor that pruning should act on. If None,\ndefault to a mask of ones."}, "Returns": "pruned version of tensor t.\n", "description": null}}, "description": "Prune entire (currently unpruned) channels in a tensor based on their Ln-norm."}, "torch.nn.utils.prune.CustomFromMask": {"method": {"torch.nn.utils.prune.CustomFromMask.apply": {"Parameters": {"module (nn.Module)": "module containing the tensor to prune", "name (str)": "parameter name within module on which pruning\nwill act."}, "description": "Adds the forward pre-hook that enables pruning on the fly and\nthe reparametrization of a tensor in terms of the original tensor\nand the pruning mask."}, "torch.nn.utils.prune.CustomFromMask.apply_mask": {"Parameters": {"module (nn.Module)": "module containing the tensor to prune"}, "Returns": "pruned version of the input tensor\n", "description": "Simply handles the multiplication between the parameter being\npruned and the generated mask.\nFetches the mask and the original tensor from the module\nand returns the pruned version of the tensor."}, "torch.nn.utils.prune.CustomFromMask.prune": {"Parameters": {"t (torch.Tensor)": "tensor to prune (of same dimensions as\ndefault_mask).", "importance_scores (torch.Tensor)": "tensor of importance scores (of\nsame shape as t) used to compute mask for pruning t.\nThe values in this tensor indicate the importance of the\ncorresponding elements in the t that is being pruned.\nIf unspecified or None, the tensor t will be used in its place.", "default_mask (torch.Tensor, optional)": "mask from previous pruning\niteration, if any. To be considered when determining what\nportion of the tensor that pruning should act on. If None,\ndefault to a mask of ones."}, "Returns": "pruned version of tensor t.\n", "description": null}}, "description": ""}, "torch.nn.utils.prune.random_unstructured": {"Parameters": {"module (nn.Module)": "module containing the tensor to prune", "name (str)": "parameter name within module on which pruning\nwill act.", "amount (int or float)": "quantity of parameters to prune.\nIf float, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune. If int, it represents the\nabsolute number of parameters to prune."}, "Returns": "modified (i.e. pruned) version of the input module\n", "description": "Prunes tensor corresponding to parameter called name in module by removing the specified amount of (currently unpruned) units selected at random."}, "torch.nn.utils.prune.l1_unstructured": {"Parameters": {"module (nn.Module)": "module containing the tensor to prune", "name (str)": "parameter name within module on which pruning\nwill act.", "amount (int or float)": "quantity of parameters to prune.\nIf float, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune. If int, it represents the\nabsolute number of parameters to prune.", "importance_scores (torch.Tensor)": "tensor of importance scores (of same\nshape as module parameter) used to compute mask for pruning.\nThe values in this tensor indicate the importance of the corresponding\nelements in the parameter being pruned.\nIf unspecified or None, the module parameter will be used in its place."}, "Returns": "modified (i.e. pruned) version of the input module\n", "description": "Prunes tensor corresponding to parameter called name in module by removing the specified amount of (currently unpruned) units with the lowest L1-norm."}, "torch.nn.utils.prune.random_structured": {"Parameters": {"module (nn.Module)": "module containing the tensor to prune", "name (str)": "parameter name within module on which pruning\nwill act.", "amount (int or float)": "quantity of parameters to prune.\nIf float, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune. If int, it represents the\nabsolute number of parameters to prune.", "dim (int)": "index of the dim along which we define channels to prune."}, "Returns": "modified (i.e. pruned) version of the input module\n", "description": "Prunes tensor corresponding to parameter called name in module by removing the specified amount of (currently unpruned) channels along the specified dim selected at random."}, "torch.nn.utils.prune.ln_structured": {"Parameters": {"module (nn.Module)": "module containing the tensor to prune", "name (str)": "parameter name within module on which pruning\nwill act.", "amount (int or float)": "quantity of parameters to prune.\nIf float, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune. If int, it represents the\nabsolute number of parameters to prune.", "n (int, float, inf, -inf, 'fro', 'nuc')": "See documentation of valid\nentries for argument p in torch.norm().", "dim (int)": "index of the dim along which we define channels to prune.", "importance_scores (torch.Tensor)": "tensor of importance scores (of same\nshape as module parameter) used to compute mask for pruning.\nThe values in this tensor indicate the importance of the corresponding\nelements in the parameter being pruned.\nIf unspecified or None, the module parameter will be used in its place."}, "Returns": "modified (i.e. pruned) version of the input module\n", "description": "Prunes tensor corresponding to parameter called name in module by removing the specified amount of (currently unpruned) channels along the specified dim with the lowest Ln-norm."}, "torch.nn.utils.prune.global_unstructured": {"Parameters": {"parameters (Iterable of (module, name) tuples)": "parameters of\nthe model to prune in a global fashion, i.e. by aggregating all\nweights prior to deciding which ones to prune. module must be of\ntype nn.Module, and name must be a string.", "pruning_method (function)": "a valid pruning function from this module,\nor a custom one implemented by the user that satisfies the\nimplementation guidelines and has PRUNING_TYPE='unstructured'.", "importance_scores (dict)": "a dictionary mapping (module, name) tuples to\nthe corresponding parameter\u2019s importance scores tensor. The tensor\nshould be the same shape as the parameter, and is used for computing\nmask for pruning.\nIf unspecified or None, the parameter will be used in place of its\nimportance scores.", "kwargs": "other keyword arguments such as:\namount (int or float): quantity of parameters to prune across the\nspecified parameters.\nIf float, should be between 0.0 and 1.0 and represent the\nfraction of parameters to prune. If int, it represents the\nabsolute number of parameters to prune."}, "description": "Globally prunes tensors corresponding to all parameters in parameters by applying the specified pruning_method."}, "torch.nn.utils.prune.custom_from_mask": {"Parameters": {"module (nn.Module)": "module containing the tensor to prune", "name (str)": "parameter name within module on which pruning\nwill act.", "mask (Tensor)": "binary mask to be applied to the parameter."}, "Returns": "modified (i.e. pruned) version of the input module\n", "description": "Prunes tensor corresponding to parameter called name in module by applying the pre-computed mask in mask."}, "torch.nn.utils.prune.remove": {"Parameters": {"module (nn.Module)": "module containing the tensor to prune", "name (str)": "parameter name within module on which pruning\nwill act."}, "description": "Removes the pruning reparameterization from a module and the pruning method from the forward hook."}, "torch.nn.utils.prune.is_pruned": {"Parameters": {"module (nn.Module)": "object that is either pruned or unpruned"}, "Returns": "binary answer to whether module is pruned.\n", "description": "Check whether module is pruned by looking for forward_pre_hooks in its modules that inherit from the BasePruningMethod."}, "torch.nn.utils.weight_norm": {"Parameters": {"module (Module)": "containing module", "name (str, optional)": "name of weight parameter", "dim (int, optional)": "dimension over which to compute the norm"}, "Returns": "The original module with the weight norm hook\n", "description": "Applies weight normalization to a parameter in the given module."}, "torch.nn.utils.remove_weight_norm": {"Parameters": {"module (Module)": "containing module", "name (str, optional)": "name of weight parameter"}, "description": "Removes the weight normalization reparameterization from a module."}, "torch.nn.utils.spectral_norm": {"Parameters": {"module (nn.Module)": "containing module", "name (str, optional)": "name of weight parameter", "n_power_iterations (int, optional)": "number of power iterations to\ncalculate spectral norm", "eps (float, optional)": "epsilon for numerical stability in\ncalculating norms", "dim (int, optional)": "dimension corresponding to number of outputs,\nthe default is 0, except for modules that are instances of\nConvTranspose{1,2,3}d, when it is 1"}, "Returns": "The original module with the spectral norm hook\n", "description": "Applies spectral normalization to a parameter in the given module."}, "torch.nn.utils.remove_spectral_norm": {"Parameters": {"module (Module)": "containing module", "name (str, optional)": "name of weight parameter"}, "description": "Removes the spectral normalization reparameterization from a module."}, "torch.nn.utils.skip_init": {"Parameters": {"module_cls": "Class object; should be a subclass of torch.nn.Module", "args": "args to pass to the module\u2019s constructor", "kwargs": "kwargs to pass to the module\u2019s constructor"}, "Returns": "Instantiated module with uninitialized parameters / buffers\n", "description": "Given a module class object and args / kwargs, instantiates the module without initializing parameters / buffers."}, "torch.nn.utils.parametrizations.orthogonal": {"Parameters": {"module (nn.Module)": "module on which to register the parametrization.", "name (str, optional)": "name of the tensor to make orthogonal. Default: \"weight\".", "orthogonal_map (str, optional)": "One of the following: \"matrix_exp\", \"cayley\", \"householder\".\nDefault: \"matrix_exp\" if the matrix is square or complex, \"householder\" otherwise.", "use_trivialization (bool, optional)": "whether to use the dynamic trivialization framework.\nDefault: True."}, "Returns": "The original module with an orthogonal parametrization registered to the specified\nweight\n", "description": "Applies an orthogonal or unitary parametrization to a matrix or a batch of matrices."}, "torch.nn.utils.parametrizations.spectral_norm": {"Parameters": {"module (nn.Module)": "containing module", "name (str, optional)": "name of weight parameter. Default: \"weight\".", "n_power_iterations (int, optional)": "number of power iterations to\ncalculate spectral norm. Default: 1.", "eps (float, optional)": "epsilon for numerical stability in\ncalculating norms. Default: 1e-12.", "dim (int, optional)": "dimension corresponding to number of outputs.\nDefault: 0, except for modules that are instances of\nConvTranspose{1,2,3}d, when it is 1"}, "Returns": "The original module with a new parametrization registered to the specified\nweight\n", "description": "Applies spectral normalization to a parameter in the given module."}, "torch.nn.utils.parametrize.register_parametrization": {"Parameters": {"module (nn.Module)": "module on which to register the parametrization", "tensor_name (str)": "name of the parameter or buffer on which to register\nthe parametrization", "parametrization (nn.Module)": "the parametrization to register"}, "description": "Adds a parametrization to a tensor in a module."}, "torch.nn.utils.parametrize.remove_parametrizations": {"Parameters": {"module (nn.Module)": "module from which remove the parametrization", "tensor_name (str)": "name of the parametrization to be removed", "leave_parametrized (bool, optional)": "leave the attribute tensor_name parametrized.\nDefault: True"}, "Returns": "module\n", "description": "Removes the parametrizations on a tensor in a module."}, "torch.nn.utils.parametrize.cached": {"description": "Context manager that enables the caching system within parametrizations registered with register_parametrization()."}, "torch.nn.utils.parametrize.is_parametrized": {"Parameters": {"module (nn.Module)": "module to query", "name (str, optional)": "attribute in the module to query\nDefault: None"}, "description": "Returns True if module has an active parametrization."}, "torch.nn.utils.parametrize.ParametrizationList": {"Parameters": {"modules (sequence)": "sequence of modules representing the parametrizations", "original (Parameter or Tensor)": "parameter or buffer that is parametrized", "unsafe (bool)": "a boolean flag that denotes whether the parametrization\nmay change the dtype and shape of the tensor. Default: False\nWarning: the parametrization is not checked for consistency upon registration.\nEnable this flag at your own risk."}, "method": {"torch.nn.utils.parametrize.ParametrizationList.right_inverse": {"Parameters": {"value (Tensor)": "Value to which initialize the module"}, "description": null}}, "description": "A sequential container that holds and manages the original or original0, original1, ."}, "torch.nn.utils.rnn.PackedSequence": {"description": "Holds the data and list of batch_sizes of a packed sequence."}, "torch.nn.utils.rnn.pack_padded_sequence": {"Parameters": {"input (Tensor)": "padded batch of variable length sequences.", "lengths (Tensor or list(int))": "list of sequence lengths of each batch\nelement (must be on the CPU if provided as a tensor).", "batch_first (bool, optional)": "if True, the input is expected in B x T x *\nformat.", "enforce_sorted (bool, optional)": "if True, the input is expected to\ncontain sequences sorted by length in a decreasing order. If\nFalse, the input will get sorted unconditionally. Default: True."}, "Returns": "a PackedSequence object\n", "description": "Packs a Tensor containing padded sequences of variable length."}, "torch.nn.utils.rnn.pad_packed_sequence": {"Parameters": {"sequence (PackedSequence)": "batch to pad", "batch_first (bool, optional)": "if True, the output will be in B x T x *\nformat.", "padding_value (float, optional)": "values for padded elements.", "total_length (int, optional)": "if not None, the output will be padded to\nhave length total_length. This method will throw ValueError\nif total_length is less than the max sequence length in\nsequence."}, "Returns": "Tuple of Tensor containing the padded sequence, and a Tensor\ncontaining the list of lengths of each sequence in the batch.\nBatch elements will be re-ordered as they were ordered originally when\nthe batch was passed to pack_padded_sequence or pack_sequence.\n", "description": "Pads a packed batch of variable length sequences."}, "torch.nn.utils.rnn.pad_sequence": {"Parameters": {"sequences (list[Tensor])": "list of variable length sequences.", "batch_first (bool, optional)": "output will be in B x T x * if True, or in\nT x B x * otherwise. Default: False.", "padding_value (float, optional)": "value for padded elements. Default: 0."}, "Returns": "Tensor of size T x B x * if batch_first is False.\nTensor of size B x T x * otherwise\n", "description": "Pad a list of variable length Tensors with padding_value"}, "torch.nn.utils.rnn.pack_sequence": {"Parameters": {"sequences (list[Tensor])": "A list of sequences of decreasing length.", "enforce_sorted (bool, optional)": "if True, checks that the input\ncontains sequences sorted by length in a decreasing order. If\nFalse, this condition is not checked. Default: True."}, "Returns": "a PackedSequence object\n", "description": "Packs a list of variable length Tensors"}, "torch.nn.Flatten": {"Parameters": {"start_dim": "first dim to flatten (default = 1).", "end_dim": "last dim to flatten (default = -1)."}, "description": "Flattens a contiguous range of dims into a tensor."}, "torch.nn.Unflatten": {"Parameters": {"dim (Union[int, str])": "Dimension to be unflattened", "unflattened_size (Union[torch.Size, Tuple, List, NamedShape])": "New shape of the unflattened dimension"}, "description": "Unflattens a tensor dim expanding it to a desired shape."}, "torch.nn.modules.lazy.LazyModuleMixin": {"description": "A mixin for modules that lazily initialize parameters, also known as \u201clazy modules.\u201d"}, "torch.nn.functional.conv1d": {"Parameters": {"input": "input tensor of shape (minibatch,in_channels,iW)(\\text{minibatch} , \\text{in\\_channels} , iW)(minibatch,in_channels,iW)", "weight": "filters of shape (out_channels,in_channelsgroups,kW)(\\text{out\\_channels} , \\frac{\\text{in\\_channels}}{\\text{groups}} , kW)(out_channels,groupsin_channels\u200b,kW)", "bias": "optional bias of shape (out_channels)(\\text{out\\_channels})(out_channels). Default: None", "stride": "the stride of the convolving kernel. Can be a single number or\na one-element tuple (sW,). Default: 1", "padding": "implicit paddings on both sides of the input. Can be a string {\u2018valid\u2019, \u2018same\u2019},\nsingle number or a one-element tuple (padW,). Default: 0\npadding='valid' is the same as no padding. padding='same' pads\nthe input so the output has the same shape as the input. However, this mode\ndoesn\u2019t support any stride values other than 1.\n\nWarning\nFor padding='same', if the weight is even-length and\ndilation is odd in any dimension, a full pad() operation\nmay be needed internally. Lowering performance.", "dilation": "the spacing between kernel elements. Can be a single number or\na one-element tuple (dW,). Default: 1", "groups": "split input into groups, in_channels\\text{in\\_channels}in_channels should be divisible by\nthe number of groups. Default: 1"}, "description": "Applies a 1D convolution over an input signal composed of several input planes."}, "torch.nn.functional.conv2d": {"Parameters": {"input": "input tensor of shape (minibatch,in_channels,iH,iW)(\\text{minibatch} , \\text{in\\_channels} , iH , iW)(minibatch,in_channels,iH,iW)", "weight": "filters of shape (out_channels,in_channelsgroups,kH,kW)(\\text{out\\_channels} , \\frac{\\text{in\\_channels}}{\\text{groups}} , kH , kW)(out_channels,groupsin_channels\u200b,kH,kW)", "bias": "optional bias tensor of shape (out_channels)(\\text{out\\_channels})(out_channels). Default: None", "stride": "the stride of the convolving kernel. Can be a single number or a\ntuple (sH, sW). Default: 1", "padding": "implicit paddings on both sides of the input. Can be a string {\u2018valid\u2019, \u2018same\u2019},\nsingle number or a tuple (padH, padW). Default: 0\npadding='valid' is the same as no padding. padding='same' pads\nthe input so the output has the same shape as the input. However, this mode\ndoesn\u2019t support any stride values other than 1.\n\nWarning\nFor padding='same', if the weight is even-length and\ndilation is odd in any dimension, a full pad() operation\nmay be needed internally. Lowering performance.", "dilation": "the spacing between kernel elements. Can be a single number or\na tuple (dH, dW). Default: 1", "groups": "split input into groups, in_channels\\text{in\\_channels}in_channels should be divisible by the\nnumber of groups. Default: 1"}, "description": "Applies a 2D convolution over an input image composed of several input planes."}, "torch.nn.functional.conv3d": {"Parameters": {"input": "input tensor of shape (minibatch,in_channels,iT,iH,iW)(\\text{minibatch} , \\text{in\\_channels} , iT , iH , iW)(minibatch,in_channels,iT,iH,iW)", "weight": "filters of shape (out_channels,in_channelsgroups,kT,kH,kW)(\\text{out\\_channels} , \\frac{\\text{in\\_channels}}{\\text{groups}} , kT , kH , kW)(out_channels,groupsin_channels\u200b,kT,kH,kW)", "bias": "optional bias tensor of shape (out_channels)(\\text{out\\_channels})(out_channels). Default: None", "stride": "the stride of the convolving kernel. Can be a single number or a\ntuple (sT, sH, sW). Default: 1", "padding": "implicit paddings on both sides of the input. Can be a string {\u2018valid\u2019, \u2018same\u2019},\nsingle number or a tuple (padT, padH, padW). Default: 0\npadding='valid' is the same as no padding. padding='same' pads\nthe input so the output has the same shape as the input. However, this mode\ndoesn\u2019t support any stride values other than 1.\n\nWarning\nFor padding='same', if the weight is even-length and\ndilation is odd in any dimension, a full pad() operation\nmay be needed internally. Lowering performance.", "dilation": "the spacing between kernel elements. Can be a single number or\na tuple (dT, dH, dW). Default: 1", "groups": "split input into groups, in_channels\\text{in\\_channels}in_channels should be divisible by\nthe number of groups. Default: 1"}, "description": "Applies a 3D convolution over an input image composed of several input planes."}, "torch.nn.functional.conv_transpose1d": {"Parameters": {"input": "input tensor of shape (minibatch,in_channels,iW)(\\text{minibatch} , \\text{in\\_channels} , iW)(minibatch,in_channels,iW)", "weight": "filters of shape (in_channels,out_channelsgroups,kW)(\\text{in\\_channels} , \\frac{\\text{out\\_channels}}{\\text{groups}} , kW)(in_channels,groupsout_channels\u200b,kW)", "bias": "optional bias of shape (out_channels)(\\text{out\\_channels})(out_channels). Default: None", "stride": "the stride of the convolving kernel. Can be a single number or a\ntuple (sW,). Default: 1", "padding": "dilation * (kernel_size - 1) - padding zero-padding will be added to both\nsides of each dimension in the input. Can be a single number or a tuple\n(padW,). Default: 0", "output_padding": "additional size added to one side of each dimension in the\noutput shape. Can be a single number or a tuple (out_padW). Default: 0", "groups": "split input into groups, in_channels\\text{in\\_channels}in_channels should be divisible by the\nnumber of groups. Default: 1", "dilation": "the spacing between kernel elements. Can be a single number or\na tuple (dW,). Default: 1"}, "description": "Applies a 1D transposed convolution operator over an input signal composed of several input planes, sometimes also called \u201cdeconvolution\u201d."}, "torch.nn.functional.conv_transpose2d": {"Parameters": {"input": "input tensor of shape (minibatch,in_channels,iH,iW)(\\text{minibatch} , \\text{in\\_channels} , iH , iW)(minibatch,in_channels,iH,iW)", "weight": "filters of shape (in_channels,out_channelsgroups,kH,kW)(\\text{in\\_channels} , \\frac{\\text{out\\_channels}}{\\text{groups}} , kH , kW)(in_channels,groupsout_channels\u200b,kH,kW)", "bias": "optional bias of shape (out_channels)(\\text{out\\_channels})(out_channels). Default: None", "stride": "the stride of the convolving kernel. Can be a single number or a\ntuple (sH, sW). Default: 1", "padding": "dilation * (kernel_size - 1) - padding zero-padding will be added to both\nsides of each dimension in the input. Can be a single number or a tuple\n(padH, padW). Default: 0", "output_padding": "additional size added to one side of each dimension in the\noutput shape. Can be a single number or a tuple (out_padH, out_padW).\nDefault: 0", "groups": "split input into groups, in_channels\\text{in\\_channels}in_channels should be divisible by the\nnumber of groups. Default: 1", "dilation": "the spacing between kernel elements. Can be a single number or\na tuple (dH, dW). Default: 1"}, "description": "Applies a 2D transposed convolution operator over an input image composed of several input planes, sometimes also called \u201cdeconvolution\u201d."}, "torch.nn.functional.conv_transpose3d": {"Parameters": {"input": "input tensor of shape (minibatch,in_channels,iT,iH,iW)(\\text{minibatch} , \\text{in\\_channels} , iT , iH , iW)(minibatch,in_channels,iT,iH,iW)", "weight": "filters of shape (in_channels,out_channelsgroups,kT,kH,kW)(\\text{in\\_channels} , \\frac{\\text{out\\_channels}}{\\text{groups}} , kT , kH , kW)(in_channels,groupsout_channels\u200b,kT,kH,kW)", "bias": "optional bias of shape (out_channels)(\\text{out\\_channels})(out_channels). Default: None", "stride": "the stride of the convolving kernel. Can be a single number or a\ntuple (sT, sH, sW). Default: 1", "padding": "dilation * (kernel_size - 1) - padding zero-padding will be added to both\nsides of each dimension in the input. Can be a single number or a tuple\n(padT, padH, padW). Default: 0", "output_padding": "additional size added to one side of each dimension in the\noutput shape. Can be a single number or a tuple\n(out_padT, out_padH, out_padW). Default: 0", "groups": "split input into groups, in_channels\\text{in\\_channels}in_channels should be divisible by the\nnumber of groups. Default: 1", "dilation": "the spacing between kernel elements. Can be a single number or\na tuple (dT, dH, dW). Default: 1"}, "description": "Applies a 3D transposed convolution operator over an input image composed of several input planes, sometimes also called \u201cdeconvolution\u201d"}, "torch.nn.functional.unfold": {"description": "Extracts sliding local blocks from a batched input tensor."}, "torch.nn.functional.fold": {"description": "Combines an array of sliding local blocks into a large containing tensor."}, "torch.nn.functional.avg_pool1d": {"Parameters": {"input": "input tensor of shape (minibatch,in_channels,iW)(\\text{minibatch} , \\text{in\\_channels} , iW)(minibatch,in_channels,iW)", "kernel_size": "the size of the window. Can be a single number or a\ntuple (kW,)", "stride": "the stride of the window. Can be a single number or a tuple\n(sW,). Default: kernel_size", "padding": "implicit zero paddings on both sides of the input. Can be a\nsingle number or a tuple (padW,). Default: 0", "ceil_mode": "when True, will use ceil instead of floor to compute the\noutput shape. Default: False", "count_include_pad": "when True, will include the zero-padding in the\naveraging calculation. Default: True"}, "description": "Applies a 1D average pooling over an input signal composed of several input planes."}, "torch.nn.functional.avg_pool2d": {"Parameters": {"input": "input tensor (minibatch,in_channels,iH,iW)(\\text{minibatch} , \\text{in\\_channels} , iH , iW)(minibatch,in_channels,iH,iW)", "kernel_size": "size of the pooling region. Can be a single number or a\ntuple (kH, kW)", "stride": "stride of the pooling operation. Can be a single number or a\ntuple (sH, sW). Default: kernel_size", "padding": "implicit zero paddings on both sides of the input. Can be a\nsingle number or a tuple (padH, padW). Default: 0", "ceil_mode": "when True, will use ceil instead of floor in the formula\nto compute the output shape. Default: False", "count_include_pad": "when True, will include the zero-padding in the\naveraging calculation. Default: True", "divisor_override": "if specified, it will be used as divisor, otherwise\nsize of the pooling region will be used. Default: None"}, "description": "Applies 2D average-pooling operation in kH\u00d7kWkH \\times kWkH\u00d7kW regions by step size sH\u00d7sWsH \\times sWsH\u00d7sW steps."}, "torch.nn.functional.avg_pool3d": {"Parameters": {"input": "input tensor (minibatch,in_channels,iT\u00d7iH,iW)(\\text{minibatch} , \\text{in\\_channels} , iT \\times iH , iW)(minibatch,in_channels,iT\u00d7iH,iW)", "kernel_size": "size of the pooling region. Can be a single number or a\ntuple (kT, kH, kW)", "stride": "stride of the pooling operation. Can be a single number or a\ntuple (sT, sH, sW). Default: kernel_size", "padding": "implicit zero paddings on both sides of the input. Can be a\nsingle number or a tuple (padT, padH, padW), Default: 0", "ceil_mode": "when True, will use ceil instead of floor in the formula\nto compute the output shape", "count_include_pad": "when True, will include the zero-padding in the\naveraging calculation", "divisor_override": "if specified, it will be used as divisor, otherwise\nsize of the pooling region will be used. Default: None"}, "description": "Applies 3D average-pooling operation in kT\u00d7kH\u00d7kWkT \\times kH \\times kWkT\u00d7kH\u00d7kW regions by step size sT\u00d7sH\u00d7sWsT \\times sH \\times sWsT\u00d7sH\u00d7sW steps."}, "torch.nn.functional.max_pool1d": {"Parameters": {"input": "input tensor of shape (minibatch,in_channels,iW)(\\text{minibatch} , \\text{in\\_channels} , iW)(minibatch,in_channels,iW), minibatch dim optional.", "kernel_size": "the size of the window. Can be a single number or a\ntuple (kW,)", "stride": "the stride of the window. Can be a single number or a tuple\n(sW,). Default: kernel_size", "padding": "Implicit negative infinity padding to be added on both sides, must be >= 0 and <= kernel_size / 2.", "dilation": "The stride between elements within a sliding window, must be > 0.", "ceil_mode": "If True, will use ceil instead of floor to compute the output shape. This\nensures that every element in the input tensor is covered by a sliding window.", "return_indices": "If True, will return the argmax along with the max values.\nUseful for torch.nn.functional.max_unpool1d later"}, "description": "Applies a 1D max pooling over an input signal composed of several input planes."}, "torch.nn.functional.max_pool2d": {"Parameters": {"input": "input tensor (minibatch,in_channels,iH,iW)(\\text{minibatch} , \\text{in\\_channels} , iH , iW)(minibatch,in_channels,iH,iW), minibatch dim optional.", "kernel_size": "size of the pooling region. Can be a single number or a\ntuple (kH, kW)", "stride": "stride of the pooling operation. Can be a single number or a\ntuple (sH, sW). Default: kernel_size", "padding": "Implicit negative infinity padding to be added on both sides, must be >= 0 and <= kernel_size / 2.", "dilation": "The stride between elements within a sliding window, must be > 0.", "ceil_mode": "If True, will use ceil instead of floor to compute the output shape. This\nensures that every element in the input tensor is covered by a sliding window.", "return_indices": "If True, will return the argmax along with the max values.\nUseful for torch.nn.functional.max_unpool2d later"}, "description": "Applies a 2D max pooling over an input signal composed of several input planes."}, "torch.nn.functional.max_pool3d": {"Parameters": {"input": "input tensor (minibatch,in_channels,iD,iH,iW)(\\text{minibatch} , \\text{in\\_channels} , iD, iH , iW)(minibatch,in_channels,iD,iH,iW), minibatch dim optional.", "kernel_size": "size of the pooling region. Can be a single number or a\ntuple (kT, kH, kW)", "stride": "stride of the pooling operation. Can be a single number or a\ntuple (sT, sH, sW). Default: kernel_size", "padding": "Implicit negative infinity padding to be added on both sides, must be >= 0 and <= kernel_size / 2.", "dilation": "The stride between elements within a sliding window, must be > 0.", "ceil_mode": "If True, will use ceil instead of floor to compute the output shape. This\nensures that every element in the input tensor is covered by a sliding window.", "return_indices": "If True, will return the argmax along with the max values.\nUseful for torch.nn.functional.max_unpool3d later"}, "description": "Applies a 3D max pooling over an input signal composed of several input planes."}, "torch.nn.functional.max_unpool1d": {"description": "Computes a partial inverse of MaxPool1d."}, "torch.nn.functional.max_unpool2d": {"description": "Computes a partial inverse of MaxPool2d."}, "torch.nn.functional.max_unpool3d": {"description": "Computes a partial inverse of MaxPool3d."}, "torch.nn.functional.lp_pool1d": {"description": "Applies a 1D power-average pooling over an input signal composed of several input planes."}, "torch.nn.functional.lp_pool2d": {"description": "Applies a 2D power-average pooling over an input signal composed of several input planes."}, "torch.nn.functional.adaptive_max_pool1d": {"Parameters": {"output_size": "the target output size (single integer)", "return_indices": "whether to return pooling indices. Default: False"}, "description": "Applies a 1D adaptive max pooling over an input signal composed of several input planes."}, "torch.nn.functional.adaptive_max_pool2d": {"Parameters": {"output_size": "the target output size (single integer or\ndouble-integer tuple)", "return_indices": "whether to return pooling indices. Default: False"}, "description": "Applies a 2D adaptive max pooling over an input signal composed of several input planes."}, "torch.nn.functional.adaptive_max_pool3d": {"Parameters": {"output_size": "the target output size (single integer or\ntriple-integer tuple)", "return_indices": "whether to return pooling indices. Default: False"}, "description": "Applies a 3D adaptive max pooling over an input signal composed of several input planes."}, "torch.nn.functional.adaptive_avg_pool1d": {"Parameters": {"output_size": "the target output size (single integer)"}, "description": "Applies a 1D adaptive average pooling over an input signal composed of several input planes."}, "torch.nn.functional.adaptive_avg_pool2d": {"Parameters": {"output_size": "the target output size (single integer or\ndouble-integer tuple)"}, "description": "Applies a 2D adaptive average pooling over an input signal composed of several input planes."}, "torch.nn.functional.adaptive_avg_pool3d": {"Parameters": {"output_size": "the target output size (single integer or\ntriple-integer tuple)"}, "description": "Applies a 3D adaptive average pooling over an input signal composed of several input planes."}, "torch.nn.functional.fractional_max_pool2d": {"Parameters": {"kernel_size": "the size of the window to take a max over.\nCan be a single number kkk (for a square kernel of k\u00d7kk \\times kk\u00d7k)\nor a tuple (kH, kW)", "output_size": "the target output size of the image of the form oH\u00d7oWoH \\times oWoH\u00d7oW.\nCan be a tuple (oH, oW) or a single number oHoHoH for a square image oH\u00d7oHoH \\times oHoH\u00d7oH", "output_ratio": "If one wants to have an output size as a ratio of the input size, this option can be given.\nThis has to be a number or tuple in the range (0, 1)", "return_indices": "if True, will return the indices along with the outputs.\nUseful to pass to max_unpool2d()."}, "description": "Applies 2D fractional max pooling over an input signal composed of several input planes."}, "torch.nn.functional.fractional_max_pool3d": {"Parameters": {"kernel_size": "the size of the window to take a max over.\nCan be a single number kkk (for a square kernel of k\u00d7k\u00d7kk \\times k \\times kk\u00d7k\u00d7k)\nor a tuple (kT, kH, kW)", "output_size": "the target output size of the form oT\u00d7oH\u00d7oWoT \\times oH \\times oWoT\u00d7oH\u00d7oW.\nCan be a tuple (oT, oH, oW) or a single number oHoHoH for a cubic output\noH\u00d7oH\u00d7oHoH \\times oH \\times oHoH\u00d7oH\u00d7oH", "output_ratio": "If one wants to have an output size as a ratio of the input size, this option can be given.\nThis has to be a number or tuple in the range (0, 1)", "return_indices": "if True, will return the indices along with the outputs.\nUseful to pass to max_unpool3d()."}, "description": "Applies 3D fractional max pooling over an input signal composed of several input planes."}, "torch.nn.functional.threshold": {"description": "Thresholds each element of the input Tensor."}, "torch.nn.functional.threshold_": {"description": "In-place version of threshold()."}, "torch.nn.functional.relu": {"description": "Applies the rectified linear unit function element-wise."}, "torch.nn.functional.relu_": {"description": "In-place version of relu()."}, "torch.nn.functional.hardtanh": {"description": "Applies the HardTanh function element-wise."}, "torch.nn.functional.hardtanh_": {"description": "In-place version of hardtanh()."}, "torch.nn.functional.hardswish": {"description": "Applies the hardswish function, element-wise, as described in the paper:"}, "torch.nn.functional.relu6": {"description": "Applies the element-wise function ReLU6(x)=min\u2061(max\u2061(0,x),6)\\text{ReLU6}(x) = \\min(\\max(0,x), 6)ReLU6(x)=min(max(0,x),6)."}, "torch.nn.functional.elu": {"description": "Applies element-wise, ELU(x)=max\u2061(0,x)+min\u2061(0,\u03b1\u2217(exp\u2061(x)\u22121))\\text{ELU}(x) = \\max(0,x) + \\min(0, \\alpha * (\\exp(x) - 1))ELU(x)=max(0,x)+min(0,\u03b1\u2217(exp(x)\u22121))."}, "torch.nn.functional.elu_": {"description": "In-place version of elu()."}, "torch.nn.functional.selu": {"description": "Applies element-wise, SELU(x)=scale\u2217(max\u2061(0,x)+min\u2061(0,\u03b1\u2217(exp\u2061(x)\u22121)))\\text{SELU}(x) = scale * (\\max(0,x) + \\min(0, \\alpha * (\\exp(x) - 1)))SELU(x)=scale\u2217(max(0,x)+min(0,\u03b1\u2217(exp(x)\u22121))), with \u03b1=1.6732632423543772848170429916717\\alpha=1.6732632423543772848170429916717\u03b1=1.6732632423543772848170429916717 and scale=1.0507009873554804934193349852946scale=1.0507009873554804934193349852946scale=1.0507009873554804934193349852946."}, "torch.nn.functional.celu": {"description": "Applies element-wise, CELU(x)=max\u2061(0,x)+min\u2061(0,\u03b1\u2217(exp\u2061(x/\u03b1)\u22121))\\text{CELU}(x) = \\max(0,x) + \\min(0, \\alpha * (\\exp(x/\\alpha) - 1))CELU(x)=max(0,x)+min(0,\u03b1\u2217(exp(x/\u03b1)\u22121))."}, "torch.nn.functional.leaky_relu": {"description": "Applies element-wise, LeakyReLU(x)=max\u2061(0,x)+negative_slope\u2217min\u2061(0,x)\\text{LeakyReLU}(x) = \\max(0, x) + \\text{negative\\_slope} * \\min(0, x)LeakyReLU(x)=max(0,x)+negative_slope\u2217min(0,x)"}, "torch.nn.functional.leaky_relu_": {"description": "In-place version of leaky_relu()."}, "torch.nn.functional.prelu": {"description": "Applies element-wise the function PReLU(x)=max\u2061(0,x)+weight\u2217min\u2061(0,x)\\text{PReLU}(x) = \\max(0,x) + \\text{weight} * \\min(0,x)PReLU(x)=max(0,x)+weight\u2217min(0,x) where weight is a learnable parameter."}, "torch.nn.functional.rrelu": {"description": "Randomized leaky ReLU."}, "torch.nn.functional.rrelu_": {"description": "In-place version of rrelu()."}, "torch.nn.functional.glu": {"Parameters": {"input (Tensor)": "input tensor", "dim (int)": "dimension on which to split the input. Default: -1"}, "description": "The gated linear unit."}, "torch.nn.functional.gelu": {"description": "Applies element-wise the function GELU(x)=x\u2217\u03a6(x)\\text{GELU}(x) = x * \\Phi(x)GELU(x)=x\u2217\u03a6(x)"}, "torch.nn.functional.logsigmoid": {"description": "Applies element-wise LogSigmoid(xi)=log\u2061(11+exp\u2061(\u2212xi))\\text{LogSigmoid}(x_i) = \\log \\left(\\frac{1}{1 + \\exp(-x_i)}\\right)LogSigmoid(xi\u200b)=log(1+exp(\u2212xi\u200b)1\u200b)"}, "torch.nn.functional.hardshrink": {"description": "Applies the hard shrinkage function element-wise"}, "torch.nn.functional.tanhshrink": {"description": "Applies element-wise, Tanhshrink(x)=x\u2212Tanh(x)\\text{Tanhshrink}(x) = x - \\text{Tanh}(x)Tanhshrink(x)=x\u2212Tanh(x)"}, "torch.nn.functional.softsign": {"description": "Applies element-wise, the function SoftSign(x)=x1+\u2223x\u2223\\text{SoftSign}(x) = \\frac{x}{1 + |x|}SoftSign(x)=1+\u2223x\u2223x\u200b"}, "torch.nn.functional.softplus": {"description": "Applies element-wise, the function Softplus(x)=1\u03b2\u2217log\u2061(1+exp\u2061(\u03b2\u2217x))\\text{Softplus}(x) = \\frac{1}{\\beta} * \\log(1 + \\exp(\\beta * x))Softplus(x)=\u03b21\u200b\u2217log(1+exp(\u03b2\u2217x))."}, "torch.nn.functional.softmin": {"Parameters": {"input (Tensor)": "input", "dim (int)": "A dimension along which softmin will be computed (so every slice\nalong dim will sum to 1).", "dtype (torch.dtype, optional)": "the desired data type of returned tensor.\nIf specified, the input tensor is casted to dtype before the operation\nis performed. This is useful for preventing data type overflows. Default: None."}, "description": "Applies a softmin function."}, "torch.nn.functional.softmax": {"Parameters": {"input (Tensor)": "input", "dim (int)": "A dimension along which softmax will be computed.", "dtype (torch.dtype, optional)": "the desired data type of returned tensor.\nIf specified, the input tensor is casted to dtype before the operation\nis performed. This is useful for preventing data type overflows. Default: None."}, "description": "Applies a softmax function."}, "torch.nn.functional.softshrink": {"description": "Applies the soft shrinkage function elementwise"}, "torch.nn.functional.gumbel_softmax": {"Parameters": {"logits": "[\u2026, num_features] unnormalized log probabilities", "tau": "non-negative scalar temperature", "hard": "if True, the returned samples will be discretized as one-hot vectors,\nbut will be differentiated as if it is the soft sample in autograd", "dim (int)": "A dimension along which softmax will be computed. Default: -1."}, "Returns": "Sampled tensor of same shape as logits from the Gumbel-Softmax distribution.\nIf hard=True, the returned samples will be one-hot, otherwise they will\nbe probability distributions that sum to 1 across dim.\n", "description": "Samples from the Gumbel-Softmax distribution (Link 1 Link 2) and optionally discretizes."}, "torch.nn.functional.log_softmax": {"Parameters": {"input (Tensor)": "input", "dim (int)": "A dimension along which log_softmax will be computed.", "dtype (torch.dtype, optional)": "the desired data type of returned tensor.\nIf specified, the input tensor is cast to dtype before the operation\nis performed. This is useful for preventing data type overflows. Default: None."}, "description": "Applies a softmax followed by a logarithm."}, "torch.nn.functional.tanh": {"description": "Applies element-wise, Tanh(x)=tanh\u2061(x)=exp\u2061(x)\u2212exp\u2061(\u2212x)exp\u2061(x)+exp\u2061(\u2212x)\\text{Tanh}(x) = \\tanh(x) = \\frac{\\exp(x) - \\exp(-x)}{\\exp(x) + \\exp(-x)}Tanh(x)=tanh(x)=exp(x)+exp(\u2212x)exp(x)\u2212exp(\u2212x)\u200b"}, "torch.nn.functional.sigmoid": {"description": "Applies the element-wise function Sigmoid(x)=11+exp\u2061(\u2212x)\\text{Sigmoid}(x) = \\frac{1}{1 + \\exp(-x)}Sigmoid(x)=1+exp(\u2212x)1\u200b"}, "torch.nn.functional.hardsigmoid": {"Parameters": {"inplace": "If set to True, will do this operation in-place. Default: False"}, "description": "Applies the element-wise function"}, "torch.nn.functional.silu": {"description": "Applies the Sigmoid Linear Unit (SiLU) function, element-wise."}, "torch.nn.functional.mish": {"description": "Applies the Mish function, element-wise."}, "torch.nn.functional.batch_norm": {"description": "Applies Batch Normalization for each channel across a batch of data."}, "torch.nn.functional.group_norm": {"description": "Applies Group Normalization for last certain number of dimensions."}, "torch.nn.functional.instance_norm": {"description": "Applies Instance Normalization for each channel in each data sample in a batch."}, "torch.nn.functional.layer_norm": {"description": "Applies Layer Normalization for last certain number of dimensions."}, "torch.nn.functional.local_response_norm": {"description": "Applies local response normalization over an input signal composed of several input planes, where channels occupy the second dimension."}, "torch.nn.functional.normalize": {"Parameters": {"input": "input tensor of any shape", "p (float)": "the exponent value in the norm formulation. Default: 2", "dim (int)": "the dimension to reduce. Default: 1", "eps (float)": "small value to avoid division by zero. Default: 1e-12", "out (Tensor, optional)": "the output tensor. If out is used, this\noperation won\u2019t be differentiable."}, "description": "Performs LpL_pLp\u200b normalization of inputs over specified dimension."}, "torch.nn.functional.linear": {"description": "Applies a linear transformation to the incoming data: y=xAT+by = xA^T + by=xAT+b."}, "torch.nn.functional.bilinear": {"description": "Applies a bilinear transformation to the incoming data: y=x1TAx2+by = x_1^T A x_2 + by=x1T\u200bAx2\u200b+b"}, "torch.nn.functional.dropout": {"Parameters": {"p": "probability of an element to be zeroed. Default: 0.5", "training": "apply dropout if is True. Default: True", "inplace": "If set to True, will do this operation in-place. Default: False"}, "description": "During training, randomly zeroes some of the elements of the input tensor with probability p using samples from a Bernoulli distribution."}, "torch.nn.functional.alpha_dropout": {"description": "Applies alpha dropout to the input."}, "torch.nn.functional.feature_alpha_dropout": {"Parameters": {"p": "dropout probability of a channel to be zeroed. Default: 0.5", "training": "apply dropout if is True. Default: True", "inplace": "If set to True, will do this operation in-place. Default: False"}, "description": "Randomly masks out entire channels (a channel is a feature map, e.g."}, "torch.nn.functional.dropout2d": {"Parameters": {"p": "probability of a channel to be zeroed. Default: 0.5", "training": "apply dropout if is True. Default: True", "inplace": "If set to True, will do this operation in-place. Default: False"}, "description": "Randomly zero out entire channels (a channel is a 2D feature map, e.g., the jjj-th channel of the iii-th sample in the batched input is a 2D tensor input[i,j]\\text{input}[i, j]input[i,j]) of the input tensor)."}, "torch.nn.functional.dropout3d": {"Parameters": {"p": "probability of a channel to be zeroed. Default: 0.5", "training": "apply dropout if is True. Default: True", "inplace": "If set to True, will do this operation in-place. Default: False"}, "description": "Randomly zero out entire channels (a channel is a 3D feature map, e.g., the jjj-th channel of the iii-th sample in the batched input is a 3D tensor input[i,j]\\text{input}[i, j]input[i,j]) of the input tensor)."}, "torch.nn.functional.embedding": {"Parameters": {"input (LongTensor)": "Tensor containing indices into the embedding matrix", "weight (Tensor)": "The embedding matrix with number of rows equal to the maximum possible index + 1,\nand number of columns equal to the embedding size", "padding_idx (int, optional)": "If specified, the entries at padding_idx do not contribute to the gradient;\ntherefore, the embedding vector at padding_idx is not updated during training,\ni.e. it remains as a fixed \u201cpad\u201d.", "max_norm (float, optional)": "If given, each embedding vector with norm larger than max_norm\nis renormalized to have norm max_norm.\nNote: this will modify weight in-place.", "norm_type (float, optional)": "The p of the p-norm to compute for the max_norm option. Default 2.", "scale_grad_by_freq (boolean, optional)": "If given, this will scale gradients by the inverse of frequency of\nthe words in the mini-batch. Default False.", "sparse (bool, optional)": "If True, gradient w.r.t. weight will be a sparse tensor. See Notes under\ntorch.nn.Embedding for more details regarding sparse gradients."}, "description": "A simple lookup table that looks up embeddings in a fixed dictionary and size."}, "torch.nn.functional.embedding_bag": {"Parameters": {"input (LongTensor)": "Tensor containing bags of indices into the embedding matrix", "weight (Tensor)": "The embedding matrix with number of rows equal to the maximum possible index + 1,\nand number of columns equal to the embedding size", "offsets (LongTensor, optional)": "Only used when input is 1D. offsets determines\nthe starting index position of each bag (sequence) in input.", "max_norm (float, optional)": "If given, each embedding vector with norm larger than max_norm\nis renormalized to have norm max_norm.\nNote: this will modify weight in-place.", "norm_type (float, optional)": "The p in the p-norm to compute for the max_norm option.\nDefault 2.", "scale_grad_by_freq (boolean, optional)": "if given, this will scale gradients by the inverse of frequency of\nthe words in the mini-batch. Default False.\nNote: this option is not supported when mode=\"max\".", "mode (string, optional)": "\"sum\", \"mean\" or \"max\". Specifies the way to reduce the bag.\nDefault: \"mean\"", "sparse (bool, optional)": "if True, gradient w.r.t. weight will be a sparse tensor. See Notes under\ntorch.nn.Embedding for more details regarding sparse gradients.\nNote: this option is not supported when mode=\"max\".", "per_sample_weights (Tensor, optional)": "a tensor of float / double weights, or None\nto indicate all weights should be taken to be 1. If specified, per_sample_weights\nmust have exactly the same shape as input and is treated as having the same\noffsets, if those are not None.", "include_last_offset (bool, optional)": "if True, the size of offsets is equal to the number of bags + 1.\nThe last element is the size of the input, or the ending index position of the last bag (sequence).", "padding_idx (int, optional)": "If specified, the entries at padding_idx do not contribute to the\ngradient; therefore, the embedding vector at padding_idx is not updated\nduring training, i.e. it remains as a fixed \u201cpad\u201d. Note that the embedding\nvector at padding_idx is excluded from the reduction."}, "description": "Computes sums, means or maxes of bags of embeddings, without instantiating the intermediate embeddings."}, "torch.nn.functional.one_hot": {"Parameters": {"tensor (LongTensor)": "class values of any shape.", "num_classes (int)": "Total number of classes. If set to -1, the number\nof classes will be inferred as one greater than the largest class\nvalue in the input tensor."}, "Returns": "LongTensor that has one more dimension with 1 values at the\nindex of last dimension indicated by the input, and 0 everywhere\nelse.\n", "description": "Takes LongTensor with index values of shape (*) and returns a tensor of shape (*, num_classes) that have zeros everywhere except where the index of last dimension matches the corresponding value of the input tensor, in which case it will be 1."}, "torch.nn.functional.pairwise_distance": {"description": "See torch.nn.PairwiseDistance for details"}, "torch.nn.functional.cosine_similarity": {"Parameters": {"x1 (Tensor)": "First input.", "x2 (Tensor)": "Second input.", "dim (int, optional)": "Dimension along which cosine similarity is computed. Default: 1", "eps (float, optional)": "Small value to avoid division by zero.\nDefault: 1e-8"}, "description": "Returns cosine similarity between x1 and x2, computed along dim."}, "torch.nn.functional.pdist": {"Parameters": {"input": "input tensor of shape N\u00d7MN \\times MN\u00d7M.", "p": "p value for the p-norm distance to calculate between each vector pair\n\u2208[0,\u221e]\\in [0, \\infty]\u2208[0,\u221e]."}, "description": "Computes the p-norm distance between every pair of row vectors in the input."}, "torch.nn.functional.binary_cross_entropy": {"Parameters": {"input": "Tensor of arbitrary shape as probabilities.", "target": "Tensor of the same shape as input with values between 0 and 1.", "weight (Tensor, optional)": "a manual rescaling weight\nif provided it\u2019s repeated to match input tensor shape", "size_average (bool, optional)": "Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True", "reduce (bool, optional)": "Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True", "reduction (string, optional)": "Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override reduction. Default: 'mean'"}, "description": "Function that measures the Binary Cross Entropy between the target and input probabilities."}, "torch.nn.functional.binary_cross_entropy_with_logits": {"Parameters": {"input": "Tensor of arbitrary shape as unnormalized scores (often referred to as logits).", "target": "Tensor of the same shape as input with values between 0 and 1", "weight (Tensor, optional)": "a manual rescaling weight\nif provided it\u2019s repeated to match input tensor shape", "size_average (bool, optional)": "Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True", "reduce (bool, optional)": "Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True", "reduction (string, optional)": "Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override reduction. Default: 'mean'", "pos_weight (Tensor, optional)": "a weight of positive examples.\nMust be a vector with length equal to the number of classes."}, "description": "Function that measures Binary Cross Entropy between target and input logits."}, "torch.nn.functional.poisson_nll_loss": {"Parameters": {"input": "expectation of underlying Poisson distribution.", "target": "random sample target\u223cPoisson(input)target \\sim \\text{Poisson}(input)target\u223cPoisson(input).", "log_input": "if True the loss is computed as\nexp\u2061(input)\u2212target\u2217input\\exp(\\text{input}) - \\text{target} * \\text{input}exp(input)\u2212target\u2217input, if False then loss is\ninput\u2212target\u2217log\u2061(input+eps)\\text{input} - \\text{target} * \\log(\\text{input}+\\text{eps})input\u2212target\u2217log(input+eps). Default: True", "full": "whether to compute full loss, i. e. to add the Stirling\napproximation term. Default: False\ntarget\u2217log\u2061(target)\u2212target+0.5\u2217log\u2061(2\u2217\u03c0\u2217target)\\text{target} * \\log(\\text{target}) - \\text{target} + 0.5 * \\log(2 * \\pi * \\text{target})target\u2217log(target)\u2212target+0.5\u2217log(2\u2217\u03c0\u2217target).", "size_average (bool, optional)": "Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True", "eps (float, optional)": "Small value to avoid evaluation of log\u2061(0)\\log(0)log(0) when\nlog_input=False. Default: 1e-8", "reduce (bool, optional)": "Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True", "reduction (string, optional)": "Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override reduction. Default: 'mean'"}, "description": "Poisson negative log likelihood loss."}, "torch.nn.functional.cosine_embedding_loss": {"description": "See CosineEmbeddingLoss for details."}, "torch.nn.functional.cross_entropy": {"Parameters": {"input (Tensor)": "Predicted unnormalized scores (often referred to as logits);\nsee Shape section below for supported shapes.", "target (Tensor)": "Ground truth class indices or class probabilities;\nsee Shape section below for supported shapes.", "weight (Tensor, optional)": "a manual rescaling weight given to each\nclass. If given, has to be a Tensor of size C", "size_average (bool, optional)": "Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True", "ignore_index (int, optional)": "Specifies a target value that is ignored\nand does not contribute to the input gradient. When size_average is\nTrue, the loss is averaged over non-ignored targets. Note that\nignore_index is only applicable when the target contains class indices.\nDefault: -100", "reduce (bool, optional)": "Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True", "reduction (string, optional)": "Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override reduction. Default: 'mean'", "label_smoothing (float, optional)": "A float in [0.0, 1.0]. Specifies the amount\nof smoothing when computing the loss, where 0.0 means no smoothing. The targets\nbecome a mixture of the original ground truth and a uniform distribution as described in\nRethinking the Inception Architecture for Computer Vision. Default: 0.00.00.0."}, "description": "This criterion computes the cross entropy loss between input and target."}, "torch.nn.functional.ctc_loss": {"Parameters": {"log_probs": "(T,N,C)(T, N, C)(T,N,C) or (T,C)(T, C)(T,C) where C = number of characters in alphabet including blank,\nT = input length, and N = batch size.\nThe logarithmized probabilities of the outputs\n(e.g. obtained with torch.nn.functional.log_softmax()).", "targets": "(N,S)(N, S)(N,S) or (sum(target_lengths)).\nTargets cannot be blank. In the second form, the targets are assumed to be concatenated.", "input_lengths": "(N)(N)(N) or ()()().\nLengths of the inputs (must each be \u2264T\\leq T\u2264T)", "target_lengths": "(N)(N)(N) or ()()().\nLengths of the targets", "blank (int, optional)": "Blank label. Default 000.", "reduction (string, optional)": "Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the output losses will be divided by the target lengths and\nthen the mean over the batch is taken, 'sum': the output will be\nsummed. Default: 'mean'", "zero_infinity (bool, optional)": "Whether to zero infinite losses and the associated gradients.\nDefault: False\nInfinite losses mainly occur when the inputs are too short\nto be aligned to the targets."}, "description": "The Connectionist Temporal Classification loss."}, "torch.nn.functional.gaussian_nll_loss": {"Parameters": {"input": "expectation of the Gaussian distribution.", "target": "sample from the Gaussian distribution.", "var": "tensor of positive variance(s), one for each of the expectations\nin the input (heteroscedastic), or a single one (homoscedastic).", "full (bool, optional)": "include the constant term in the loss calculation. Default: False.", "eps (float, optional)": "value added to var, for stability. Default: 1e-6.", "reduction (string, optional)": "specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the output is the average of all batch member losses,\n'sum': the output is the sum of all batch member losses.\nDefault: 'mean'."}, "description": "Gaussian negative log likelihood loss."}, "torch.nn.functional.hinge_embedding_loss": {"description": "See HingeEmbeddingLoss for details."}, "torch.nn.functional.kl_div": {"Parameters": {"input": "Tensor of arbitrary shape in log-probabilities.", "target": "Tensor of the same shape as input. See log_target for\nthe target\u2019s interpretation.", "size_average (bool, optional)": "Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True", "reduce (bool, optional)": "Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True", "reduction (string, optional)": "Specifies the reduction to apply to the output:\n'none' | 'batchmean' | 'sum' | 'mean'.\n'none': no reduction will be applied\n'batchmean': the sum of the output will be divided by the batchsize\n'sum': the output will be summed\n'mean': the output will be divided by the number of elements in the output\nDefault: 'mean'", "log_target (bool)": "A flag indicating whether target is passed in the log space.\nIt is recommended to pass certain distributions (like softmax)\nin the log space to avoid numerical issues caused by explicit log.\nDefault: False"}, "description": "The Kullback-Leibler divergence Loss"}, "torch.nn.functional.l1_loss": {"description": "Function that takes the mean element-wise absolute value difference."}, "torch.nn.functional.mse_loss": {"description": "Measures the element-wise mean squared error."}, "torch.nn.functional.margin_ranking_loss": {"description": "See MarginRankingLoss for details."}, "torch.nn.functional.multilabel_margin_loss": {"description": "See MultiLabelMarginLoss for details."}, "torch.nn.functional.multilabel_soft_margin_loss": {"description": "See MultiLabelSoftMarginLoss for details."}, "torch.nn.functional.multi_margin_loss": {"description": "See MultiMarginLoss for details."}, "torch.nn.functional.nll_loss": {"Parameters": {"input": "(N,C)(N, C)(N,C) where C = number of classes or (N,C,H,W)(N, C, H, W)(N,C,H,W)\nin case of 2D Loss, or (N,C,d1,d2,...,dK)(N, C, d_1, d_2, ..., d_K)(N,C,d1\u200b,d2\u200b,...,dK\u200b) where K\u22651K \\geq 1K\u22651\nin the case of K-dimensional loss. input is expected to be log-probabilities.", "target": "(N)(N)(N) where each value is 0\u2264targets[i]\u2264C\u221210 \\leq \\text{targets}[i] \\leq C-10\u2264targets[i]\u2264C\u22121,\nor (N,d1,d2,...,dK)(N, d_1, d_2, ..., d_K)(N,d1\u200b,d2\u200b,...,dK\u200b) where K\u22651K \\geq 1K\u22651 for\nK-dimensional loss.", "weight (Tensor, optional)": "a manual rescaling weight given to each\nclass. If given, has to be a Tensor of size C", "size_average (bool, optional)": "Deprecated (see reduction). By default,\nthe losses are averaged over each loss element in the batch. Note that for\nsome losses, there multiple elements per sample. If the field size_average\nis set to False, the losses are instead summed for each minibatch. Ignored\nwhen reduce is False. Default: True", "ignore_index (int, optional)": "Specifies a target value that is ignored\nand does not contribute to the input gradient. When size_average is\nTrue, the loss is averaged over non-ignored targets. Default: -100", "reduce (bool, optional)": "Deprecated (see reduction). By default, the\nlosses are averaged or summed over observations for each minibatch depending\non size_average. When reduce is False, returns a loss per\nbatch element instead and ignores size_average. Default: True", "reduction (string, optional)": "Specifies the reduction to apply to the output:\n'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n'mean': the sum of the output will be divided by the number of\nelements in the output, 'sum': the output will be summed. Note: size_average\nand reduce are in the process of being deprecated, and in the meantime,\nspecifying either of those two args will override reduction. Default: 'mean'"}, "description": "The negative log likelihood loss."}, "torch.nn.functional.huber_loss": {"description": "Function that uses a squared term if the absolute element-wise error falls below delta and a delta-scaled L1 term otherwise."}, "torch.nn.functional.smooth_l1_loss": {"description": "Function that uses a squared term if the absolute element-wise error falls below beta and an L1 term otherwise."}, "torch.nn.functional.soft_margin_loss": {"description": "See SoftMarginLoss for details."}, "torch.nn.functional.triplet_margin_loss": {"description": "See TripletMarginLoss for details"}, "torch.nn.functional.triplet_margin_with_distance_loss": {"description": "See TripletMarginWithDistanceLoss for details."}, "torch.nn.functional.pixel_shuffle": {"Parameters": {"input (Tensor)": "the input tensor", "upscale_factor (int)": "factor to increase spatial resolution by"}, "description": "Rearranges elements in a tensor of shape (\u2217,C\u00d7r2,H,W)(*, C \\times r^2, H, W)(\u2217,C\u00d7r2,H,W) to a tensor of shape (\u2217,C,H\u00d7r,W\u00d7r)(*, C, H \\times r, W \\times r)(\u2217,C,H\u00d7r,W\u00d7r), where r is the upscale_factor."}, "torch.nn.functional.pixel_unshuffle": {"Parameters": {"input (Tensor)": "the input tensor", "downscale_factor (int)": "factor to increase spatial resolution by"}, "description": "Reverses the PixelShuffle operation by rearranging elements in a tensor of shape (\u2217,C,H\u00d7r,W\u00d7r)(*, C, H \\times r, W \\times r)(\u2217,C,H\u00d7r,W\u00d7r) to a tensor of shape (\u2217,C\u00d7r2,H,W)(*, C \\times r^2, H, W)(\u2217,C\u00d7r2,H,W), where r is the downscale_factor."}, "torch.nn.functional.pad": {"Parameters": {"input (Tensor)": "N-dimensional tensor", "pad (tuple)": "m-elements tuple, where\nm2\u2264\\frac{m}{2} \\leq2m\u200b\u2264 input dimensions and mmm is even.", "mode": "'constant', 'reflect', 'replicate' or 'circular'.\nDefault: 'constant'", "value": "fill value for 'constant' padding. Default: 0"}, "description": "Pads tensor."}, "torch.nn.functional.interpolate": {"Parameters": {"input (Tensor)": "the input tensor", "size (int or Tuple[int] or Tuple[int, int] or Tuple[int, int, int])": "output spatial size.", "scale_factor (float or Tuple[float])": "multiplier for spatial size. If scale_factor is a tuple,\nits length has to match input.dim().", "mode (str)": "algorithm used for upsampling:\n'nearest' | 'linear' | 'bilinear' | 'bicubic' |\n'trilinear' | 'area' | 'nearest-exact'. Default: 'nearest'", "align_corners (bool, optional)": "Geometrically, we consider the pixels of the\ninput and output as squares rather than points.\nIf set to True, the input and output tensors are aligned by the\ncenter points of their corner pixels, preserving the values at the corner pixels.\nIf set to False, the input and output tensors are aligned by the corner\npoints of their corner pixels, and the interpolation uses edge value padding\nfor out-of-boundary values, making this operation independent of input size\nwhen scale_factor is kept the same. This only has an effect when mode\nis 'linear', 'bilinear', 'bicubic' or 'trilinear'.\nDefault: False", "recompute_scale_factor (bool, optional)": "recompute the scale_factor for use in the\ninterpolation calculation. If recompute_scale_factor is True, then\nscale_factor must be passed in and scale_factor is used to compute the\noutput size. The computed output size will be used to infer new scales for\nthe interpolation. Note that when scale_factor is floating-point, it may differ\nfrom the recomputed scale_factor due to rounding and precision issues.\nIf recompute_scale_factor is False, then size or scale_factor will\nbe used directly for interpolation. Default: None.", "antialias (bool, optional)": "flag to apply anti-aliasing. Default: False. Using anti-alias\noption together with align_corners=False, interpolation result would match Pillow\nresult for downsampling operation. Supported modes: 'bilinear', 'bicubic'."}, "description": "Down/up samples the input to either the given size or the given scale_factor"}, "torch.nn.functional.upsample": {"Parameters": {"input (Tensor)": "the input tensor", "size (int or Tuple[int] or Tuple[int, int] or Tuple[int, int, int])": "output spatial size.", "scale_factor (float or Tuple[float])": "multiplier for spatial size. Has to match input size if it is a tuple.", "mode (string)": "algorithm used for upsampling:\n'nearest' | 'linear' | 'bilinear' | 'bicubic' |\n'trilinear'. Default: 'nearest'", "align_corners (bool, optional)": "Geometrically, we consider the pixels of the\ninput and output as squares rather than points.\nIf set to True, the input and output tensors are aligned by the\ncenter points of their corner pixels, preserving the values at the corner pixels.\nIf set to False, the input and output tensors are aligned by the corner\npoints of their corner pixels, and the interpolation uses edge value padding\nfor out-of-boundary values, making this operation independent of input size\nwhen scale_factor is kept the same. This only has an effect when mode\nis 'linear', 'bilinear', 'bicubic' or 'trilinear'.\nDefault: False"}, "description": "Upsamples the input to either the given size or the given scale_factor"}, "torch.nn.functional.upsample_nearest": {"Parameters": {"input (Tensor)": "input", "size (int or Tuple[int, int] or Tuple[int, int, int])": "output spatia\nsize.", "scale_factor (int)": "multiplier for spatial size. Has to be an integer."}, "description": "Upsamples the input, using nearest neighbours\u2019 pixel values."}, "torch.nn.functional.upsample_bilinear": {"Parameters": {"input (Tensor)": "input", "size (int or Tuple[int, int])": "output spatial size.", "scale_factor (int or Tuple[int, int])": "multiplier for spatial size"}, "description": "Upsamples the input, using bilinear upsampling."}, "torch.nn.functional.grid_sample": {"Parameters": {"input (Tensor)": "input of shape (N,C,Hin,Win)(N, C, H_\\text{in}, W_\\text{in})(N,C,Hin\u200b,Win\u200b) (4-D case)\nor (N,C,Din,Hin,Win)(N, C, D_\\text{in}, H_\\text{in}, W_\\text{in})(N,C,Din\u200b,Hin\u200b,Win\u200b) (5-D case)", "grid (Tensor)": "flow-field of shape (N,Hout,Wout,2)(N, H_\\text{out}, W_\\text{out}, 2)(N,Hout\u200b,Wout\u200b,2) (4-D case)\nor (N,Dout,Hout,Wout,3)(N, D_\\text{out}, H_\\text{out}, W_\\text{out}, 3)(N,Dout\u200b,Hout\u200b,Wout\u200b,3) (5-D case)", "mode (str)": "interpolation mode to calculate output values\n'bilinear' | 'nearest' | 'bicubic'. Default: 'bilinear'\nNote: mode='bicubic' supports only 4-D input.\nWhen mode='bilinear' and the input is 5-D, the interpolation mode\nused internally will actually be trilinear. However, when the input is 4-D,\nthe interpolation mode will legitimately be bilinear.", "padding_mode (str)": "padding mode for outside grid values\n'zeros' | 'border' | 'reflection'. Default: 'zeros'", "align_corners (bool, optional)": "Geometrically, we consider the pixels of the\ninput  as squares rather than points.\nIf set to True, the extrema (-1 and 1) are considered as referring\nto the center points of the input\u2019s corner pixels. If set to False, they\nare instead considered as referring to the corner points of the input\u2019s corner\npixels, making the sampling more resolution agnostic.\nThis option parallels the align_corners option in\ninterpolate(), and so whichever option is used here\nshould also be used there to resize the input image before grid sampling.\nDefault: False"}, "Returns": "output Tensor\n", "description": "Given an input and a flow-field grid, computes the output using input values and pixel locations from grid."}, "torch.nn.functional.affine_grid": {"Parameters": {"theta (Tensor)": "input batch of affine matrices with shape\n(N\u00d72\u00d73N \\times 2 \\times 3N\u00d72\u00d73) for 2D or\n(N\u00d73\u00d74N \\times 3 \\times 4N\u00d73\u00d74) for 3D", "size (torch.Size)": "the target output image size.\n(N\u00d7C\u00d7H\u00d7WN \\times C \\times H \\times WN\u00d7C\u00d7H\u00d7W for 2D or\nN\u00d7C\u00d7D\u00d7H\u00d7WN \\times C \\times D \\times H \\times WN\u00d7C\u00d7D\u00d7H\u00d7W for 3D)\nExample: torch.Size((32, 3, 24, 24))", "align_corners (bool, optional)": "if True, consider -1 and 1\nto refer to the centers of the corner pixels rather than the image corners.\nRefer to grid_sample() for a more complete description.\nA grid generated by affine_grid() should be passed to grid_sample()\nwith the same setting for this option.\nDefault: False"}, "Returns": "output Tensor of size (N\u00d7H\u00d7W\u00d72N \\times H \\times W \\times 2N\u00d7H\u00d7W\u00d72)\n", "description": "Generates a 2D or 3D flow field (sampling grid), given a batch of affine matrices theta."}, "torch.nn.parallel.data_parallel": {"description": "Evaluates module(input) in parallel across the GPUs given in device_ids."}, "torch.Tensor.new_tensor": {"Parameters": {"data (array_like)": "The returned Tensor copies data.", "dtype (torch.dtype, optional)": "the desired type of returned tensor.\nDefault: if None, same torch.dtype as this tensor.", "device (torch.device, optional)": "the desired device of returned tensor.\nDefault: if None, same torch.device as this tensor.", "requires_grad (bool, optional)": "If autograd should record operations on the\nreturned tensor. Default: False."}, "description": "Returns a new Tensor with data as the tensor data."}, "torch.Tensor.new_full": {"Parameters": {"fill_value (scalar)": "the number to fill the output tensor with.", "dtype (torch.dtype, optional)": "the desired type of returned tensor.\nDefault: if None, same torch.dtype as this tensor.", "device (torch.device, optional)": "the desired device of returned tensor.\nDefault: if None, same torch.device as this tensor.", "requires_grad (bool, optional)": "If autograd should record operations on the\nreturned tensor. Default: False."}, "description": "Returns a Tensor of size size filled with fill_value."}, "torch.Tensor.new_empty": {"Parameters": {"dtype (torch.dtype, optional)": "the desired type of returned tensor.\nDefault: if None, same torch.dtype as this tensor.", "device (torch.device, optional)": "the desired device of returned tensor.\nDefault: if None, same torch.device as this tensor.", "requires_grad (bool, optional)": "If autograd should record operations on the\nreturned tensor. Default: False."}, "description": "Returns a Tensor of size size filled with uninitialized data."}, "torch.Tensor.new_ones": {"Parameters": {"size (int...)": "a list, tuple, or torch.Size of integers defining the\nshape of the output tensor.", "dtype (torch.dtype, optional)": "the desired type of returned tensor.\nDefault: if None, same torch.dtype as this tensor.", "device (torch.device, optional)": "the desired device of returned tensor.\nDefault: if None, same torch.device as this tensor.", "requires_grad (bool, optional)": "If autograd should record operations on the\nreturned tensor. Default: False."}, "description": "Returns a Tensor of size size filled with 1."}, "torch.Tensor.new_zeros": {"Parameters": {"size (int...)": "a list, tuple, or torch.Size of integers defining the\nshape of the output tensor.", "dtype (torch.dtype, optional)": "the desired type of returned tensor.\nDefault: if None, same torch.dtype as this tensor.", "device (torch.device, optional)": "the desired device of returned tensor.\nDefault: if None, same torch.device as this tensor.", "requires_grad (bool, optional)": "If autograd should record operations on the\nreturned tensor. Default: False."}, "description": "Returns a Tensor of size size filled with 0."}, "torch.Tensor.is_cuda": {"description": "Is True if the Tensor is stored on the GPU, False otherwise."}, "torch.Tensor.is_quantized": {"description": "Is True if the Tensor is quantized, False otherwise."}, "torch.Tensor.is_meta": {"description": "Is True if the Tensor is a meta tensor, False otherwise."}, "torch.Tensor.device": {"description": "Is the torch.device where this Tensor is."}, "torch.Tensor.grad": {"description": "This attribute is None by default and becomes a Tensor the first time a call to backward() computes gradients for self."}, "torch.Tensor.ndim": {"description": "Alias for dim()"}, "torch.Tensor.real": {"description": "Returns a new tensor containing real values of the self tensor for a complex-valued input tensor."}, "torch.Tensor.imag": {"description": "Returns a new tensor containing imaginary values of the self tensor."}, "torch.Tensor.abs": {"description": "See torch.abs()"}, "torch.Tensor.abs_": {"description": "In-place version of abs()"}, "torch.Tensor.absolute": {"description": "Alias for abs()"}, "torch.Tensor.absolute_": {"description": "In-place version of absolute() Alias for abs_()"}, "torch.Tensor.acos": {"description": "See torch.acos()"}, "torch.Tensor.acos_": {"description": "In-place version of acos()"}, "torch.Tensor.arccos": {"description": "See torch.arccos()"}, "torch.Tensor.arccos_": {"description": "In-place version of arccos()"}, "torch.Tensor.add": {"description": "Add a scalar or tensor to self tensor."}, "torch.Tensor.add_": {"description": "In-place version of add()"}, "torch.Tensor.addbmm": {"description": "See torch.addbmm()"}, "torch.Tensor.addbmm_": {"description": "In-place version of addbmm()"}, "torch.Tensor.addcdiv": {"description": "See torch.addcdiv()"}, "torch.Tensor.addcdiv_": {"description": "In-place version of addcdiv()"}, "torch.Tensor.addcmul": {"description": "See torch.addcmul()"}, "torch.Tensor.addcmul_": {"description": "In-place version of addcmul()"}, "torch.Tensor.addmm": {"description": "See torch.addmm()"}, "torch.Tensor.addmm_": {"description": "In-place version of addmm()"}, "torch.Tensor.sspaddmm": {"description": "See torch.sspaddmm()"}, "torch.Tensor.addmv": {"description": "See torch.addmv()"}, "torch.Tensor.addmv_": {"description": "In-place version of addmv()"}, "torch.Tensor.addr": {"description": "See torch.addr()"}, "torch.Tensor.addr_": {"description": "In-place version of addr()"}, "torch.Tensor.adjoint": {"description": "Alias for adjoint()"}, "torch.Tensor.allclose": {"description": "See torch.allclose()"}, "torch.Tensor.amax": {"description": "See torch.amax()"}, "torch.Tensor.amin": {"description": "See torch.amin()"}, "torch.Tensor.aminmax": {"description": "See torch.aminmax()"}, "torch.Tensor.angle": {"description": "See torch.angle()"}, "torch.Tensor.apply_": {"description": "Applies the function callable to each element in the tensor, replacing each element with the value returned by callable."}, "torch.Tensor.argmax": {"description": "See torch.argmax()"}, "torch.Tensor.argmin": {"description": "See torch.argmin()"}, "torch.Tensor.argsort": {"description": "See torch.argsort()"}, "torch.Tensor.argwhere": {"description": "See torch.argwhere()"}, "torch.Tensor.asin": {"description": "See torch.asin()"}, "torch.Tensor.asin_": {"description": "In-place version of asin()"}, "torch.Tensor.arcsin": {"description": "See torch.arcsin()"}, "torch.Tensor.arcsin_": {"description": "In-place version of arcsin()"}, "torch.Tensor.as_strided": {"description": "See torch.as_strided()"}, "torch.Tensor.atan": {"description": "See torch.atan()"}, "torch.Tensor.atan_": {"description": "In-place version of atan()"}, "torch.Tensor.arctan": {"description": "See torch.arctan()"}, "torch.Tensor.arctan_": {"description": "In-place version of arctan()"}, "torch.Tensor.atan2": {"description": "See torch.atan2()"}, "torch.Tensor.atan2_": {"description": "In-place version of atan2()"}, "torch.Tensor.arctan2": {"description": "See torch.arctan2()"}, "torch.Tensor.arctan2_": {"description": "atan2_(other) -> Tensor"}, "torch.Tensor.all": {"description": "See torch.all()"}, "torch.Tensor.any": {"description": "See torch.any()"}, "torch.Tensor.backward": {"Parameters": {"gradient (Tensor or None)": "Gradient w.r.t. the\ntensor. If it is a tensor, it will be automatically converted\nto a Tensor that does not require grad unless create_graph is True.\nNone values can be specified for scalar Tensors or ones that\ndon\u2019t require grad. If a None value would be acceptable then\nthis argument is optional.", "retain_graph (bool, optional)": "If False, the graph used to compute\nthe grads will be freed. Note that in nearly all cases setting\nthis option to True is not needed and often can be worked around\nin a much more efficient way. Defaults to the value of\ncreate_graph.", "create_graph (bool, optional)": "If True, graph of the derivative will\nbe constructed, allowing to compute higher order derivative\nproducts. Defaults to False.", "inputs (sequence of Tensor)": "Inputs w.r.t. which the gradient will be\naccumulated into .grad. All other Tensors will be ignored. If not\nprovided, the gradient is accumulated into all the leaf Tensors that were\nused to compute the attr::tensors."}, "description": "Computes the gradient of current tensor w.r.t."}, "torch.Tensor.baddbmm": {"description": "See torch.baddbmm()"}, "torch.Tensor.baddbmm_": {"description": "In-place version of baddbmm()"}, "torch.Tensor.bernoulli": {"description": "Returns a result tensor where each result[i]\\texttt{result[i]}result[i] is independently sampled from Bernoulli(self[i])\\text{Bernoulli}(\\texttt{self[i]})Bernoulli(self[i])."}, "torch.Tensor.bernoulli_": {"description": "Fills each location of self with an independent sample from Bernoulli(p)\\text{Bernoulli}(\\texttt{p})Bernoulli(p)."}, "torch.Tensor.bfloat16": {"Parameters": {"memory_format (torch.memory_format, optional)": "the desired memory format of\nreturned Tensor. Default: torch.preserve_format."}, "description": "self.bfloat16() is equivalent to self.to(torch.bfloat16)."}, "torch.Tensor.bincount": {"description": "See torch.bincount()"}, "torch.Tensor.bitwise_not": {"description": "See torch.bitwise_not()"}, "torch.Tensor.bitwise_not_": {"description": "In-place version of bitwise_not()"}, "torch.Tensor.bitwise_and": {"description": "See torch.bitwise_and()"}, "torch.Tensor.bitwise_and_": {"description": "In-place version of bitwise_and()"}, "torch.Tensor.bitwise_or": {"description": "See torch.bitwise_or()"}, "torch.Tensor.bitwise_or_": {"description": "In-place version of bitwise_or()"}, "torch.Tensor.bitwise_xor": {"description": "See torch.bitwise_xor()"}, "torch.Tensor.bitwise_xor_": {"description": "In-place version of bitwise_xor()"}, "torch.Tensor.bitwise_left_shift": {"description": "See torch.bitwise_left_shift()"}, "torch.Tensor.bitwise_left_shift_": {"description": "In-place version of bitwise_left_shift()"}, "torch.Tensor.bitwise_right_shift": {"description": "See torch.bitwise_right_shift()"}, "torch.Tensor.bitwise_right_shift_": {"description": "In-place version of bitwise_right_shift()"}, "torch.Tensor.bmm": {"description": "See torch.bmm()"}, "torch.Tensor.bool": {"Parameters": {"memory_format (torch.memory_format, optional)": "the desired memory format of\nreturned Tensor. Default: torch.preserve_format."}, "description": "self.bool() is equivalent to self.to(torch.bool)."}, "torch.Tensor.byte": {"Parameters": {"memory_format (torch.memory_format, optional)": "the desired memory format of\nreturned Tensor. Default: torch.preserve_format."}, "description": "self.byte() is equivalent to self.to(torch.uint8)."}, "torch.Tensor.broadcast_to": {"description": "See torch.broadcast_to()."}, "torch.Tensor.cauchy_": {"description": "Fills the tensor with numbers drawn from the Cauchy distribution:"}, "torch.Tensor.ceil": {"description": "See torch.ceil()"}, "torch.Tensor.ceil_": {"description": "In-place version of ceil()"}, "torch.Tensor.char": {"Parameters": {"memory_format (torch.memory_format, optional)": "the desired memory format of\nreturned Tensor. Default: torch.preserve_format."}, "description": "self.char() is equivalent to self.to(torch.int8)."}, "torch.Tensor.cholesky": {"description": "See torch.cholesky()"}, "torch.Tensor.cholesky_inverse": {"description": "See torch.cholesky_inverse()"}, "torch.Tensor.cholesky_solve": {"description": "See torch.cholesky_solve()"}, "torch.Tensor.chunk": {"description": "See torch.chunk()"}, "torch.Tensor.clamp": {"description": "See torch.clamp()"}, "torch.Tensor.clamp_": {"description": "In-place version of clamp()"}, "torch.Tensor.clip": {"description": "Alias for clamp()."}, "torch.Tensor.clip_": {"description": "Alias for clamp_()."}, "torch.Tensor.clone": {"description": "See torch.clone()"}, "torch.Tensor.contiguous": {"Parameters": {"memory_format (torch.memory_format, optional)": "the desired memory format of\nreturned Tensor. Default: torch.contiguous_format."}, "description": "Returns a contiguous in memory tensor containing the same data as self tensor."}, "torch.Tensor.copy_": {"Parameters": {"src (Tensor)": "the source tensor to copy from", "non_blocking (bool)": "if True and this copy is between CPU and GPU,\nthe copy may occur asynchronously with respect to the host. For other\ncases, this argument has no effect."}, "description": "Copies the elements from src into self tensor and returns self."}, "torch.Tensor.conj": {"description": "See torch.conj()"}, "torch.Tensor.conj_physical": {"description": "See torch.conj_physical()"}, "torch.Tensor.conj_physical_": {"description": "In-place version of conj_physical()"}, "torch.Tensor.resolve_conj": {"description": "See torch.resolve_conj()"}, "torch.Tensor.resolve_neg": {"description": "See torch.resolve_neg()"}, "torch.Tensor.copysign": {"description": "See torch.copysign()"}, "torch.Tensor.copysign_": {"description": "In-place version of copysign()"}, "torch.Tensor.cos": {"description": "See torch.cos()"}, "torch.Tensor.cos_": {"description": "In-place version of cos()"}, "torch.Tensor.cosh": {"description": "See torch.cosh()"}, "torch.Tensor.cosh_": {"description": "In-place version of cosh()"}, "torch.Tensor.corrcoef": {"description": "See torch.corrcoef()"}, "torch.Tensor.count_nonzero": {"description": "See torch.count_nonzero()"}, "torch.Tensor.cov": {"description": "See torch.cov()"}, "torch.Tensor.acosh": {"description": "See torch.acosh()"}, "torch.Tensor.acosh_": {"description": "In-place version of acosh()"}, "torch.Tensor.arccosh": {"description": "acosh() -> Tensor"}, "torch.Tensor.arccosh_": {"description": "acosh_() -> Tensor"}, "torch.Tensor.cpu": {"Parameters": {"memory_format (torch.memory_format, optional)": "the desired memory format of\nreturned Tensor. Default: torch.preserve_format."}, "description": "Returns a copy of this object in CPU memory."}, "torch.Tensor.cross": {"description": "See torch.cross()"}, "torch.Tensor.cuda": {"Parameters": {"device (torch.device)": "The destination GPU device.\nDefaults to the current CUDA device.", "non_blocking (bool)": "If True and the source is in pinned memory,\nthe copy will be asynchronous with respect to the host.\nOtherwise, the argument has no effect. Default: False.", "memory_format (torch.memory_format, optional)": "the desired memory format of\nreturned Tensor. Default: torch.preserve_format."}, "description": "Returns a copy of this object in CUDA memory."}, "torch.Tensor.logcumsumexp": {"description": "See torch.logcumsumexp()"}, "torch.Tensor.cummax": {"description": "See torch.cummax()"}, "torch.Tensor.cummin": {"description": "See torch.cummin()"}, "torch.Tensor.cumprod": {"description": "See torch.cumprod()"}, "torch.Tensor.cumprod_": {"description": "In-place version of cumprod()"}, "torch.Tensor.cumsum": {"description": "See torch.cumsum()"}, "torch.Tensor.cumsum_": {"description": "In-place version of cumsum()"}, "torch.Tensor.data_ptr": {"description": "Returns the address of the first element of self tensor."}, "torch.Tensor.deg2rad": {"description": "See torch.deg2rad()"}, "torch.Tensor.dequantize": {"description": "Given a quantized Tensor, dequantize it and return the dequantized float Tensor."}, "torch.Tensor.det": {"description": "See torch.det()"}, "torch.Tensor.dense_dim": {"description": "Return the number of dense dimensions in a sparse tensor self."}, "torch.Tensor.detach": {"description": "Returns a new Tensor, detached from the current graph."}, "torch.Tensor.detach_": {"description": "Detaches the Tensor from the graph that created it, making it a leaf."}, "torch.Tensor.diag": {"description": "See torch.diag()"}, "torch.Tensor.diag_embed": {"description": "See torch.diag_embed()"}, "torch.Tensor.diagflat": {"description": "See torch.diagflat()"}, "torch.Tensor.diagonal": {"description": "See torch.diagonal()"}, "torch.Tensor.diagonal_scatter": {"description": "diagonal(src, offset=0, dim1=0, dim2=1) -> Tensor"}, "torch.Tensor.fill_diagonal_": {"Parameters": {"fill_value (Scalar)": "the fill value", "wrap (bool)": "the diagonal \u2018wrapped\u2019 after N columns for tall matrices."}, "description": "Fill the main diagonal of a tensor that has at least 2-dimensions."}, "torch.Tensor.fmax": {"description": "See torch.fmax()"}, "torch.Tensor.fmin": {"description": "See torch.fmin()"}, "torch.Tensor.diff": {"description": "See torch.diff()"}, "torch.Tensor.digamma": {"description": "See torch.digamma()"}, "torch.Tensor.digamma_": {"description": "In-place version of digamma()"}, "torch.Tensor.dim": {"description": "Returns the number of dimensions of self tensor."}, "torch.Tensor.dist": {"description": "See torch.dist()"}, "torch.Tensor.div": {"description": "See torch.div()"}, "torch.Tensor.div_": {"description": "In-place version of div()"}, "torch.Tensor.divide": {"description": "See torch.divide()"}, "torch.Tensor.divide_": {"description": "In-place version of divide()"}, "torch.Tensor.dot": {"description": "See torch.dot()"}, "torch.Tensor.double": {"Parameters": {"memory_format (torch.memory_format, optional)": "the desired memory format of\nreturned Tensor. Default: torch.preserve_format."}, "description": "self.double() is equivalent to self.to(torch.float64)."}, "torch.Tensor.dsplit": {"description": "See torch.dsplit()"}, "torch.Tensor.eig": {"description": "See torch.eig()"}, "torch.Tensor.element_size": {"description": "Returns the size in bytes of an individual element."}, "torch.Tensor.eq": {"description": "See torch.eq()"}, "torch.Tensor.eq_": {"description": "In-place version of eq()"}, "torch.Tensor.equal": {"description": "See torch.equal()"}, "torch.Tensor.erf": {"description": "See torch.erf()"}, "torch.Tensor.erf_": {"description": "In-place version of erf()"}, "torch.Tensor.erfc": {"description": "See torch.erfc()"}, "torch.Tensor.erfc_": {"description": "In-place version of erfc()"}, "torch.Tensor.erfinv": {"description": "See torch.erfinv()"}, "torch.Tensor.erfinv_": {"description": "In-place version of erfinv()"}, "torch.Tensor.exp": {"description": "See torch.exp()"}, "torch.Tensor.exp_": {"description": "In-place version of exp()"}, "torch.Tensor.expm1": {"description": "See torch.expm1()"}, "torch.Tensor.expm1_": {"description": "In-place version of expm1()"}, "torch.Tensor.expand": {"Parameters": {"*sizes (torch.Size or int...)": "the desired expanded size"}, "description": "Returns a new view of the self tensor with singleton dimensions expanded to a larger size."}, "torch.Tensor.expand_as": {"Parameters": {"other (torch.Tensor)": "The result tensor has the same size\nas other."}, "description": "Expand this tensor to the same size as other."}, "torch.Tensor.exponential_": {"description": "Fills self tensor with elements drawn from the exponential distribution:"}, "torch.Tensor.fix": {"description": "See torch.fix()."}, "torch.Tensor.fix_": {"description": "In-place version of fix()"}, "torch.Tensor.fill_": {"description": "Fills self tensor with the specified value."}, "torch.Tensor.flatten": {"description": "See torch.flatten()"}, "torch.Tensor.flip": {"description": "See torch.flip()"}, "torch.Tensor.fliplr": {"description": "See torch.fliplr()"}, "torch.Tensor.flipud": {"description": "See torch.flipud()"}, "torch.Tensor.float": {"Parameters": {"memory_format (torch.memory_format, optional)": "the desired memory format of\nreturned Tensor. Default: torch.preserve_format."}, "description": "self.float() is equivalent to self.to(torch.float32)."}, "torch.Tensor.float_power": {"description": "See torch.float_power()"}, "torch.Tensor.float_power_": {"description": "In-place version of float_power()"}, "torch.Tensor.floor": {"description": "See torch.floor()"}, "torch.Tensor.floor_": {"description": "In-place version of floor()"}, "torch.Tensor.floor_divide": {"description": "See torch.floor_divide()"}, "torch.Tensor.floor_divide_": {"description": "In-place version of floor_divide()"}, "torch.Tensor.fmod": {"description": "See torch.fmod()"}, "torch.Tensor.fmod_": {"description": "In-place version of fmod()"}, "torch.Tensor.frac": {"description": "See torch.frac()"}, "torch.Tensor.frac_": {"description": "In-place version of frac()"}, "torch.Tensor.frexp": {"description": "See torch.frexp()"}, "torch.Tensor.gather": {"description": "See torch.gather()"}, "torch.Tensor.gcd": {"description": "See torch.gcd()"}, "torch.Tensor.gcd_": {"description": "In-place version of gcd()"}, "torch.Tensor.ge": {"description": "See torch.ge()."}, "torch.Tensor.ge_": {"description": "In-place version of ge()."}, "torch.Tensor.greater_equal": {"description": "See torch.greater_equal()."}, "torch.Tensor.greater_equal_": {"description": "In-place version of greater_equal()."}, "torch.Tensor.geometric_": {"description": "Fills self tensor with elements drawn from the geometric distribution:"}, "torch.Tensor.geqrf": {"description": "See torch.geqrf()"}, "torch.Tensor.ger": {"description": "See torch.ger()"}, "torch.Tensor.get_device": {"description": "For CUDA tensors, this function returns the device ordinal of the GPU on which the tensor resides."}, "torch.Tensor.gt": {"description": "See torch.gt()."}, "torch.Tensor.gt_": {"description": "In-place version of gt()."}, "torch.Tensor.greater": {"description": "See torch.greater()."}, "torch.Tensor.greater_": {"description": "In-place version of greater()."}, "torch.Tensor.half": {"Parameters": {"memory_format (torch.memory_format, optional)": "the desired memory format of\nreturned Tensor. Default: torch.preserve_format."}, "description": "self.half() is equivalent to self.to(torch.float16)."}, "torch.Tensor.hardshrink": {"description": "See torch.nn.functional.hardshrink()"}, "torch.Tensor.heaviside": {"description": "See torch.heaviside()"}, "torch.Tensor.histc": {"description": "See torch.histc()"}, "torch.Tensor.histogram": {"description": "See torch.histogram()"}, "torch.Tensor.hsplit": {"description": "See torch.hsplit()"}, "torch.Tensor.hypot": {"description": "See torch.hypot()"}, "torch.Tensor.hypot_": {"description": "In-place version of hypot()"}, "torch.Tensor.i0": {"description": "See torch.i0()"}, "torch.Tensor.i0_": {"description": "In-place version of i0()"}, "torch.Tensor.igamma": {"description": "See torch.igamma()"}, "torch.Tensor.igamma_": {"description": "In-place version of igamma()"}, "torch.Tensor.igammac": {"description": "See torch.igammac()"}, "torch.Tensor.igammac_": {"description": "In-place version of igammac()"}, "torch.Tensor.index_add_": {"Parameters": {"dim (int)": "dimension along which to index", "index (Tensor)": "indices of source to select from,\nshould have dtype either torch.int64 or torch.int32", "source (Tensor)": "the tensor containing values to add"}, "description": "Accumulate the elements of alpha times source into the self tensor by adding to the indices in the order given in index."}, "torch.Tensor.index_add": {"description": "Out-of-place version of torch.Tensor.index_add_()."}, "torch.Tensor.index_copy_": {"Parameters": {"dim (int)": "dimension along which to index", "index (LongTensor)": "indices of tensor to select from", "tensor (Tensor)": "the tensor containing values to copy"}, "description": "Copies the elements of tensor into the self tensor by selecting the indices in the order given in index."}, "torch.Tensor.index_copy": {"description": "Out-of-place version of torch.Tensor.index_copy_()."}, "torch.Tensor.index_fill_": {"Parameters": {"dim (int)": "dimension along which to index", "index (LongTensor)": "indices of self tensor to fill in", "value (float)": "the value to fill with"}, "description": "Fills the elements of the self tensor with value value by selecting the indices in the order given in index."}, "torch.Tensor.index_fill": {"description": "Out-of-place version of torch.Tensor.index_fill_()."}, "torch.Tensor.index_put_": {"Parameters": {"indices (tuple of LongTensor)": "tensors used to index into self.", "values (Tensor)": "tensor of same dtype as self.", "accumulate (bool)": "whether to accumulate into self"}, "description": "Puts values from the tensor values into the tensor self using the indices specified in indices (which is a tuple of Tensors)."}, "torch.Tensor.index_put": {"description": "Out-place version of index_put_()."}, "torch.Tensor.index_select": {"description": "See torch.index_select()"}, "torch.Tensor.indices": {"description": "Return the indices tensor of a sparse COO tensor."}, "torch.Tensor.inner": {"description": "See torch.inner()."}, "torch.Tensor.int": {"Parameters": {"memory_format (torch.memory_format, optional)": "the desired memory format of\nreturned Tensor. Default: torch.preserve_format."}, "description": "self.int() is equivalent to self.to(torch.int32)."}, "torch.Tensor.int_repr": {"description": "Given a quantized Tensor, self.int_repr() returns a CPU Tensor with uint8_t as data type that stores the underlying uint8_t values of the given Tensor."}, "torch.Tensor.inverse": {"description": "See torch.inverse()"}, "torch.Tensor.isclose": {"description": "See torch.isclose()"}, "torch.Tensor.isfinite": {"description": "See torch.isfinite()"}, "torch.Tensor.isinf": {"description": "See torch.isinf()"}, "torch.Tensor.isposinf": {"description": "See torch.isposinf()"}, "torch.Tensor.isneginf": {"description": "See torch.isneginf()"}, "torch.Tensor.isnan": {"description": "See torch.isnan()"}, "torch.Tensor.is_contiguous": {"Parameters": {"memory_format (torch.memory_format, optional)": "Specifies memory allocation\norder. Default: torch.contiguous_format."}, "description": "Returns True if self tensor is contiguous in memory in the order specified by memory format."}, "torch.Tensor.is_complex": {"description": "Returns True if the data type of self is a complex data type."}, "torch.Tensor.is_conj": {"description": "Returns True if the conjugate bit of self is set to true."}, "torch.Tensor.is_floating_point": {"description": "Returns True if the data type of self is a floating point data type."}, "torch.Tensor.is_inference": {"description": "See torch.is_inference()"}, "torch.Tensor.is_leaf": {"description": "All Tensors that have requires_grad which is False will be leaf Tensors by convention."}, "torch.Tensor.is_pinned": {"description": "Returns true if this tensor resides in pinned memory."}, "torch.Tensor.is_set_to": {"description": "Returns True if both tensors are pointing to the exact same memory (same storage, offset, size and stride)."}, "torch.Tensor.is_shared": {"description": "Checks if tensor is in shared memory."}, "torch.Tensor.is_signed": {"description": "Returns True if the data type of self is a signed data type."}, "torch.Tensor.is_sparse": {"description": "Is True if the Tensor uses sparse storage layout, False otherwise."}, "torch.Tensor.istft": {"description": "See torch.istft()"}, "torch.Tensor.isreal": {"description": "See torch.isreal()"}, "torch.Tensor.item": {"description": "Returns the value of this tensor as a standard Python number."}, "torch.Tensor.kthvalue": {"description": "See torch.kthvalue()"}, "torch.Tensor.lcm": {"description": "See torch.lcm()"}, "torch.Tensor.lcm_": {"description": "In-place version of lcm()"}, "torch.Tensor.ldexp": {"description": "See torch.ldexp()"}, "torch.Tensor.ldexp_": {"description": "In-place version of ldexp()"}, "torch.Tensor.le": {"description": "See torch.le()."}, "torch.Tensor.le_": {"description": "In-place version of le()."}, "torch.Tensor.less_equal": {"description": "See torch.less_equal()."}, "torch.Tensor.less_equal_": {"description": "In-place version of less_equal()."}, "torch.Tensor.lerp": {"description": "See torch.lerp()"}, "torch.Tensor.lerp_": {"description": "In-place version of lerp()"}, "torch.Tensor.lgamma": {"description": "See torch.lgamma()"}, "torch.Tensor.lgamma_": {"description": "In-place version of lgamma()"}, "torch.Tensor.log": {"description": "See torch.log()"}, "torch.Tensor.log_": {"description": "In-place version of log()"}, "torch.Tensor.logdet": {"description": "See torch.logdet()"}, "torch.Tensor.log10": {"description": "See torch.log10()"}, "torch.Tensor.log10_": {"description": "In-place version of log10()"}, "torch.Tensor.log1p": {"description": "See torch.log1p()"}, "torch.Tensor.log1p_": {"description": "In-place version of log1p()"}, "torch.Tensor.log2": {"description": "See torch.log2()"}, "torch.Tensor.log2_": {"description": "In-place version of log2()"}, "torch.Tensor.log_normal_": {"description": "Fills self tensor with numbers samples from the log-normal distribution parameterized by the given mean \u03bc\\mu\u03bc and standard deviation \u03c3\\sigma\u03c3."}, "torch.Tensor.logaddexp": {"description": "See torch.logaddexp()"}, "torch.Tensor.logaddexp2": {"description": "See torch.logaddexp2()"}, "torch.Tensor.logsumexp": {"description": "See torch.logsumexp()"}, "torch.Tensor.logical_and": {"description": "See torch.logical_and()"}, "torch.Tensor.logical_and_": {"description": "In-place version of logical_and()"}, "torch.Tensor.logical_not": {"description": "See torch.logical_not()"}, "torch.Tensor.logical_not_": {"description": "In-place version of logical_not()"}, "torch.Tensor.logical_or": {"description": "See torch.logical_or()"}, "torch.Tensor.logical_or_": {"description": "In-place version of logical_or()"}, "torch.Tensor.logical_xor": {"description": "See torch.logical_xor()"}, "torch.Tensor.logical_xor_": {"description": "In-place version of logical_xor()"}, "torch.Tensor.logit": {"description": "See torch.logit()"}, "torch.Tensor.logit_": {"description": "In-place version of logit()"}, "torch.Tensor.long": {"Parameters": {"memory_format (torch.memory_format, optional)": "the desired memory format of\nreturned Tensor. Default: torch.preserve_format."}, "description": "self.long() is equivalent to self.to(torch.int64)."}, "torch.Tensor.lstsq": {"description": "See torch.lstsq()"}, "torch.Tensor.lt": {"description": "See torch.lt()."}, "torch.Tensor.lt_": {"description": "In-place version of lt()."}, "torch.Tensor.less": {"description": "lt(other) -> Tensor"}, "torch.Tensor.less_": {"description": "In-place version of less()."}, "torch.Tensor.lu": {"description": "See torch.lu()"}, "torch.Tensor.lu_solve": {"description": "See torch.lu_solve()"}, "torch.Tensor.as_subclass": {"description": "Makes a cls instance with the same data pointer as self."}, "torch.Tensor.map_": {"description": "Applies callable for each element in self tensor and the given tensor and stores the results in self tensor."}, "torch.Tensor.masked_scatter_": {"Parameters": {"mask (BoolTensor)": "the boolean mask", "source (Tensor)": "the tensor to copy from"}, "description": "Copies elements from source into self tensor at positions where the mask is True."}, "torch.Tensor.masked_scatter": {"description": "Out-of-place version of torch.Tensor.masked_scatter_()"}, "torch.Tensor.masked_fill_": {"Parameters": {"mask (BoolTensor)": "the boolean mask", "value (float)": "the value to fill in with"}, "description": "Fills elements of self tensor with value where mask is True."}, "torch.Tensor.masked_fill": {"description": "Out-of-place version of torch.Tensor.masked_fill_()"}, "torch.Tensor.masked_select": {"description": "See torch.masked_select()"}, "torch.Tensor.matmul": {"description": "See torch.matmul()"}, "torch.Tensor.matrix_power": {"description": "\nNote\nmatrix_power() is deprecated, use torch.linalg.matrix_power() instead.\n\n"}, "torch.Tensor.matrix_exp": {"description": "See torch.matrix_exp()"}, "torch.Tensor.max": {"description": "See torch.max()"}, "torch.Tensor.maximum": {"description": "See torch.maximum()"}, "torch.Tensor.mean": {"description": "See torch.mean()"}, "torch.Tensor.nanmean": {"description": "See torch.nanmean()"}, "torch.Tensor.median": {"description": "See torch.median()"}, "torch.Tensor.nanmedian": {"description": "See torch.nanmedian()"}, "torch.Tensor.min": {"description": "See torch.min()"}, "torch.Tensor.minimum": {"description": "See torch.minimum()"}, "torch.Tensor.mm": {"description": "See torch.mm()"}, "torch.Tensor.smm": {"description": "See torch.smm()"}, "torch.Tensor.mode": {"description": "See torch.mode()"}, "torch.Tensor.movedim": {"description": "See torch.movedim()"}, "torch.Tensor.moveaxis": {"description": "See torch.moveaxis()"}, "torch.Tensor.msort": {"description": "See torch.msort()"}, "torch.Tensor.mul": {"description": "See torch.mul()."}, "torch.Tensor.mul_": {"description": "In-place version of mul()."}, "torch.Tensor.multiply": {"description": "See torch.multiply()."}, "torch.Tensor.multiply_": {"description": "In-place version of multiply()."}, "torch.Tensor.multinomial": {"description": "See torch.multinomial()"}, "torch.Tensor.mv": {"description": "See torch.mv()"}, "torch.Tensor.mvlgamma": {"description": "See torch.mvlgamma()"}, "torch.Tensor.mvlgamma_": {"description": "In-place version of mvlgamma()"}, "torch.Tensor.nansum": {"description": "See torch.nansum()"}, "torch.Tensor.narrow": {"description": "See torch.narrow()"}, "torch.Tensor.narrow_copy": {"description": "Same as Tensor.narrow() except returning a copy rather than shared storage."}, "torch.Tensor.ndimension": {"description": "Alias for dim()"}, "torch.Tensor.nan_to_num": {"description": "See torch.nan_to_num()."}, "torch.Tensor.nan_to_num_": {"description": "In-place version of nan_to_num()."}, "torch.Tensor.ne": {"description": "See torch.ne()."}, "torch.Tensor.ne_": {"description": "In-place version of ne()."}, "torch.Tensor.not_equal": {"description": "See torch.not_equal()."}, "torch.Tensor.not_equal_": {"description": "In-place version of not_equal()."}, "torch.Tensor.neg": {"description": "See torch.neg()"}, "torch.Tensor.neg_": {"description": "In-place version of neg()"}, "torch.Tensor.negative": {"description": "See torch.negative()"}, "torch.Tensor.negative_": {"description": "In-place version of negative()"}, "torch.Tensor.nelement": {"description": "Alias for numel()"}, "torch.Tensor.nextafter": {"description": "See torch.nextafter()"}, "torch.Tensor.nextafter_": {"description": "In-place version of nextafter()"}, "torch.Tensor.nonzero": {"description": "See torch.nonzero()"}, "torch.Tensor.norm": {"description": "See torch.norm()"}, "torch.Tensor.normal_": {"description": "Fills self tensor with elements samples from the normal distribution parameterized by mean and std."}, "torch.Tensor.numel": {"description": "See torch.numel()"}, "torch.Tensor.numpy": {"description": "Returns self tensor as a NumPy ndarray."}, "torch.Tensor.orgqr": {"description": "See torch.orgqr()"}, "torch.Tensor.ormqr": {"description": "See torch.ormqr()"}, "torch.Tensor.outer": {"description": "See torch.outer()."}, "torch.Tensor.permute": {"description": "See torch.permute()"}, "torch.Tensor.pin_memory": {"description": "Copies the tensor to pinned memory, if it\u2019s not already pinned."}, "torch.Tensor.pinverse": {"description": "See torch.pinverse()"}, "torch.Tensor.polygamma": {"description": "See torch.polygamma()"}, "torch.Tensor.polygamma_": {"description": "In-place version of polygamma()"}, "torch.Tensor.positive": {"description": "See torch.positive()"}, "torch.Tensor.pow": {"description": "See torch.pow()"}, "torch.Tensor.pow_": {"description": "In-place version of pow()"}, "torch.Tensor.prod": {"description": "See torch.prod()"}, "torch.Tensor.put_": {"Parameters": {"index (LongTensor)": "the indices into self", "source (Tensor)": "the tensor containing values to copy from", "accumulate (bool)": "whether to accumulate into self"}, "description": "Copies the elements from source into the positions specified by index."}, "torch.Tensor.qr": {"description": "See torch.qr()"}, "torch.Tensor.qscheme": {"description": "Returns the quantization scheme of a given QTensor."}, "torch.Tensor.quantile": {"description": "See torch.quantile()"}, "torch.Tensor.nanquantile": {"description": "See torch.nanquantile()"}, "torch.Tensor.q_scale": {"description": "Given a Tensor quantized by linear(affine) quantization, returns the scale of the underlying quantizer()."}, "torch.Tensor.q_zero_point": {"description": "Given a Tensor quantized by linear(affine) quantization, returns the zero_point of the underlying quantizer()."}, "torch.Tensor.q_per_channel_scales": {"description": "Given a Tensor quantized by linear (affine) per-channel quantization, returns a Tensor of scales of the underlying quantizer."}, "torch.Tensor.q_per_channel_zero_points": {"description": "Given a Tensor quantized by linear (affine) per-channel quantization, returns a tensor of zero_points of the underlying quantizer."}, "torch.Tensor.q_per_channel_axis": {"description": "Given a Tensor quantized by linear (affine) per-channel quantization, returns the index of dimension on which per-channel quantization is applied."}, "torch.Tensor.rad2deg": {"description": "See torch.rad2deg()"}, "torch.Tensor.random_": {"description": "Fills self tensor with numbers sampled from the discrete uniform distribution over [from, to - 1]."}, "torch.Tensor.ravel": {"description": "see torch.ravel()"}, "torch.Tensor.reciprocal": {"description": "See torch.reciprocal()"}, "torch.Tensor.reciprocal_": {"description": "In-place version of reciprocal()"}, "torch.Tensor.record_stream": {"description": "Ensures that the tensor memory is not reused for another tensor until all current work queued on stream are complete."}, "torch.Tensor.register_hook": {"description": "Registers a backward hook."}, "torch.Tensor.remainder": {"description": "See torch.remainder()"}, "torch.Tensor.remainder_": {"description": "In-place version of remainder()"}, "torch.Tensor.renorm": {"description": "See torch.renorm()"}, "torch.Tensor.renorm_": {"description": "In-place version of renorm()"}, "torch.Tensor.repeat": {"Parameters": {"sizes (torch.Size or int...)": "The number of times to repeat this tensor along each\ndimension"}, "description": "Repeats this tensor along the specified dimensions."}, "torch.Tensor.repeat_interleave": {"description": "See torch.repeat_interleave()."}, "torch.Tensor.requires_grad": {"description": "Is True if gradients need to be computed for this Tensor, False otherwise."}, "torch.Tensor.requires_grad_": {"Parameters": {"requires_grad (bool)": "If autograd should record operations on this tensor.\nDefault: True."}, "description": "Change if autograd should record operations on this tensor: sets this tensor\u2019s requires_grad attribute in-place."}, "torch.Tensor.reshape": {"Parameters": {"shape (tuple of python:ints or int...)": "the desired shape"}, "description": "Returns a tensor with the same data and number of elements as self but with the specified shape."}, "torch.Tensor.reshape_as": {"Parameters": {"other (torch.Tensor)": "The result tensor has the same shape\nas other."}, "description": "Returns this tensor as the same shape as other."}, "torch.Tensor.resize_": {"Parameters": {"sizes (torch.Size or int...)": "the desired size", "memory_format (torch.memory_format, optional)": "the desired memory format of\nTensor. Default: torch.contiguous_format. Note that memory format of\nself is going to be unaffected if self.size() matches sizes."}, "description": "Resizes self tensor to the specified size."}, "torch.Tensor.resize_as_": {"Parameters": {"memory_format (torch.memory_format, optional)": "the desired memory format of\nTensor. Default: torch.contiguous_format. Note that memory format of\nself is going to be unaffected if self.size() matches tensor.size()."}, "description": "Resizes the self tensor to be the same size as the specified tensor."}, "torch.Tensor.retain_grad": {"description": "Enables this Tensor to have their grad populated during backward()."}, "torch.Tensor.retains_grad": {"description": "Is True if this Tensor is non-leaf and its grad is enabled to be populated during backward(), False otherwise."}, "torch.Tensor.roll": {"description": "See torch.roll()"}, "torch.Tensor.rot90": {"description": "See torch.rot90()"}, "torch.Tensor.round": {"description": "See torch.round()"}, "torch.Tensor.round_": {"description": "In-place version of round()"}, "torch.Tensor.rsqrt": {"description": "See torch.rsqrt()"}, "torch.Tensor.rsqrt_": {"description": "In-place version of rsqrt()"}, "torch.Tensor.scatter": {"description": "Out-of-place version of torch.Tensor.scatter_()"}, "torch.Tensor.scatter_": {"Parameters": {"dim (int)": "the axis along which to index", "index (LongTensor)": "the indices of elements to scatter, can be either empty\nor of the same dimensionality as src. When empty, the operation\nreturns self unchanged.", "src (Tensor or float)": "the source element(s) to scatter.", "reduce (str, optional)": "reduction operation to apply, can be either\n'add' or 'multiply'."}, "description": "Writes all values from the tensor src into self at the indices specified in the index tensor."}, "torch.Tensor.scatter_add_": {"Parameters": {"dim (int)": "the axis along which to index", "index (LongTensor)": "the indices of elements to scatter and add, can be\neither empty or of the same dimensionality as src. When empty, the\noperation returns self unchanged.", "src (Tensor)": "the source elements to scatter and add"}, "description": "Adds all values from the tensor other into self at the indices specified in the index tensor in a similar fashion as scatter_()."}, "torch.Tensor.scatter_add": {"description": "Out-of-place version of torch.Tensor.scatter_add_()"}, "torch.Tensor.scatter_reduce": {"description": "See torch.scatter_reduce()"}, "torch.Tensor.select": {"description": "See torch.select()"}, "torch.Tensor.select_scatter": {"description": "See torch.select_scatter()"}, "torch.Tensor.set_": {"Parameters": {"source (Tensor or Storage)": "the tensor or storage to use", "storage_offset (int, optional)": "the offset in the storage", "size (torch.Size, optional)": "the desired size. Defaults to the size of the source.", "stride (tuple, optional)": "the desired stride. Defaults to C-contiguous strides."}, "description": "Sets the underlying storage, size, and strides."}, "torch.Tensor.share_memory_": {"description": "Moves the underlying storage to shared memory."}, "torch.Tensor.short": {"Parameters": {"memory_format (torch.memory_format, optional)": "the desired memory format of\nreturned Tensor. Default: torch.preserve_format."}, "description": "self.short() is equivalent to self.to(torch.int16)."}, "torch.Tensor.sigmoid": {"description": "See torch.sigmoid()"}, "torch.Tensor.sigmoid_": {"description": "In-place version of sigmoid()"}, "torch.Tensor.sign": {"description": "See torch.sign()"}, "torch.Tensor.sign_": {"description": "In-place version of sign()"}, "torch.Tensor.signbit": {"description": "See torch.signbit()"}, "torch.Tensor.sgn": {"description": "See torch.sgn()"}, "torch.Tensor.sgn_": {"description": "In-place version of sgn()"}, "torch.Tensor.sin": {"description": "See torch.sin()"}, "torch.Tensor.sin_": {"description": "In-place version of sin()"}, "torch.Tensor.sinc": {"description": "See torch.sinc()"}, "torch.Tensor.sinc_": {"description": "In-place version of sinc()"}, "torch.Tensor.sinh": {"description": "See torch.sinh()"}, "torch.Tensor.sinh_": {"description": "In-place version of sinh()"}, "torch.Tensor.asinh": {"description": "See torch.asinh()"}, "torch.Tensor.asinh_": {"description": "In-place version of asinh()"}, "torch.Tensor.arcsinh": {"description": "See torch.arcsinh()"}, "torch.Tensor.arcsinh_": {"description": "In-place version of arcsinh()"}, "torch.Tensor.size": {"Parameters": {"dim (int, optional)": "The dimension for which to retrieve the size."}, "description": "Returns the size of the self tensor."}, "torch.Tensor.slogdet": {"description": "See torch.slogdet()"}, "torch.Tensor.slice_scatter": {"description": "See torch.slice_scatter()"}, "torch.Tensor.solve": {"description": "See torch.solve()"}, "torch.Tensor.sort": {"description": "See torch.sort()"}, "torch.Tensor.split": {"description": "See torch.split()"}, "torch.Tensor.sparse_mask": {"Parameters": {"mask (Tensor)": "a sparse tensor whose indices are used as a filter"}, "description": "Returns a new sparse tensor with values from a strided tensor self filtered by the indices of the sparse tensor mask."}, "torch.Tensor.sparse_dim": {"description": "Return the number of sparse dimensions in a sparse tensor self."}, "torch.Tensor.sqrt": {"description": "See torch.sqrt()"}, "torch.Tensor.sqrt_": {"description": "In-place version of sqrt()"}, "torch.Tensor.square": {"description": "See torch.square()"}, "torch.Tensor.square_": {"description": "In-place version of square()"}, "torch.Tensor.squeeze": {"description": "See torch.squeeze()"}, "torch.Tensor.squeeze_": {"description": "In-place version of squeeze()"}, "torch.Tensor.std": {"description": "See torch.std()"}, "torch.Tensor.stft": {"description": "See torch.stft()"}, "torch.Tensor.storage": {"description": "Returns the underlying storage."}, "torch.Tensor.storage_offset": {"description": "Returns self tensor\u2019s offset in the underlying storage in terms of number of storage elements (not bytes)."}, "torch.Tensor.storage_type": {"description": "Returns the type of the underlying storage."}, "torch.Tensor.stride": {"Parameters": {"dim (int, optional)": "the desired dimension in which stride is required"}, "description": "Returns the stride of self tensor."}, "torch.Tensor.sub": {"description": "See torch.sub()."}, "torch.Tensor.sub_": {"description": "In-place version of sub()"}, "torch.Tensor.subtract": {"description": "See torch.subtract()."}, "torch.Tensor.subtract_": {"description": "In-place version of subtract()."}, "torch.Tensor.sum": {"description": "See torch.sum()"}, "torch.Tensor.sum_to_size": {"Parameters": {"size (int...)": "a sequence of integers defining the shape of the output tensor."}, "description": "Sum this tensor to size."}, "torch.Tensor.svd": {"description": "See torch.svd()"}, "torch.Tensor.swapaxes": {"description": "See torch.swapaxes()"}, "torch.Tensor.swapdims": {"description": "See torch.swapdims()"}, "torch.Tensor.symeig": {"description": "See torch.symeig()"}, "torch.Tensor.t": {"description": "See torch.t()"}, "torch.Tensor.t_": {"description": "In-place version of t()"}, "torch.Tensor.tensor_split": {"description": "See torch.tensor_split()"}, "torch.Tensor.tile": {"description": "See torch.tile()"}, "torch.Tensor.to": {"description": "Performs Tensor dtype and/or device conversion."}, "torch.Tensor.to_mkldnn": {"description": "Returns a copy of the tensor in torch.mkldnn layout."}, "torch.Tensor.take": {"description": "See torch.take()"}, "torch.Tensor.take_along_dim": {"description": "See torch.take_along_dim()"}, "torch.Tensor.tan": {"description": "See torch.tan()"}, "torch.Tensor.tan_": {"description": "In-place version of tan()"}, "torch.Tensor.tanh": {"description": "See torch.tanh()"}, "torch.Tensor.tanh_": {"description": "In-place version of tanh()"}, "torch.Tensor.atanh": {"description": "See torch.atanh()"}, "torch.Tensor.atanh_": {"description": "In-place version of atanh()"}, "torch.Tensor.arctanh": {"description": "See torch.arctanh()"}, "torch.Tensor.arctanh_": {"description": "In-place version of arctanh()"}, "torch.Tensor.tolist": {"description": "Returns the tensor as a (nested) list."}, "torch.Tensor.topk": {"description": "See torch.topk()"}, "torch.Tensor.to_sparse": {"Parameters": {"sparseDims (int, optional)": "the number of sparse dimensions to include in the new sparse tensor"}, "description": "Returns a sparse copy of the tensor."}, "torch.Tensor.trace": {"description": "See torch.trace()"}, "torch.Tensor.transpose": {"description": "See torch.transpose()"}, "torch.Tensor.transpose_": {"description": "In-place version of transpose()"}, "torch.Tensor.triangular_solve": {"description": "See torch.triangular_solve()"}, "torch.Tensor.tril": {"description": "See torch.tril()"}, "torch.Tensor.tril_": {"description": "In-place version of tril()"}, "torch.Tensor.triu": {"description": "See torch.triu()"}, "torch.Tensor.triu_": {"description": "In-place version of triu()"}, "torch.Tensor.true_divide": {"description": "See torch.true_divide()"}, "torch.Tensor.true_divide_": {"description": "In-place version of true_divide_()"}, "torch.Tensor.trunc": {"description": "See torch.trunc()"}, "torch.Tensor.trunc_": {"description": "In-place version of trunc()"}, "torch.Tensor.type": {"Parameters": {"dtype (dpython:type or string)": "The desired type", "non_blocking (bool)": "If True, and the source is in pinned memory\nand destination is on the GPU or vice versa, the copy is performed\nasynchronously with respect to the host. Otherwise, the argument\nhas no effect.", "**kwargs": "For compatibility, may contain the key async in place of\nthe non_blocking argument. The async arg is deprecated."}, "description": "Returns the type if dtype is not provided, else casts this object to the specified type."}, "torch.Tensor.type_as": {"Parameters": {"tensor (Tensor)": "the tensor which has the desired type"}, "description": "Returns this tensor cast to the type of the given tensor."}, "torch.Tensor.unbind": {"description": "See torch.unbind()"}, "torch.Tensor.unfold": {"Parameters": {"dimension (int)": "dimension in which unfolding happens", "size (int)": "the size of each slice that is unfolded", "step (int)": "the step between each slice"}, "description": "Returns a view of the original tensor which contains all slices of size size from self tensor in the dimension dimension."}, "torch.Tensor.uniform_": {"description": "Fills self tensor with numbers sampled from the continuous uniform distribution:"}, "torch.Tensor.unique": {"description": "Returns the unique elements of the input tensor."}, "torch.Tensor.unique_consecutive": {"description": "Eliminates all but the first element from every consecutive group of equivalent elements."}, "torch.Tensor.unsqueeze": {"description": "See torch.unsqueeze()"}, "torch.Tensor.unsqueeze_": {"description": "In-place version of unsqueeze()"}, "torch.Tensor.values": {"description": "Return the values tensor of a sparse COO tensor."}, "torch.Tensor.var": {"description": "See torch.var()"}, "torch.Tensor.vdot": {"description": "See torch.vdot()"}, "torch.Tensor.view": {"Parameters": {"dtype (torch.dtype)": "the desired dtype"}, "description": "Returns a new tensor with the same data as the self tensor but of a different shape."}, "torch.Tensor.view_as": {"Parameters": {"other (torch.Tensor)": "The result tensor has the same size\nas other."}, "description": "View this tensor as the same size as other."}, "torch.Tensor.vsplit": {"description": "See torch.vsplit()"}, "torch.Tensor.where": {"description": "self.where(condition, y) is equivalent to torch.where(condition, self, y)."}, "torch.Tensor.xlogy": {"description": "See torch.xlogy()"}, "torch.Tensor.xlogy_": {"description": "In-place version of xlogy()"}, "torch.Tensor.zero_": {"description": "Fills self tensor with zeros."}, "torch.autograd.backward": {"Parameters": {"tensors (Sequence[Tensor] or Tensor)": "Tensors of which the derivative will be\ncomputed.", "grad_tensors (Sequence[Tensor or None] or Tensor, optional)": "The \u201cvector\u201d in\nthe Jacobian-vector product, usually gradients w.r.t. each element of\ncorresponding tensors. None values can be specified for scalar Tensors or\nones that don\u2019t require grad. If a None value would be acceptable for all\ngrad_tensors, then this argument is optional.", "retain_graph (bool, optional)": "If False, the graph used to compute the grad\nwill be freed. Note that in nearly all cases setting this option to True\nis not needed and often can be worked around in a much more efficient\nway. Defaults to the value of create_graph.", "create_graph (bool, optional)": "If True, graph of the derivative will\nbe constructed, allowing to compute higher order derivative products.\nDefaults to False.", "inputs (Sequence[Tensor] or Tensor, optional)": "Inputs w.r.t. which the gradient\nbe will accumulated into .grad. All other Tensors will be ignored. If\nnot provided, the gradient is accumulated into all the leaf Tensors that\nwere used to compute the attr::tensors."}, "description": "Computes the sum of gradients of given tensors with respect to graph leaves."}, "torch.autograd.grad": {"Parameters": {"outputs (sequence of Tensor)": "outputs of the differentiated function.", "inputs (sequence of Tensor)": "Inputs w.r.t. which the gradient will be\nreturned (and not accumulated into .grad).", "grad_outputs (sequence of Tensor)": "The \u201cvector\u201d in the vector-Jacobian product.\nUsually gradients w.r.t. each output. None values can be specified for scalar\nTensors or ones that don\u2019t require grad. If a None value would be acceptable\nfor all grad_tensors, then this argument is optional. Default: None.", "retain_graph (bool, optional)": "If False, the graph used to compute the grad\nwill be freed. Note that in nearly all cases setting this option to True\nis not needed and often can be worked around in a much more efficient\nway. Defaults to the value of create_graph.", "create_graph (bool, optional)": "If True, graph of the derivative will\nbe constructed, allowing to compute higher order derivative products.\nDefault: False.", "allow_unused (bool, optional)": "If False, specifying inputs that were not\nused when computing outputs (and therefore their grad is always zero)\nis an error. Defaults to False.", "is_grads_batched (bool, optional)": "If True, the first dimension of each\ntensor in grad_outputs will be interpreted as the batch dimension.\nInstead of computing a single vector-Jacobian product, we compute a\nbatch of vector-Jacobian products for each \u201cvector\u201d in the batch.\nWe use the vmap prototype feature as the backend to vectorize calls\nto the autograd engine so that this computation can be performed in a\nsingle call. This should lead to performance improvements when compared\nto manually looping and performing backward multiple times. Note that\ndue to this feature being experimental, there may be performance\ncliffs. Please use torch._C._debug_only_display_vmap_fallback_warnings(True)\nto show any performance warnings and file an issue on github if warnings exist\nfor your use case. Defaults to False."}, "description": "Computes and returns the sum of gradients of outputs with respect to the inputs."}, "torch.autograd.forward_ad.dual_level": {"description": "Context-manager that enables forward AD."}, "torch.autograd.forward_ad.make_dual": {"description": "Associates a tensor value with a forward gradient, the tangent, to create a \u201cdual tensor\u201d, which is used to compute forward AD gradients."}, "torch.autograd.forward_ad.unpack_dual": {"description": "Unpacks a \u201cdual tensor\u201d to get both its Tensor value and its forward AD gradient."}, "torch.autograd.functional.jacobian": {"Parameters": {"func (function)": "a Python function that takes Tensor inputs and returns\na tuple of Tensors or a Tensor.", "inputs (tuple of Tensors or Tensor)": "inputs to the function func.", "create_graph (bool, optional)": "If True, the Jacobian will be\ncomputed in a differentiable manner. Note that when strict is\nFalse, the result can not require gradients or be disconnected\nfrom the inputs.  Defaults to False.", "strict (bool, optional)": "If True, an error will be raised when we\ndetect that there exists an input such that all the outputs are\nindependent of it. If False, we return a Tensor of zeros as the\njacobian for said inputs, which is the expected mathematical value.\nDefaults to False.", "vectorize (bool, optional)": "This feature is experimental.\nPlease consider using\nfunctorch\u2019s jacrev or jacfwd\ninstead if you are looking for something less experimental and more performant.\nWhen computing the jacobian, usually we invoke\nautograd.grad once per row of the jacobian. If this flag is\nTrue, we perform only a single autograd.grad call with\nbatched_grad=True which uses the vmap prototype feature.\nThough this should lead to performance improvements in many cases,\nbecause this feature is still experimental, there may be performance\ncliffs. See torch.autograd.grad()\u2019s batched_grad parameter for\nmore information.", "strategy (str, optional)": "Set to \"forward-mode\" or \"reverse-mode\" to\ndetermine whether the Jacobian will be computed with forward or reverse\nmode AD. Currently, \"forward-mode\" requires vectorized=True.\nDefaults to \"reverse-mode\". If func has more outputs than\ninputs, \"forward-mode\" tends to be more performant. Otherwise,\nprefer to use \"reverse-mode\"."}, "Returns": "if there is a single\ninput and output, this will be a single Tensor containing the\nJacobian for the linearized inputs and output. If one of the two is\na tuple, then the Jacobian will be a tuple of Tensors. If both of\nthem are tuples, then the Jacobian will be a tuple of tuple of\nTensors where Jacobian[i][j] will contain the Jacobian of the\nith output and jth input and will have as size the\nconcatenation of the sizes of the corresponding output and the\ncorresponding input and will have same dtype and device as the\ncorresponding input. If strategy is forward-mode, the dtype will be\nthat of the output; otherwise, the input.\n", "description": "Function that computes the Jacobian of a given function."}, "torch.autograd.functional.hessian": {"Parameters": {"func (function)": "a Python function that takes Tensor inputs and returns\na Tensor with a single element.", "inputs (tuple of Tensors or Tensor)": "inputs to the function func.", "create_graph (bool, optional)": "If True, the Hessian will be computed in\na differentiable manner. Note that when strict is False, the result can not\nrequire gradients or be disconnected from the inputs.\nDefaults to False.", "strict (bool, optional)": "If True, an error will be raised when we detect that there exists an input\nsuch that all the outputs are independent of it. If False, we return a Tensor of zeros as the\nhessian for said inputs, which is the expected mathematical value.\nDefaults to False.", "vectorize (bool, optional)": "This feature is experimental.\nPlease consider using\nfunctorch\ninstead if you are looking for something less experimental and more performant.\nWhen computing the hessian, usually we invoke\nautograd.grad once per row of the hessian. If this flag is\nTrue, we use the vmap prototype feature as the backend to\nvectorize calls to autograd.grad so we only invoke it once\ninstead of once per row. This should lead to performance\nimprovements in many use cases, however, due to this feature\nbeing incomplete, there may be performance cliffs. Please\nuse torch._C._debug_only_display_vmap_fallback_warnings(True)\nto show any performance warnings and file us issues if\nwarnings exist for your use case. Defaults to False.", "outer_jacobian_strategy (str, optional)": "The Hessian is computed by\ncomputing the Jacobian of a Jacobian. The inner Jacobian is always\ncomputed in reverse-mode AD. Setting strategy to \"forward-mode\"\nor \"reverse-mode\" determines whether the outer Jacobian will be\ncomputed with forward or reverse mode AD. Currently, computing the outer\nJacobian in \"forward-mode\" requires vectorized=True. Defaults\nto \"reverse-mode\"."}, "Returns": "if there is a single input,\nthis will be a single Tensor containing the Hessian for the input.\nIf it is a tuple, then the Hessian will be a tuple of tuples where\nHessian[i][j] will contain the Hessian of the ith input\nand jth input with size the sum of the size of the ith input plus\nthe size of the jth input. Hessian[i][j] will have the same\ndtype and device as the corresponding ith input.\n", "description": "Function that computes the Hessian of a given scalar function."}, "torch.autograd.functional.vjp": {"Parameters": {"func (function)": "a Python function that takes Tensor inputs and returns\na tuple of Tensors or a Tensor.", "inputs (tuple of Tensors or Tensor)": "inputs to the function func.", "v (tuple of Tensors or Tensor)": "The vector for which the vector\nJacobian product is computed.  Must be the same size as the output\nof func. This argument is optional when the output of func\ncontains a single element and (if it is not provided) will be set\nas a Tensor containing a single 1.", "create_graph (bool, optional)": "If True, both the output and result\nwill be computed in a differentiable way. Note that when strict\nis False, the result can not require gradients or be\ndisconnected from the inputs.  Defaults to False.", "strict (bool, optional)": "If True, an error will be raised when we\ndetect that there exists an input such that all the outputs are\nindependent of it. If False, we return a Tensor of zeros as the\nvjp for said inputs, which is the expected mathematical value.\nDefaults to False."}, "Returns": "\ntuple with:func_output (tuple of Tensors or Tensor): output of func(inputs)\nvjp (tuple of Tensors or Tensor): result of the dot product with\nthe same shape as the inputs.\n\n\n\n", "description": "Function that computes the dot product between a vector v and the Jacobian of the given function at the point given by the inputs."}, "torch.autograd.functional.jvp": {"Parameters": {"func (function)": "a Python function that takes Tensor inputs and returns\na tuple of Tensors or a Tensor.", "inputs (tuple of Tensors or Tensor)": "inputs to the function func.", "v (tuple of Tensors or Tensor)": "The vector for which the Jacobian\nvector product is computed. Must be the same size as the input of\nfunc. This argument is optional when the input to func\ncontains a single element and (if it is not provided) will be set\nas a Tensor containing a single 1.", "create_graph (bool, optional)": "If True, both the output and result\nwill be computed in a differentiable way. Note that when strict\nis False, the result can not require gradients or be\ndisconnected from the inputs.  Defaults to False.", "strict (bool, optional)": "If True, an error will be raised when we\ndetect that there exists an input such that all the outputs are\nindependent of it. If False, we return a Tensor of zeros as the\njvp for said inputs, which is the expected mathematical value.\nDefaults to False."}, "Returns": "\ntuple with:func_output (tuple of Tensors or Tensor): output of func(inputs)\njvp (tuple of Tensors or Tensor): result of the dot product with\nthe same shape as the output.\n\n\n\n", "description": "Function that computes the dot product between  the Jacobian of the given function at the point given by the inputs and a vector v."}, "torch.autograd.functional.vhp": {"Parameters": {"func (function)": "a Python function that takes Tensor inputs and returns\na Tensor with a single element.", "inputs (tuple of Tensors or Tensor)": "inputs to the function func.", "v (tuple of Tensors or Tensor)": "The vector for which the vector Hessian\nproduct is computed. Must be the same size as the input of\nfunc. This argument is optional when func\u2019s input contains\na single element and (if it is not provided) will be set as a\nTensor containing a single 1.", "create_graph (bool, optional)": "If True, both the output and result\nwill be computed in a differentiable way. Note that when strict\nis False, the result can not require gradients or be\ndisconnected from the inputs.\nDefaults to False.", "strict (bool, optional)": "If True, an error will be raised when we\ndetect that there exists an input such that all the outputs are\nindependent of it. If False, we return a Tensor of zeros as the\nvhp for said inputs, which is the expected mathematical value.\nDefaults to False."}, "Returns": "\ntuple with:func_output (tuple of Tensors or Tensor): output of func(inputs)\nvhp (tuple of Tensors or Tensor): result of the dot product with the\nsame shape as the inputs.\n\n\n\n", "description": "Function that computes the dot product between a vector v and the Hessian of a given scalar function at the point given by the inputs."}, "torch.autograd.functional.hvp": {"Parameters": {"func (function)": "a Python function that takes Tensor inputs and returns\na Tensor with a single element.", "inputs (tuple of Tensors or Tensor)": "inputs to the function func.", "v (tuple of Tensors or Tensor)": "The vector for which the Hessian vector\nproduct is computed. Must be the same size as the input of\nfunc. This argument is optional when func\u2019s input contains\na single element and (if it is not provided) will be set as a\nTensor containing a single 1.", "create_graph (bool, optional)": "If True, both the output and result will be\ncomputed in a differentiable way. Note that when strict is\nFalse, the result can not require gradients or be disconnected\nfrom the inputs.  Defaults to False.", "strict (bool, optional)": "If True, an error will be raised when we\ndetect that there exists an input such that all the outputs are\nindependent of it. If False, we return a Tensor of zeros as the\nhvp for said inputs, which is the expected mathematical value.\nDefaults to False."}, "Returns": "\ntuple with:func_output (tuple of Tensors or Tensor): output of func(inputs)\nhvp (tuple of Tensors or Tensor): result of the dot product with\nthe same shape as the inputs.\n\n\n\n", "description": "Function that computes the dot product between the Hessian of a given scalar function and a vector v at the point given by the inputs."}, "torch.autograd.no_grad": {"description": "Context-manager that disabled gradient calculation."}, "torch.autograd.enable_grad": {"description": "Context-manager that enables gradient calculation."}, "torch.autograd.set_grad_enabled": {"Parameters": {"mode (bool)": "Flag whether to enable grad (True), or disable\n(False). This can be used to conditionally enable\ngradients."}, "description": "Context-manager that sets gradient calculation to on or off."}, "torch.autograd.inference_mode": {"Parameters": {"mode (bool)": "Flag whether to enable or disable inference mode"}, "description": "Context-manager that enables or disables inference mode"}, "torch.Tensor.backward([gradient,\u00a0\u2026])": {"description": "Computes the gradient of current tensor w.r.t."}, "torch.Tensor.register_hook(hook)": {"description": "Registers a backward hook."}, "torch.Tensor.retain_grad()": {"description": "Enables this Tensor to have their grad populated during backward()."}, "torch.autograd.Function.forward": {"description": "Performs the operation."}, "torch.autograd.Function.backward": {"description": "Defines a formula for differentiating the operation with backward mode automatic differentiation (alias to the vjp function)."}, "torch.autograd.Function.jvp": {"description": "Defines a formula for differentiating the operation with forward mode automatic differentiation."}, "torch.autograd.function.FunctionCtx.mark_dirty": {"description": "Marks given tensors as modified in an in-place operation."}, "torch.autograd.function.FunctionCtx.mark_non_differentiable": {"description": "Marks outputs as non-differentiable."}, "torch.autograd.function.FunctionCtx.save_for_backward": {"description": "Saves given tensors for a future call to backward()."}, "torch.autograd.function.FunctionCtx.set_materialize_grads": {"description": "Sets whether to materialize output grad tensors."}, "torch.autograd.gradcheck": {"Parameters": {"func (function)": "a Python function that takes Tensor inputs and returns\na Tensor or a tuple of Tensors", "inputs (tuple of Tensor or Tensor)": "inputs to the function", "eps (float, optional)": "perturbation for finite differences", "atol (float, optional)": "absolute tolerance", "rtol (float, optional)": "relative tolerance", "raise_exception (bool, optional)": "indicating whether to raise an exception if\nthe check fails. The exception gives more information about the\nexact nature of the failure. This is helpful when debugging gradchecks.", "check_sparse_nnz (bool, optional)": "if True, gradcheck allows for SparseTensor input,\nand for any SparseTensor at input, gradcheck will perform check at nnz positions only.", "nondet_tol (float, optional)": "tolerance for non-determinism. When running\nidentical inputs through the differentiation, the results must either match\nexactly (default, 0.0) or be within this tolerance.", "check_undefined_grad (bool, optional)": "if True, check if undefined output grads\nare supported and treated as zeros, for Tensor outputs.", "check_batched_grad (bool, optional)": "if True, check if we can compute\nbatched gradients using prototype vmap support. Defaults to False.", "check_batched_forward_grad (bool, optional)": "if True, checks if we can compute\nbatched forward gradients using forward ad and prototype vmap support. Defaults to False.", "check_forward_ad (bool, optional)": "if True, check that the gradients computed with forward\nmode AD match the numerical ones. Defaults to False.", "check_backward_ad (bool, optional)": "if False, do not perform any checks that rely on\nbackward mode AD to be implemented. Defaults to True.", "fast_mode (bool, optional)": "Fast mode for gradcheck and gradgradcheck is currently only\nimplemented for R to R functions. If none of the inputs and outputs are complex\na faster implementation of gradcheck that no longer computes the entire jacobian\nis run; otherwise, we fall back to the slow implementation."}, "Returns": "True if all differences satisfy allclose condition\n", "description": "Check gradients computed via small finite differences against analytical gradients w.r.t."}, "torch.autograd.gradgradcheck": {"Parameters": {"func (function)": "a Python function that takes Tensor inputs and returns\na Tensor or a tuple of Tensors", "inputs (tuple of Tensor or Tensor)": "inputs to the function", "grad_outputs (tuple of Tensor or Tensor, optional)": "The gradients with\nrespect to the function\u2019s outputs.", "eps (float, optional)": "perturbation for finite differences", "atol (float, optional)": "absolute tolerance", "rtol (float, optional)": "relative tolerance", "gen_non_contig_grad_outputs (bool, optional)": "if grad_outputs is\nNone and gen_non_contig_grad_outputs is True, the\nrandomly generated gradient outputs are made to be noncontiguous", "raise_exception (bool, optional)": "indicating whether to raise an exception if\nthe check fails. The exception gives more information about the\nexact nature of the failure. This is helpful when debugging gradchecks.", "nondet_tol (float, optional)": "tolerance for non-determinism. When running\nidentical inputs through the differentiation, the results must either match\nexactly (default, 0.0) or be within this tolerance. Note that a small amount\nof nondeterminism in the gradient will lead to larger inaccuracies in\nthe second derivative.", "check_undefined_grad (bool, optional)": "if True, check if undefined output grads\nare supported and treated as zeros", "check_batched_grad (bool, optional)": "if True, check if we can compute\nbatched gradients using prototype vmap support. Defaults to False.", "fast_mode (bool, optional)": "if True, run a faster implementation of gradgradcheck that\nno longer computes the entire jacobian."}, "Returns": "True if all differences satisfy allclose condition\n", "description": "Check gradients of gradients computed via small finite differences against analytical gradients w.r.t."}, "torch.autograd.profiler.profile.export_chrome_trace": {"Parameters": {"path (str)": "Path where the trace will be written."}, "description": "Exports an EventList as a Chrome tracing tools file."}, "torch.autograd.profiler.profile.key_averages": {"Parameters": {"group_by_input_shapes": "group entries by\n(event name, input shapes) rather than just event name.\nThis is useful to see which input shapes contribute to the runtime\nthe most and may help with size-specific optimizations or\nchoosing the best candidates for quantization (aka fitting a roof line)", "group_by_stack_n": "group by top n stack trace entries"}, "Returns": "An EventList containing FunctionEventAvg objects.\n", "description": "Averages all function events over their keys."}, "torch.autograd.profiler.profile.self_cpu_time_total": {"description": "Returns total time spent on CPU obtained as a sum of all self times across all the events."}, "torch.autograd.profiler.profile.total_average": {"Returns": "A FunctionEventAvg object.\n", "description": "Averages all events."}, "torch.autograd.profiler.load_nvprof": {"Parameters": {"path (str)": "path to nvprof trace"}, "description": "Opens an nvprof trace file and parses autograd annotations."}, "torch.cuda.StreamContext": {"Parameters": {"Stream (Stream)": "selected stream. This manager is a no-op if it\u2019s\nNone."}, "description": "Context-manager that selects a given stream."}, "torch.cuda.can_device_access_peer": {"description": "Checks if peer access between two devices is possible."}, "torch.cuda.current_blas_handle": {"description": "Returns cublasHandle_t pointer to current cuBLAS handle"}, "torch.cuda.current_device": {"description": "Returns the index of a currently selected device."}, "torch.cuda.current_stream": {"Parameters": {"device (torch.device or int, optional)": "selected device. Returns\nthe currently selected Stream for the current device, given\nby current_device(), if device is None\n(default)."}, "description": "Returns the currently selected Stream for a given device."}, "torch.cuda.default_stream": {"Parameters": {"device (torch.device or int, optional)": "selected device. Returns\nthe default Stream for the current device, given by\ncurrent_device(), if device is None\n(default)."}, "description": "Returns the default Stream for a given device."}, "torch.cuda.device": {"Parameters": {"device (torch.device or int)": "device index to select. It\u2019s a no-op if\nthis argument is a negative integer or None."}, "description": "Context-manager that changes the selected device."}, "torch.cuda.device_count": {"description": "Returns the number of GPUs available."}, "torch.cuda.device_of": {"Parameters": {"obj (Tensor or Storage)": "object allocated on the selected device."}, "description": "Context-manager that changes the current device to that of given object."}, "torch.cuda.get_arch_list": {"description": "Returns list CUDA architectures this library was compiled for."}, "torch.cuda.get_device_capability": {"Parameters": {"device (torch.device or int, optional)": "device for which to return the\ndevice capability. This function is a no-op if this argument is\na negative integer. It uses the current device, given by\ncurrent_device(), if device is None\n(default)."}, "Returns": "the major and minor cuda capability of the device\n", "description": "Gets the cuda capability of a device."}, "torch.cuda.get_device_name": {"Parameters": {"device (torch.device or int, optional)": "device for which to return the\nname. This function is a no-op if this argument is a negative\ninteger. It uses the current device, given by current_device(),\nif device is None (default)."}, "Returns": "the name of the device\n", "description": "Gets the name of a device."}, "torch.cuda.get_device_properties": {"Parameters": {"device (torch.device or int or str)": "device for which to return the\nproperties of the device."}, "Returns": "the properties of the device\n", "description": "Gets the properties of a device."}, "torch.cuda.get_gencode_flags": {"description": "Returns NVCC gencode flags this library was compiled with."}, "torch.cuda.get_sync_debug_mode": {"description": "Returns current value of debug mode for cuda synchronizing operations."}, "torch.cuda.init": {"description": "Initialize PyTorch\u2019s CUDA state."}, "torch.cuda.ipc_collect": {"description": "Force collects GPU memory after it has been released by CUDA IPC."}, "torch.cuda.is_available": {"description": "Returns a bool indicating if CUDA is currently available."}, "torch.cuda.is_initialized": {"description": "Returns whether PyTorch\u2019s CUDA state has been initialized."}, "torch.cuda.memory_usage": {"Parameters": {"device (torch.device or int, optional)": "selected device. Returns\nstatistic for the current device, given by current_device(),\nif device is None (default)."}, "description": "Returns the percent of time over the past sample period during which global (device) memory was being read or written."}, "torch.cuda.set_device": {"Parameters": {"device (torch.device or int)": "selected device. This function is a no-op\nif this argument is negative."}, "description": "Sets the current device."}, "torch.cuda.set_stream": {"Parameters": {"stream (Stream)": "selected stream. This function is a no-op\nif this argument is None."}, "description": "Sets the current stream.This is a wrapper API to set the stream."}, "torch.cuda.set_sync_debug_mode": {"Parameters": {"debug_mode (str or int)": "if \u201cdefault\u201d or 0, don\u2019t error or warn on synchronizing operations,\nif \u201cwarn\u201d or 1, warn on synchronizing operations, if \u201cerror\u201d or 2, error out synchronizing operations."}, "description": "Sets the debug mode for cuda synchronizing operations."}, "torch.cuda.Stream": {"Parameters": {"device (torch.device or int, optional)": "a device on which to allocate\nthe stream. If device is None (default) or a negative\ninteger, this will use the current device.", "priority (int, optional)": "priority of the stream. Can be either\n-1 (high priority) or 0 (low priority). By default, streams have\npriority 0."}, "method": {"torch.cuda.Stream.query": {"Returns": "A boolean indicating if all kernels in this stream are completed.\n", "description": "Checks if all the work submitted has been completed."}, "torch.cuda.Stream.record_event": {"Parameters": {"event (torch.cuda.Event, optional)": "event to record. If not given, a new one\nwill be allocated."}, "Returns": "Recorded event.\n", "description": "Records an event."}, "torch.cuda.Stream.wait_event": {"Parameters": {"event (torch.cuda.Event)": "an event to wait for."}, "description": "Makes all future work submitted to the stream wait for an event."}, "torch.cuda.Stream.wait_stream": {"Parameters": {"stream (Stream)": "a stream to synchronize."}, "description": "Synchronizes with another stream."}}, "description": "Wrapper around a CUDA stream."}, "torch.cuda.synchronize": {"Parameters": {"device (torch.device or int, optional)": "device for which to synchronize.\nIt uses the current device, given by current_device(),\nif device is None (default)."}, "description": "Waits for all kernels in all streams on a CUDA device to complete."}, "torch.cuda.utilization": {"Parameters": {"device (torch.device or int, optional)": "selected device. Returns\nstatistic for the current device, given by current_device(),\nif device is None (default)."}, "description": "Returns the percent of time over the past sample period during which one or more kernels was executing on the GPU as given by nvidia-smi."}, "torch.cuda.get_rng_state": {"Parameters": {"device (torch.device or int, optional)": "The device to return the RNG state of.\nDefault: 'cuda' (i.e., torch.device('cuda'), the current CUDA device)."}, "description": "Returns the random number generator state of the specified GPU as a ByteTensor."}, "torch.cuda.get_rng_state_all": {"description": "Returns a list of ByteTensor representing the random number states of all devices."}, "torch.cuda.set_rng_state": {"Parameters": {"new_state (torch.ByteTensor)": "The desired state", "device (torch.device or int, optional)": "The device to set the RNG state.\nDefault: 'cuda' (i.e., torch.device('cuda'), the current CUDA device)."}, "description": "Sets the random number generator state of the specified GPU."}, "torch.cuda.set_rng_state_all": {"Parameters": {"new_states (Iterable of torch.ByteTensor)": "The desired state for each device"}, "description": "Sets the random number generator state of all devices."}, "torch.cuda.manual_seed": {"Parameters": {"seed (int)": "The desired seed."}, "description": "Sets the seed for generating random numbers for the current GPU."}, "torch.cuda.manual_seed_all": {"Parameters": {"seed (int)": "The desired seed."}, "description": "Sets the seed for generating random numbers on all GPUs."}, "torch.cuda.seed": {"description": "Sets the seed for generating random numbers to a random number for the current GPU."}, "torch.cuda.seed_all": {"description": "Sets the seed for generating random numbers to a random number on all GPUs."}, "torch.cuda.initial_seed": {"description": "Returns the current random seed of the current GPU."}, "torch.cuda.comm.broadcast": {"Parameters": {"tensor (Tensor)": "tensor to broadcast. Can be on CPU or GPU.", "devices (Iterable[torch.device, str or int], optional)": "an iterable of\nGPU devices, among which to broadcast.", "out (Sequence[Tensor], optional, keyword-only)": "the GPU tensors to\nstore output results."}, "Returns": "\n\nIf devices is specified,a tuple containing copies of tensor, placed on\ndevices.\n\n\n\n\nIf out is specified,a tuple containing out tensors, each containing a copy of\ntensor.\n\n\n\n\n\n", "description": "Broadcasts a tensor to specified GPU devices."}, "torch.cuda.comm.broadcast_coalesced": {"Parameters": {"tensors (sequence)": "tensors to broadcast. Must be on the same device,\neither CPU or GPU.", "devices (Iterable[torch.device, str or int])": "an iterable of GPU\ndevices, among which to broadcast.", "buffer_size (int)": "maximum size of the buffer used for coalescing"}, "Returns": "A tuple containing copies of tensor, placed on devices.\n", "description": "Broadcasts a sequence tensors to the specified GPUs."}, "torch.cuda.comm.reduce_add": {"Parameters": {"inputs (Iterable[Tensor])": "an iterable of tensors to add.", "destination (int, optional)": "a device on which the output will be\nplaced (default: current device)."}, "Returns": "A tensor containing an elementwise sum of all inputs, placed on the\ndestination device.\n", "description": "Sums tensors from multiple GPUs."}, "torch.cuda.comm.scatter": {"Parameters": {"tensor (Tensor)": "tensor to scatter. Can be on CPU or GPU.", "devices (Iterable[torch.device, str or int], optional)": "an iterable of\nGPU devices, among which to scatter.", "chunk_sizes (Iterable[int], optional)": "sizes of chunks to be placed on\neach device. It should match devices in length and sums to\ntensor.size(dim). If not specified, tensor will be divided\ninto equal chunks.", "dim (int, optional)": "A dimension along which to chunk tensor.\nDefault: 0.", "streams (Iterable[Stream], optional)": "an iterable of Streams, among\nwhich to execute the scatter. If not specified, the default stream will\nbe utilized.", "out (Sequence[Tensor], optional, keyword-only)": "the GPU tensors to\nstore output results. Sizes of these tensors must match that of\ntensor, except for dim, where the total size must\nsum to tensor.size(dim)."}, "Returns": "\n\nIf devices is specified,a tuple containing chunks of tensor, placed on\ndevices.\n\n\n\n\nIf out is specified,a tuple containing out tensors, each containing a chunk of\ntensor.\n\n\n\n\n\n", "description": "Scatters tensor across multiple GPUs."}, "torch.cuda.comm.gather": {"Parameters": {"tensors (Iterable[Tensor])": "an iterable of tensors to gather.\nTensor sizes in all dimensions other than dim have to match.", "dim (int, optional)": "a dimension along which the tensors will be\nconcatenated. Default: 0.", "destination (torch.device, str, or int, optional)": "the output device.\nCan be CPU or CUDA. Default: the current CUDA device.", "out (Tensor, optional, keyword-only)": "the tensor to store gather result.\nIts sizes must match those of tensors, except for dim,\nwhere the size must equal sum(tensor.size(dim) for tensor in tensors).\nCan be on CPU or CUDA."}, "Returns": "\n\nIf destination is specified,a tensor located on destination device, that is a result of\nconcatenating tensors along dim.\n\n\n\n\nIf out is specified,the out tensor, now containing results of concatenating\ntensors along dim.\n\n\n\n\n\n", "description": "Gathers tensors from multiple GPU devices."}, "torch.cuda.ExternalStream": {"Parameters": {"stream_ptr (int)": "Integer representation of the cudaStream_t value.\nallocated externally.", "device (torch.device or int, optional)": "the device where the stream\nwas originally allocated. if device is specified incorrectly,\nsubsequent launches using this stream may fail."}, "method": {"torch.cuda.ExternalStream.query": {"Returns": "A boolean indicating if all kernels in this stream are completed.\n", "description": "Checks if all the work submitted has been completed."}, "torch.cuda.ExternalStream.record_event": {"Parameters": {"event (torch.cuda.Event, optional)": "event to record. If not given, a new one\nwill be allocated."}, "Returns": "Recorded event.\n", "description": "Records an event."}, "torch.cuda.ExternalStream.wait_event": {"Parameters": {"event (torch.cuda.Event)": "an event to wait for."}, "description": "Makes all future work submitted to the stream wait for an event."}, "torch.cuda.ExternalStream.wait_stream": {"Parameters": {"stream (Stream)": "a stream to synchronize."}, "description": "Synchronizes with another stream."}}, "description": "Wrapper around an externally allocated CUDA stream."}, "torch.cuda.Event": {"Parameters": {"enable_timing (bool, optional)": "indicates if the event should measure time\n(default: False)", "blocking (bool, optional)": "if True, wait() will be blocking (default: False)", "interprocess (bool)": "if True, the event can be shared between processes\n(default: False)"}, "method": {"torch.cuda.Event.query": {"Returns": "A boolean indicating if all work currently captured by event has\ncompleted.\n", "description": "Checks if all work currently captured by event has completed."}}, "description": "Wrapper around a CUDA event."}, "torch.cuda.graph_pool_handle": {"description": "Returns an opaque token representing the id of a graph memory pool."}, "torch.cuda.CUDAGraph": {"method": {"torch.cuda.CUDAGraph.capture_begin": {"Parameters": {"pool (optional)": "Token (returned by graph_pool_handle() or\nother_Graph_instance.pool()) that hints this graph may share memory\nwith the indicated pool.  See Graph memory management."}, "description": "Begins capturing CUDA work on the current stream."}}, "description": "Wrapper around a CUDA graph."}, "torch.cuda.graph": {"Parameters": {"cuda_graph (torch.cuda.CUDAGraph)": "Graph object used for capture.", "pool (optional)": "Opaque token (returned by a call to graph_pool_handle() or\nother_Graph_instance.pool()) hinting this graph\u2019s capture\nmay share memory from the specified pool. See Graph memory management.", "stream (torch.cuda.Stream, optional)": "If supplied, will be set as the current stream in the context.\nIf not supplied, graph sets its own internal side stream as the current stream in the context."}, "description": "Context-manager that captures CUDA work into a torch.cuda.CUDAGraph object for later replay."}, "torch.cuda.make_graphed_callables": {"Parameters": {"callables (torch.nn.Module or Python function, or tuple of these)": "Callable or callables to graph.\nSee Graph memory management for when passing a tuple of callables\nis appropriate.  If you pass a tuple of callables, their order in the tuple must be the same order\nthey\u2019ll run in the live workload.", "sample_args (tuple of Tensors, or tuple of tuples of Tensors)": "Samples args for each callable.\nIf a single callable was passed, sample_args must be a single tuple of argument Tensors.\nIf a tuple of callables was passed, sample_args must be tuple of tuples of argument Tensors."}, "description": "Accepts callables (functions or nn.Modules) and returns graphed versions."}, "torch.cuda.empty_cache": {"description": "Releases all unoccupied cached memory currently held by the caching allocator so that those can be used in other GPU application and visible in nvidia-smi."}, "torch.cuda.list_gpu_processes": {"Parameters": {"device (torch.device or int, optional)": "selected device. Returns\nprintout for the current device, given by current_device(),\nif device is None (default)."}, "description": "Returns a human-readable printout of the running processes and their GPU memory use for a given device."}, "torch.cuda.mem_get_info": {"Parameters": {"device (torch.device or int, optional)": "selected device. Returns\nstatistic for the current device, given by current_device(),\nif device is None (default)."}, "description": "Returns the global free and total GPU memory occupied for a given device using cudaMemGetInfo."}, "torch.cuda.memory_stats": {"Parameters": {"device (torch.device or int, optional)": "selected device. Returns\nstatistics for the current device, given by current_device(),\nif device is None (default)."}, "description": "Returns a dictionary of CUDA memory allocator statistics for a given device."}, "torch.cuda.memory_summary": {"Parameters": {"device (torch.device or int, optional)": "selected device. Returns\nprintout for the current device, given by current_device(),\nif device is None (default).", "abbreviated (bool, optional)": "whether to return an abbreviated summary\n(default: False)."}, "description": "Returns a human-readable printout of the current memory allocator statistics for a given device."}, "torch.cuda.memory_snapshot": {"description": "Returns a snapshot of the CUDA memory allocator state across all devices."}, "torch.cuda.memory_allocated": {"Parameters": {"device (torch.device or int, optional)": "selected device. Returns\nstatistic for the current device, given by current_device(),\nif device is None (default)."}, "description": "Returns the current GPU memory occupied by tensors in bytes for a given device."}, "torch.cuda.max_memory_allocated": {"Parameters": {"device (torch.device or int, optional)": "selected device. Returns\nstatistic for the current device, given by current_device(),\nif device is None (default)."}, "description": "Returns the maximum GPU memory occupied by tensors in bytes for a given device."}, "torch.cuda.reset_max_memory_allocated": {"Parameters": {"device (torch.device or int, optional)": "selected device. Returns\nstatistic for the current device, given by current_device(),\nif device is None (default)."}, "description": "Resets the starting point in tracking maximum GPU memory occupied by tensors for a given device."}, "torch.cuda.memory_reserved": {"Parameters": {"device (torch.device or int, optional)": "selected device. Returns\nstatistic for the current device, given by current_device(),\nif device is None (default)."}, "description": "Returns the current GPU memory managed by the caching allocator in bytes for a given device."}, "torch.cuda.max_memory_reserved": {"Parameters": {"device (torch.device or int, optional)": "selected device. Returns\nstatistic for the current device, given by current_device(),\nif device is None (default)."}, "description": "Returns the maximum GPU memory managed by the caching allocator in bytes for a given device."}, "torch.cuda.set_per_process_memory_fraction": {"Parameters": {"fraction (float)": "Range: 0~1. Allowed memory equals total_memory * fraction.", "device (torch.device or int, optional)": "selected device. If it is\nNone the default CUDA device is used."}, "description": "Set memory fraction for a process."}, "torch.cuda.memory_cached": {"description": "Deprecated; see memory_reserved()."}, "torch.cuda.max_memory_cached": {"description": "Deprecated; see max_memory_reserved()."}, "torch.cuda.reset_max_memory_cached": {"Parameters": {"device (torch.device or int, optional)": "selected device. Returns\nstatistic for the current device, given by current_device(),\nif device is None (default)."}, "description": "Resets the starting point in tracking maximum GPU memory managed by the caching allocator for a given device."}, "torch.cuda.reset_peak_memory_stats": {"Parameters": {"device (torch.device or int, optional)": "selected device. Returns\nstatistic for the current device, given by current_device(),\nif device is None (default)."}, "description": "Resets the \u201cpeak\u201d stats tracked by the CUDA memory allocator."}, "torch.cuda.caching_allocator_alloc": {"Parameters": {"size (int)": "number of bytes to be allocated.", "device (torch.device or int, optional)": "selected device. If it is\nNone the default CUDA device is used.", "stream (torch.cuda.Stream or int, optional)": "selected stream. If is None then\nthe default stream for the selected device is used."}, "description": "Performs a memory allocation using the CUDA memory allocator."}, "torch.cuda.caching_allocator_delete": {"Parameters": {"mem_ptr (int)": "memory address to be freed by the allocator."}, "description": "Deletes memory allocated using the CUDA memory allocator."}, "torch.cuda.nvtx.mark": {"Parameters": {"msg (string)": "ASCII message to associate with the event."}, "description": "Describe an instantaneous event that occurred at some point."}, "torch.cuda.nvtx.range_push": {"Parameters": {"msg (string)": "ASCII message to associate with range"}, "description": "Pushes a range onto a stack of nested range span."}, "torch.cuda.nvtx.range_pop": {"description": "Pops a range off of a stack of nested range spans."}, "torch.fft.fft": {"Parameters": {"input (Tensor)": "the input tensor", "n (int, optional)": "Signal length. If given, the input will either be zero-padded\nor trimmed to this length before computing the FFT.", "dim (int, optional)": "The dimension along which to take the one dimensional FFT.", "norm (str, optional)": "Normalization mode. For the forward transform\n(fft()), these correspond to:\n\n\"forward\" - normalize by 1/n\n\"backward\" - no normalization\n\"ortho\" - normalize by 1/sqrt(n) (making the FFT orthonormal)\n\nCalling the backward transform (ifft()) with the same\nnormalization mode will apply an overall normalization of 1/n between\nthe two transforms. This is required to make ifft()\nthe exact inverse.\nDefault is \"backward\" (no normalization)."}, "description": "Computes the one dimensional discrete Fourier transform of input."}, "torch.fft.ifft": {"Parameters": {"input (Tensor)": "the input tensor", "n (int, optional)": "Signal length. If given, the input will either be zero-padded\nor trimmed to this length before computing the IFFT.", "dim (int, optional)": "The dimension along which to take the one dimensional IFFT.", "norm (str, optional)": "Normalization mode. For the backward transform\n(ifft()), these correspond to:\n\n\"forward\" - no normalization\n\"backward\" - normalize by 1/n\n\"ortho\" - normalize by 1/sqrt(n) (making the IFFT orthonormal)\n\nCalling the forward transform (fft()) with the same\nnormalization mode will apply an overall normalization of 1/n between\nthe two transforms. This is required to make ifft()\nthe exact inverse.\nDefault is \"backward\" (normalize by 1/n)."}, "description": "Computes the one dimensional inverse discrete Fourier transform of input."}, "torch.fft.fft2": {"Parameters": {"input (Tensor)": "the input tensor", "s (Tuple[int], optional)": "Signal size in the transformed dimensions.\nIf given, each dimension dim[i] will either be zero-padded or\ntrimmed to the length s[i] before computing the FFT.\nIf a length -1 is specified, no padding is done in that dimension.\nDefault: s = [input.size(d) for d in dim]", "dim (Tuple[int], optional)": "Dimensions to be transformed.\nDefault: last two dimensions.", "norm (str, optional)": "Normalization mode. For the forward transform\n(fft2()), these correspond to:\n\n\"forward\" - normalize by 1/n\n\"backward\" - no normalization\n\"ortho\" - normalize by 1/sqrt(n) (making the FFT orthonormal)\n\nWhere n = prod(s) is the logical FFT size.\nCalling the backward transform (ifft2()) with the same\nnormalization mode will apply an overall normalization of 1/n\nbetween the two transforms. This is required to make\nifft2() the exact inverse.\nDefault is \"backward\" (no normalization)."}, "description": "Computes the 2 dimensional discrete Fourier transform of input."}, "torch.fft.ifft2": {"Parameters": {"input (Tensor)": "the input tensor", "s (Tuple[int], optional)": "Signal size in the transformed dimensions.\nIf given, each dimension dim[i] will either be zero-padded or\ntrimmed to the length s[i] before computing the IFFT.\nIf a length -1 is specified, no padding is done in that dimension.\nDefault: s = [input.size(d) for d in dim]", "dim (Tuple[int], optional)": "Dimensions to be transformed.\nDefault: last two dimensions.", "norm (str, optional)": "Normalization mode. For the backward transform\n(ifft2()), these correspond to:\n\n\"forward\" - no normalization\n\"backward\" - normalize by 1/n\n\"ortho\" - normalize by 1/sqrt(n) (making the IFFT orthonormal)\n\nWhere n = prod(s) is the logical IFFT size.\nCalling the forward transform (fft2()) with the same\nnormalization mode will apply an overall normalization of 1/n between\nthe two transforms. This is required to make ifft2()\nthe exact inverse.\nDefault is \"backward\" (normalize by 1/n)."}, "description": "Computes the 2 dimensional inverse discrete Fourier transform of input."}, "torch.fft.fftn": {"Parameters": {"input (Tensor)": "the input tensor", "s (Tuple[int], optional)": "Signal size in the transformed dimensions.\nIf given, each dimension dim[i] will either be zero-padded or\ntrimmed to the length s[i] before computing the FFT.\nIf a length -1 is specified, no padding is done in that dimension.\nDefault: s = [input.size(d) for d in dim]", "dim (Tuple[int], optional)": "Dimensions to be transformed.\nDefault: all dimensions, or the last len(s) dimensions if s is given.", "norm (str, optional)": "Normalization mode. For the forward transform\n(fftn()), these correspond to:\n\n\"forward\" - normalize by 1/n\n\"backward\" - no normalization\n\"ortho\" - normalize by 1/sqrt(n) (making the FFT orthonormal)\n\nWhere n = prod(s) is the logical FFT size.\nCalling the backward transform (ifftn()) with the same\nnormalization mode will apply an overall normalization of 1/n\nbetween the two transforms. This is required to make\nifftn() the exact inverse.\nDefault is \"backward\" (no normalization)."}, "description": "Computes the N dimensional discrete Fourier transform of input."}, "torch.fft.ifftn": {"Parameters": {"input (Tensor)": "the input tensor", "s (Tuple[int], optional)": "Signal size in the transformed dimensions.\nIf given, each dimension dim[i] will either be zero-padded or\ntrimmed to the length s[i] before computing the IFFT.\nIf a length -1 is specified, no padding is done in that dimension.\nDefault: s = [input.size(d) for d in dim]", "dim (Tuple[int], optional)": "Dimensions to be transformed.\nDefault: all dimensions, or the last len(s) dimensions if s is given.", "norm (str, optional)": "Normalization mode. For the backward transform\n(ifftn()), these correspond to:\n\n\"forward\" - no normalization\n\"backward\" - normalize by 1/n\n\"ortho\" - normalize by 1/sqrt(n) (making the IFFT orthonormal)\n\nWhere n = prod(s) is the logical IFFT size.\nCalling the forward transform (fftn()) with the same\nnormalization mode will apply an overall normalization of 1/n between\nthe two transforms. This is required to make ifftn()\nthe exact inverse.\nDefault is \"backward\" (normalize by 1/n)."}, "description": "Computes the N dimensional inverse discrete Fourier transform of input."}, "torch.fft.rfft": {"Parameters": {"input (Tensor)": "the real input tensor", "n (int, optional)": "Signal length. If given, the input will either be zero-padded\nor trimmed to this length before computing the real FFT.", "dim (int, optional)": "The dimension along which to take the one dimensional real FFT.", "norm (str, optional)": "Normalization mode. For the forward transform\n(rfft()), these correspond to:\n\n\"forward\" - normalize by 1/n\n\"backward\" - no normalization\n\"ortho\" - normalize by 1/sqrt(n) (making the FFT orthonormal)\n\nCalling the backward transform (irfft()) with the same\nnormalization mode will apply an overall normalization of 1/n between\nthe two transforms. This is required to make irfft()\nthe exact inverse.\nDefault is \"backward\" (no normalization)."}, "description": "Computes the one dimensional Fourier transform of real-valued input."}, "torch.fft.irfft": {"Parameters": {"input (Tensor)": "the input tensor representing a half-Hermitian signal", "n (int, optional)": "Output signal length. This determines the length of the\noutput signal. If given, the input will either be zero-padded or trimmed to this\nlength before computing the real IFFT.\nDefaults to even output: n=2*(input.size(dim) - 1).", "dim (int, optional)": "The dimension along which to take the one dimensional real IFFT.", "norm (str, optional)": "Normalization mode. For the backward transform\n(irfft()), these correspond to:\n\n\"forward\" - no normalization\n\"backward\" - normalize by 1/n\n\"ortho\" - normalize by 1/sqrt(n) (making the real IFFT orthonormal)\n\nCalling the forward transform (rfft()) with the same\nnormalization mode will apply an overall normalization of 1/n between\nthe two transforms. This is required to make irfft()\nthe exact inverse.\nDefault is \"backward\" (normalize by 1/n)."}, "description": "Computes the inverse of rfft()."}, "torch.fft.rfft2": {"Parameters": {"input (Tensor)": "the input tensor", "s (Tuple[int], optional)": "Signal size in the transformed dimensions.\nIf given, each dimension dim[i] will either be zero-padded or\ntrimmed to the length s[i] before computing the real FFT.\nIf a length -1 is specified, no padding is done in that dimension.\nDefault: s = [input.size(d) for d in dim]", "dim (Tuple[int], optional)": "Dimensions to be transformed.\nDefault: last two dimensions.", "norm (str, optional)": "Normalization mode. For the forward transform\n(rfft2()), these correspond to:\n\n\"forward\" - normalize by 1/n\n\"backward\" - no normalization\n\"ortho\" - normalize by 1/sqrt(n) (making the real FFT orthonormal)\n\nWhere n = prod(s) is the logical FFT size.\nCalling the backward transform (irfft2()) with the same\nnormalization mode will apply an overall normalization of 1/n between\nthe two transforms. This is required to make irfft2()\nthe exact inverse.\nDefault is \"backward\" (no normalization)."}, "description": "Computes the 2-dimensional discrete Fourier transform of real input."}, "torch.fft.irfft2": {"Parameters": {"input (Tensor)": "the input tensor", "s (Tuple[int], optional)": "Signal size in the transformed dimensions.\nIf given, each dimension dim[i] will either be zero-padded or\ntrimmed to the length s[i] before computing the real FFT.\nIf a length -1 is specified, no padding is done in that dimension.\nDefaults to even output in the last dimension:\ns[-1] = 2*(input.size(dim[-1]) - 1).", "dim (Tuple[int], optional)": "Dimensions to be transformed.\nThe last dimension must be the half-Hermitian compressed dimension.\nDefault: last two dimensions.", "norm (str, optional)": "Normalization mode. For the backward transform\n(irfft2()), these correspond to:\n\n\"forward\" - no normalization\n\"backward\" - normalize by 1/n\n\"ortho\" - normalize by 1/sqrt(n) (making the real IFFT orthonormal)\n\nWhere n = prod(s) is the logical IFFT size.\nCalling the forward transform (rfft2()) with the same\nnormalization mode will apply an overall normalization of 1/n between\nthe two transforms. This is required to make irfft2()\nthe exact inverse.\nDefault is \"backward\" (normalize by 1/n)."}, "description": "Computes the inverse of rfft2()."}, "torch.fft.rfftn": {"Parameters": {"input (Tensor)": "the input tensor", "s (Tuple[int], optional)": "Signal size in the transformed dimensions.\nIf given, each dimension dim[i] will either be zero-padded or\ntrimmed to the length s[i] before computing the real FFT.\nIf a length -1 is specified, no padding is done in that dimension.\nDefault: s = [input.size(d) for d in dim]", "dim (Tuple[int], optional)": "Dimensions to be transformed.\nDefault: all dimensions, or the last len(s) dimensions if s is given.", "norm (str, optional)": "Normalization mode. For the forward transform\n(rfftn()), these correspond to:\n\n\"forward\" - normalize by 1/n\n\"backward\" - no normalization\n\"ortho\" - normalize by 1/sqrt(n) (making the real FFT orthonormal)\n\nWhere n = prod(s) is the logical FFT size.\nCalling the backward transform (irfftn()) with the same\nnormalization mode will apply an overall normalization of 1/n between\nthe two transforms. This is required to make irfftn()\nthe exact inverse.\nDefault is \"backward\" (no normalization)."}, "description": "Computes the N-dimensional discrete Fourier transform of real input."}, "torch.fft.irfftn": {"Parameters": {"input (Tensor)": "the input tensor", "s (Tuple[int], optional)": "Signal size in the transformed dimensions.\nIf given, each dimension dim[i] will either be zero-padded or\ntrimmed to the length s[i] before computing the real FFT.\nIf a length -1 is specified, no padding is done in that dimension.\nDefaults to even output in the last dimension:\ns[-1] = 2*(input.size(dim[-1]) - 1).", "dim (Tuple[int], optional)": "Dimensions to be transformed.\nThe last dimension must be the half-Hermitian compressed dimension.\nDefault: all dimensions, or the last len(s) dimensions if s is given.", "norm (str, optional)": "Normalization mode. For the backward transform\n(irfftn()), these correspond to:\n\n\"forward\" - no normalization\n\"backward\" - normalize by 1/n\n\"ortho\" - normalize by 1/sqrt(n) (making the real IFFT orthonormal)\n\nWhere n = prod(s) is the logical IFFT size.\nCalling the forward transform (rfftn()) with the same\nnormalization mode will apply an overall normalization of 1/n between\nthe two transforms. This is required to make irfftn()\nthe exact inverse.\nDefault is \"backward\" (normalize by 1/n)."}, "description": "Computes the inverse of rfftn()."}, "torch.fft.hfft": {"Parameters": {"input (Tensor)": "the input tensor representing a half-Hermitian signal", "n (int, optional)": "Output signal length. This determines the length of the\nreal output. If given, the input will either be zero-padded or trimmed to this\nlength before computing the Hermitian FFT.\nDefaults to even output: n=2*(input.size(dim) - 1).", "dim (int, optional)": "The dimension along which to take the one dimensional Hermitian FFT.", "norm (str, optional)": "Normalization mode. For the forward transform\n(hfft()), these correspond to:\n\n\"forward\" - normalize by 1/n\n\"backward\" - no normalization\n\"ortho\" - normalize by 1/sqrt(n) (making the Hermitian FFT orthonormal)\n\nCalling the backward transform (ihfft()) with the same\nnormalization mode will apply an overall normalization of 1/n between\nthe two transforms. This is required to make ihfft()\nthe exact inverse.\nDefault is \"backward\" (no normalization)."}, "description": "Computes the one dimensional discrete Fourier transform of a Hermitian symmetric input signal."}, "torch.fft.ihfft": {"Parameters": {"input (Tensor)": "the real input tensor", "n (int, optional)": "Signal length. If given, the input will either be zero-padded\nor trimmed to this length before computing the Hermitian IFFT.", "dim (int, optional)": "The dimension along which to take the one dimensional Hermitian IFFT.", "norm (str, optional)": "Normalization mode. For the backward transform\n(ihfft()), these correspond to:\n\n\"forward\" - no normalization\n\"backward\" - normalize by 1/n\n\"ortho\" - normalize by 1/sqrt(n) (making the IFFT orthonormal)\n\nCalling the forward transform (hfft()) with the same\nnormalization mode will apply an overall normalization of 1/n between\nthe two transforms. This is required to make ihfft()\nthe exact inverse.\nDefault is \"backward\" (normalize by 1/n)."}, "description": "Computes the inverse of hfft()."}, "torch.fft.hfft2": {"Parameters": {"input (Tensor)": "the input tensor", "s (Tuple[int], optional)": "Signal size in the transformed dimensions.\nIf given, each dimension dim[i] will either be zero-padded or\ntrimmed to the length s[i] before computing the Hermitian FFT.\nIf a length -1 is specified, no padding is done in that dimension.\nDefaults to even output in the last dimension:\ns[-1] = 2*(input.size(dim[-1]) - 1).", "dim (Tuple[int], optional)": "Dimensions to be transformed.\nThe last dimension must be the half-Hermitian compressed dimension.\nDefault: last two dimensions.", "norm (str, optional)": "Normalization mode. For the forward transform\n(hfft2()), these correspond to:\n\n\"forward\" - normalize by 1/n\n\"backward\" - no normalization\n\"ortho\" - normalize by 1/sqrt(n) (making the Hermitian FFT orthonormal)\n\nWhere n = prod(s) is the logical FFT size.\nCalling the backward transform (ihfft2()) with the same\nnormalization mode will apply an overall normalization of 1/n between\nthe two transforms. This is required to make ihfft2()\nthe exact inverse.\nDefault is \"backward\" (no normalization)."}, "description": "Computes the 2-dimensional discrete Fourier transform of a Hermitian symmetric input signal."}, "torch.fft.ihfft2": {"Parameters": {"input (Tensor)": "the input tensor", "s (Tuple[int], optional)": "Signal size in the transformed dimensions.\nIf given, each dimension dim[i] will either be zero-padded or\ntrimmed to the length s[i] before computing the Hermitian IFFT.\nIf a length -1 is specified, no padding is done in that dimension.\nDefault: s = [input.size(d) for d in dim]", "dim (Tuple[int], optional)": "Dimensions to be transformed.\nDefault: last two dimensions.", "norm (str, optional)": "Normalization mode. For the backward transform\n(ihfft2()), these correspond to:\n\n\"forward\" - no normalization\n\"backward\" - normalize by 1/n\n\"ortho\" - normalize by 1/sqrt(n) (making the Hermitian IFFT orthonormal)\n\nWhere n = prod(s) is the logical IFFT size.\nCalling the forward transform (hfft2()) with the same\nnormalization mode will apply an overall normalization of 1/n between\nthe two transforms. This is required to make ihfft2()\nthe exact inverse.\nDefault is \"backward\" (normalize by 1/n)."}, "description": "Computes the 2-dimensional inverse discrete Fourier transform of real input."}, "torch.fft.hfftn": {"Parameters": {"input (Tensor)": "the input tensor", "s (Tuple[int], optional)": "Signal size in the transformed dimensions.\nIf given, each dimension dim[i] will either be zero-padded or\ntrimmed to the length s[i] before computing the real FFT.\nIf a length -1 is specified, no padding is done in that dimension.\nDefaults to even output in the last dimension:\ns[-1] = 2*(input.size(dim[-1]) - 1).", "dim (Tuple[int], optional)": "Dimensions to be transformed.\nThe last dimension must be the half-Hermitian compressed dimension.\nDefault: all dimensions, or the last len(s) dimensions if s is given.", "norm (str, optional)": "Normalization mode. For the forward transform\n(hfftn()), these correspond to:\n\n\"forward\" - normalize by 1/n\n\"backward\" - no normalization\n\"ortho\" - normalize by 1/sqrt(n) (making the Hermitian FFT orthonormal)\n\nWhere n = prod(s) is the logical FFT size.\nCalling the backward transform (ihfftn()) with the same\nnormalization mode will apply an overall normalization of 1/n between\nthe two transforms. This is required to make ihfftn()\nthe exact inverse.\nDefault is \"backward\" (no normalization)."}, "description": "Computes the n-dimensional discrete Fourier transform of a Herimitian symmetric input signal."}, "torch.fft.ihfftn": {"Parameters": {"input (Tensor)": "the input tensor", "s (Tuple[int], optional)": "Signal size in the transformed dimensions.\nIf given, each dimension dim[i] will either be zero-padded or\ntrimmed to the length s[i] before computing the Hermitian IFFT.\nIf a length -1 is specified, no padding is done in that dimension.\nDefault: s = [input.size(d) for d in dim]", "dim (Tuple[int], optional)": "Dimensions to be transformed.\nDefault: all dimensions, or the last len(s) dimensions if s is given.", "norm (str, optional)": "Normalization mode. For the backward transform\n(ihfftn()), these correspond to:\n\n\"forward\" - no normalization\n\"backward\" - normalize by 1/n\n\"ortho\" - normalize by 1/sqrt(n) (making the Hermitian IFFT orthonormal)\n\nWhere n = prod(s) is the logical IFFT size.\nCalling the forward transform (hfftn()) with the same\nnormalization mode will apply an overall normalization of 1/n between\nthe two transforms. This is required to make ihfftn()\nthe exact inverse.\nDefault is \"backward\" (normalize by 1/n)."}, "description": "Computes the N-dimensional inverse discrete Fourier transform of real input."}, "torch.fft.fftfreq": {"Parameters": {"n (int)": "the FFT length", "d (float, optional)": "The sampling length scale.\nThe spacing between individual samples of the FFT input.\nThe default assumes unit spacing, dividing that result by the actual\nspacing gives the result in physical frequency units."}, "description": "Computes the discrete Fourier Transform sample frequencies for a signal of size n."}, "torch.fft.rfftfreq": {"Parameters": {"n (int)": "the real FFT length", "d (float, optional)": "The sampling length scale.\nThe spacing between individual samples of the FFT input.\nThe default assumes unit spacing, dividing that result by the actual\nspacing gives the result in physical frequency units."}, "description": "Computes the sample frequencies for rfft() with a signal of size n."}, "torch.fft.fftshift": {"Parameters": {"input (Tensor)": "the tensor in FFT order", "dim (int, Tuple[int], optional)": "The dimensions to rearrange.\nOnly dimensions specified here will be rearranged, any other dimensions\nwill be left in their original order.\nDefault: All dimensions of input."}, "description": "Reorders n-dimensional FFT data, as provided by fftn(), to have negative frequency terms first."}, "torch.fft.ifftshift": {"Parameters": {"input (Tensor)": "the tensor in FFT order", "dim (int, Tuple[int], optional)": "The dimensions to rearrange.\nOnly dimensions specified here will be rearranged, any other dimensions\nwill be left in their original order.\nDefault: All dimensions of input."}, "description": "Inverse of fftshift()."}, "torch.jit.script": {"Parameters": {"obj (callable, class, or nn.Module)": "The nn.Module, function, class type,\ndictionary, or list to compile.", "example_inputs (Union[List[Tuple], Dict[Callable, List[Tuple]], None])": "Provide example inputs\nto annotate the arguments for a function or nn.Module."}, "Returns": "If obj is nn.Module, script returns\na ScriptModule object. The returned ScriptModule will\nhave the same set of sub-modules and parameters as the\noriginal nn.Module. If obj is a standalone function,\na ScriptFunction will be returned. If obj is a dict, then\nscript returns an instance of torch._C.ScriptDict. If obj is a list,\nthen script returns an instance of torch._C.ScriptList.\n", "description": "Scripting a function or nn.Module will inspect the source code, compile it as TorchScript code using the TorchScript compiler, and return a ScriptModule or ScriptFunction."}, "torch.jit.trace": {"Parameters": {"func (callable or torch.nn.Module)": "A Python function or torch.nn.Module\nthat will be run with example_inputs. func arguments and return\nvalues  must be tensors or (possibly nested) tuples that contain\ntensors. When a module is passed torch.jit.trace, only the\nforward method is run and traced (see torch.jit.trace for details).", "example_inputs (tuple or torch.Tensor)": "A tuple of example inputs that\nwill be passed to the function while tracing. The resulting trace\ncan be run with inputs of different types and shapes assuming the\ntraced operations support those types and shapes. example_inputs\nmay also be a single Tensor in which case it is automatically\nwrapped in a tuple."}, "Returns": "If func is nn.Module or forward of nn.Module, trace returns\na ScriptModule object with a single forward method\ncontaining the traced code.  The returned ScriptModule will\nhave the same set of sub-modules and parameters as the original\nnn.Module.  If func is a standalone function, trace\nreturns ScriptFunction.\n", "description": "Trace a function and return an executable  or ScriptFunction that will be optimized using just-in-time compilation."}, "torch.jit.script_if_tracing": {"Parameters": {"fn": "A function to compile."}, "Returns": "If called during tracing, a ScriptFunction created by torch.jit.script is returned.\nOtherwise, the original function fn is returned.\n", "description": "Compiles fn when it is first called during tracing."}, "torch.jit.trace_module": {"Parameters": {"mod (torch.nn.Module)": "A torch.nn.Module containing methods whose names are\nspecified in inputs. The given methods will be compiled\nas a part of a single ScriptModule.", "inputs (dict)": "A dict containing sample inputs indexed by method names in mod.\nThe inputs will be passed to methods whose names correspond to inputs\u2019\nkeys while tracing.\n{ 'forward' : example_forward_input, 'method2': example_method2_input}"}, "Returns": "A ScriptModule object with a single forward method containing the traced code.\nWhen func is a torch.nn.Module, the returned ScriptModule will have the same set of\nsub-modules and parameters as func.\n", "description": "Trace a module and return an executable ScriptModule that will be optimized using just-in-time compilation."}, "torch.jit.fork": {"Parameters": {"func (callable or torch.nn.Module)": "A Python function or torch.nn.Module\nthat will be invoked. If executed in TorchScript, it will execute asynchronously,\notherwise it will not. Traced invocations of fork will be captured in the IR.", "*args": "arguments to invoke func with.", "**kwargs": "arguments to invoke func with."}, "Returns": "a reference to the execution of func. The value T\ncan only be accessed by forcing completion of func through torch.jit.wait.\n", "description": "Creates an asynchronous task executing func and a reference to the value of the result of this execution."}, "torch.jit.wait": {"Returns": "the return value of the the completed task\n", "description": "Forces completion of a torch.jit.Future[T] asynchronous task, returning the result of the task."}, "torch.jit.ScriptModule": {"method": {"torch.jit.ScriptModule.add_module": {"Parameters": {"name (string)": "name of the child module. The child module can be\naccessed from this module using the given name", "module (Module)": "child module to be added to the module."}, "description": "Adds a child module to the current module."}, "torch.jit.ScriptModule.apply": {"Parameters": {"fn (Module -> None)": "function to be applied to each submodule"}, "Returns": "self\n", "description": null}, "torch.jit.ScriptModule.bfloat16": {"Returns": "self\n", "description": null}, "torch.jit.ScriptModule.buffers": {"Parameters": {"recurse (bool)": "if True, then yields buffers of this module\nand all submodules. Otherwise, yields only buffers that\nare direct members of this module."}, "description": "Returns an iterator over module buffers."}, "torch.jit.ScriptModule.children": {"description": "Returns an iterator over immediate children modules."}, "torch.jit.ScriptModule.cpu": {"Returns": "self\n", "description": "Moves all model parameters and buffers to the CPU."}, "torch.jit.ScriptModule.cuda": {"Parameters": {"device (int, optional)": "if specified, all parameters will be\ncopied to that device"}, "Returns": "self\n", "description": "Moves all model parameters and buffers to the GPU."}, "torch.jit.ScriptModule.double": {"Returns": "self\n", "description": null}, "torch.jit.ScriptModule.eval": {"Returns": "self\n", "description": "Sets the module in evaluation mode."}, "torch.jit.ScriptModule.float": {"Returns": "self\n", "description": null}, "torch.jit.ScriptModule.get_buffer": {"Parameters": {"target": "The fully-qualified string name of the buffer\nto look for. (See get_submodule for how to specify a\nfully-qualified string.)"}, "Returns": "The buffer referenced by target\n", "description": null}, "torch.jit.ScriptModule.get_extra_state": {"Returns": "Any extra state to store in the module\u2019s state_dict\n", "description": null}, "torch.jit.ScriptModule.get_parameter": {"Parameters": {"target": "The fully-qualified string name of the Parameter\nto look for. (See get_submodule for how to specify a\nfully-qualified string.)"}, "Returns": "The Parameter referenced by target\n", "description": null}, "torch.jit.ScriptModule.get_submodule": {"Parameters": {"target": "The fully-qualified string name of the submodule\nto look for. (See above example for how to specify a\nfully-qualified string.)"}, "Returns": "The submodule referenced by target\n", "description": null}, "torch.jit.ScriptModule.half": {"Returns": "self\n", "description": null}, "torch.jit.ScriptModule.load_state_dict": {"Parameters": {"state_dict (dict)": "a dict containing parameters and\npersistent buffers.", "strict (bool, optional)": "whether to strictly enforce that the keys\nin state_dict match the keys returned by this module\u2019s\nstate_dict() function. Default: True"}, "Returns": "\nmissing_keys is a list of str containing the missing keys\nunexpected_keys is a list of str containing the unexpected keys\n\n\n", "description": null}, "torch.jit.ScriptModule.modules": {"description": "Returns an iterator over all modules in the network."}, "torch.jit.ScriptModule.named_buffers": {"Parameters": {"prefix (str)": "prefix to prepend to all buffer names.", "recurse (bool)": "if True, then yields buffers of this module\nand all submodules. Otherwise, yields only buffers that\nare direct members of this module."}, "description": "Returns an iterator over module buffers, yielding both the\nname of the buffer as well as the buffer itself."}, "torch.jit.ScriptModule.named_children": {"description": "Returns an iterator over immediate children modules, yielding both\nthe name of the module as well as the module itself."}, "torch.jit.ScriptModule.named_modules": {"Parameters": {"memo": "a memo to store the set of modules already added to the result", "prefix": "a prefix that will be added to the name of the module", "remove_duplicate": "whether to remove the duplicated module instances in the result\nor not"}, "description": "Returns an iterator over all modules in the network, yielding\nboth the name of the module as well as the module itself."}, "torch.jit.ScriptModule.named_parameters": {"Parameters": {"prefix (str)": "prefix to prepend to all parameter names.", "recurse (bool)": "if True, then yields parameters of this module\nand all submodules. Otherwise, yields only parameters that\nare direct members of this module."}, "description": "Returns an iterator over module parameters, yielding both the\nname of the parameter as well as the parameter itself."}, "torch.jit.ScriptModule.parameters": {"Parameters": {"recurse (bool)": "if True, then yields parameters of this module\nand all submodules. Otherwise, yields only parameters that\nare direct members of this module."}, "description": "Returns an iterator over module parameters."}, "torch.jit.ScriptModule.register_backward_hook": {"Returns": "a handle that can be used to remove the added hook by calling\nhandle.remove()\n", "description": "Registers a backward hook on the module."}, "torch.jit.ScriptModule.register_buffer": {"Parameters": {"name (string)": "name of the buffer. The buffer can be accessed\nfrom this module using the given name", "tensor (Tensor or None)": "buffer to be registered. If None, then operations\nthat run on buffers, such as cuda, are ignored. If None,\nthe buffer is not included in the module\u2019s state_dict.", "persistent (bool)": "whether the buffer is part of this module\u2019s\nstate_dict."}, "description": "Adds a buffer to the module."}, "torch.jit.ScriptModule.register_forward_hook": {"Returns": "a handle that can be used to remove the added hook by calling\nhandle.remove()\n", "description": "Registers a forward hook on the module."}, "torch.jit.ScriptModule.register_forward_pre_hook": {"Returns": "a handle that can be used to remove the added hook by calling\nhandle.remove()\n", "description": "Registers a forward pre-hook on the module."}, "torch.jit.ScriptModule.register_full_backward_hook": {"Returns": "a handle that can be used to remove the added hook by calling\nhandle.remove()\n", "description": "Registers a backward hook on the module."}, "torch.jit.ScriptModule.register_parameter": {"Parameters": {"name (string)": "name of the parameter. The parameter can be accessed\nfrom this module using the given name", "param (Parameter or None)": "parameter to be added to the module. If\nNone, then operations that run on parameters, such as cuda,\nare ignored. If None, the parameter is not included in the\nmodule\u2019s state_dict."}, "description": "Adds a parameter to the module."}, "torch.jit.ScriptModule.requires_grad_": {"Parameters": {"requires_grad (bool)": "whether autograd should record operations on\nparameters in this module. Default: True."}, "Returns": "self\n", "description": "Change if autograd should record operations on parameters in this\nmodule."}, "torch.jit.ScriptModule.set_extra_state": {"Parameters": {"state (dict)": "Extra state from the state_dict"}, "description": null}, "torch.jit.ScriptModule.state_dict": {"Returns": "a dictionary containing a whole state of the module\n", "description": "Returns a dictionary containing a whole state of the module."}, "torch.jit.ScriptModule.to": {"Parameters": {"device (torch.device)": "the desired device of the parameters\nand buffers in this module", "dtype (torch.dtype)": "the desired floating point or complex dtype of\nthe parameters and buffers in this module", "tensor (torch.Tensor)": "Tensor whose dtype and device are the desired\ndtype and device for all parameters and buffers in this module", "memory_format (torch.memory_format)": "the desired memory\nformat for 4D parameters and buffers in this module (keyword\nonly argument)"}, "Returns": "self\n", "description": "Moves and/or casts the parameters and buffers."}, "torch.jit.ScriptModule.to_empty": {"Parameters": {"device (torch.device)": "The desired device of the parameters\nand buffers in this module."}, "Returns": "self\n", "description": "Moves the parameters and buffers to the specified device without copying storage."}, "torch.jit.ScriptModule.train": {"Parameters": {"mode (bool)": "whether to set training mode (True) or evaluation\nmode (False). Default: True."}, "Returns": "self\n", "description": "Sets the module in training mode."}, "torch.jit.ScriptModule.type": {"Parameters": {"dst_type (type or string)": "the desired type"}, "Returns": "self\n", "description": null}, "torch.jit.ScriptModule.xpu": {"Parameters": {"device (int, optional)": "if specified, all parameters will be\ncopied to that device"}, "Returns": "self\n", "description": "Moves all model parameters and buffers to the XPU."}, "torch.jit.ScriptModule.zero_grad": {"Parameters": {"set_to_none (bool)": "instead of setting to zero, set the grads to None.\nSee torch.optim.Optimizer.zero_grad() for details."}, "description": null}}, "description": "A wrapper around C++ torch::jit::Module."}, "torch.jit.ScriptFunction": {"description": "Functionally equivalent to a ScriptModule, but represents a single function and does not have any attributes or Parameters."}, "torch.jit.freeze": {"Parameters": {"mod (ScriptModule)": "a module to be frozen", "preserved_attrs (Optional[List[str]])": "a list of attributes to preserve in addition to the forward method.", "modified in preserved methods will also be preserved. (Attributes)": "", "optimize_numerics (bool)": "If True, a set of optimization passes will be run that does not strictly", "numerics. Full details of optimization can be found at torch.jit.run_frozen_optimizations. (preserve)": ""}, "Returns": "Frozen ScriptModule.\n", "description": "Freezing a ScriptModule will clone it and attempt to inline the cloned module\u2019s submodules, parameters, and attributes as constants in the TorchScript IR Graph."}, "torch.jit.optimize_for_inference": {"description": "Performs a set of optimization passes to optimize a model for the purposes of inference."}, "torch.jit.set_fusion_strategy": {"description": "Sets the type and number of specializations that can occur during fusion."}, "torch.jit.save": {"Parameters": {"m": "A ScriptModule to save.", "f": "A file-like object (has to implement write and flush) or a string\ncontaining a file name.", "_extra_files": "Map from filename to contents which will be stored as part of f."}, "description": "Save an offline version of this module for use in a separate process."}, "torch.jit.load": {"Parameters": {"f": "a file-like object (has to implement read, readline, tell, and seek),\nor a string containing a file name", "map_location (string or torch.device)": "A simplified version of\nmap_location in torch.jit.save used to dynamically remap\nstorages to an alternative set of devices.", "_extra_files (dictionary of filename to content)": "The extra\nfilenames given in the map would be loaded and their content\nwould be stored in the provided map."}, "Returns": "A ScriptModule object.\n", "description": "Load a ScriptModule or ScriptFunction previously saved with torch.jit.save"}, "torch.jit.ignore": {"description": "This decorator indicates to the compiler that a function or method should be ignored and left as a Python function."}, "torch.jit.unused": {"description": "This decorator indicates to the compiler that a function or method should be ignored and replaced with the raising of an exception."}, "torch.jit.isinstance": {"Parameters": {"obj": "object to refine the type of", "target_type": "type to try to refine obj to"}, "Returns": "\nTrue if obj was successfully refined to the type of target_type,False otherwise with no new type refinement\n\n\n\n", "description": "This function provides for conatiner type refinement in TorchScript."}, "torch.jit.Attribute": {"Parameters": {"value": "An initial value to be assigned to attribute.", "type": "A Python type"}, "Returns": "Returns value\n", "description": "This method is a pass-through function that returns value, mostly used to indicate to the TorchScript compiler that the left-hand side expression is a class instance attribute with type of type."}, "torch.jit.annotate": {"Parameters": {"the_type": "Python type that should be passed to TorchScript compiler as type hint for the_value", "the_value": "Value or expression to hint type for."}, "Returns": "the_value is passed back as return value.\n", "description": "This method is a pass-through function that returns the_value, used to hint TorchScript compiler the type of the_value."}, "torch.linalg.norm": {"Parameters": {"A (Tensor)": "tensor of shape (*, n) or (*, m, n) where * is zero or more batch dimensions", "ord (int, float, inf, -inf, 'fro', 'nuc', optional)": "order of norm. Default: None", "dim (int, Tuple[int], optional)": "dimensions over which to compute\nthe vector or matrix norm. See above for the behavior when dim= None.\nDefault: None", "keepdim (bool, optional)": "If set to True, the reduced dimensions are retained\nin the result as dimensions with size one. Default: False"}, "Returns": "A real-valued tensor, even when A is complex.\n", "description": "Computes a vector or matrix norm."}, "torch.linalg.vector_norm": {"Parameters": {"A (Tensor)": "tensor, flattened by default, but this behavior can be\ncontrolled using dim.", "ord (int, float, inf, -inf, 'fro', 'nuc', optional)": "order of norm. Default: 2", "dim (int, Tuple[int], optional)": "dimensions over which to compute\nthe norm. See above for the behavior when dim= None.\nDefault: None", "keepdim (bool, optional)": "If set to True, the reduced dimensions are retained\nin the result as dimensions with size one. Default: False"}, "Returns": "A real-valued tensor, even when A is complex.\n", "description": "Computes a vector norm."}, "torch.linalg.matrix_norm": {"Parameters": {"A (Tensor)": "tensor with two or more dimensions. By default its\nshape is interpreted as (*, m, n) where * is zero or more\nbatch dimensions, but this behavior can be controlled using dim.", "ord (int, inf, -inf, 'fro', 'nuc', optional)": "order of norm. Default: \u2018fro\u2019", "dim (Tuple[int, int], optional)": "dimensions over which to compute the norm. Default: (-2, -1)", "keepdim (bool, optional)": "If set to True, the reduced dimensions are retained\nin the result as dimensions with size one. Default: False"}, "Returns": "A real-valued tensor, even when A is complex.\n", "description": "Computes a matrix norm."}, "torch.linalg.diagonal": {"description": "Alias for torch.diagonal() with defaults dim1= -2, dim2= -1."}, "torch.linalg.det": {"Parameters": {"A (Tensor)": "tensor of shape (*, n, n) where * is zero or more batch dimensions."}, "description": "Computes the determinant of a square matrix."}, "torch.linalg.slogdet": {"Parameters": {"A (Tensor)": "tensor of shape (*, n, n) where * is zero or more batch dimensions."}, "Returns": "A named tuple (sign, logabsdet).\nlogabsdet will always be real-valued, even when A is complex.\nsign will have the same dtype as A.\n\n", "description": "Computes the sign and natural logarithm of the absolute value of the determinant of a square matrix."}, "torch.linalg.cond": {"Parameters": {"A (Tensor)": "tensor of shape (*, m, n) where * is zero or more batch dimensions\nfor p in (2, -2), and of shape (*, n, n) where every matrix\nis invertible for p in (\u2018fro\u2019, \u2018nuc\u2019, inf, -inf, 1, -1).", "p (int, inf, -inf, 'fro', 'nuc', optional)": "the type of the matrix norm to use in the computations (see above). Default: None"}, "Returns": "A real-valued tensor, even when A is complex.\n", "description": "Computes the condition number of a matrix with respect to a matrix norm."}, "torch.linalg.matrix_rank": {"Parameters": {"A (Tensor)": "tensor of shape (*, m, n) where * is zero or more batch dimensions.", "tol (float, Tensor, optional)": "[NumPy Compat] Alias for atol. Default: None."}, "description": "Computes the numerical rank of a matrix."}, "torch.linalg.cholesky": {"Parameters": {"A (Tensor)": "tensor of shape (*, n, n) where * is zero or more batch dimensions\nconsisting of symmetric or Hermitian positive-definite matrices."}, "description": "Computes the Cholesky decomposition of a complex Hermitian or real symmetric positive-definite matrix."}, "torch.linalg.qr": {"Parameters": {"A (Tensor)": "tensor of shape (*, m, n) where * is zero or more batch dimensions.", "mode (str, optional)": "one of \u2018reduced\u2019, \u2018complete\u2019, \u2018r\u2019.\nControls the shape of the returned tensors. Default: \u2018reduced\u2019."}, "Returns": "A named tuple (Q, R).\n", "description": "Computes the QR decomposition of a matrix."}, "torch.linalg.lu_factor": {"Parameters": {"A (Tensor)": "tensor of shape (*, m, n) where * is zero or more batch dimensions."}, "Returns": "A named tuple (LU, pivots).\n", "description": "Computes a compact representation of the LU factorization with partial pivoting of a matrix."}, "torch.linalg.eig": {"Parameters": {"A (Tensor)": "tensor of shape (*, n, n) where * is zero or more batch dimensions\nconsisting of diagonalizable matrices."}, "Returns": "A named tuple (eigenvalues, eigenvectors) which corresponds to \u039b\\Lambda\u039b and VVV above.\neigenvalues and eigenvectors will always be complex-valued, even when A is real. The eigenvectors\nwill be given by the columns of eigenvectors.\n\n", "description": "Computes the eigenvalue decomposition of a square matrix if it exists."}, "torch.linalg.eigvals": {"Parameters": {"A (Tensor)": "tensor of shape (*, n, n) where * is zero or more batch dimensions."}, "Returns": "A complex-valued tensor cointaining the eigenvalues even when A is real.\n", "description": "Computes the eigenvalues of a square matrix."}, "torch.linalg.eigh": {"Parameters": {"A (Tensor)": "tensor of shape (*, n, n) where * is zero or more batch dimensions\nconsisting of symmetric or Hermitian matrices.", "UPLO ('L', 'U', optional)": "controls whether to use the upper or lower triangular part\nof A in the computations. Default: \u2018L\u2019."}, "Returns": "A named tuple (eigenvalues, eigenvectors) which corresponds to \u039b\\Lambda\u039b and QQQ above.\neigenvalues will always be real-valued, even when A is complex.\nIt will also be ordered in ascending order.\neigenvectors will have the same dtype as A and will contain the eigenvectors as its columns.\n\n", "description": "Computes the eigenvalue decomposition of a complex Hermitian or real symmetric matrix."}, "torch.linalg.eigvalsh": {"Parameters": {"A (Tensor)": "tensor of shape (*, n, n) where * is zero or more batch dimensions\nconsisting of symmetric or Hermitian matrices.", "UPLO ('L', 'U', optional)": "controls whether to use the upper or lower triangular part\nof A in the computations. Default: \u2018L\u2019."}, "Returns": "A real-valued tensor cointaining the eigenvalues even when A is complex.\nThe eigenvalues are returned in ascending order.\n", "description": "Computes the eigenvalues of a complex Hermitian or real symmetric matrix."}, "torch.linalg.svd": {"Parameters": {"A (Tensor)": "tensor of shape (*, m, n) where * is zero or more batch dimensions.", "full_matrices (bool, optional)": "controls whether to compute the full or reduced\nSVD, and consequently,\nthe shape of the returned tensors\nU and Vh. Default: True."}, "Returns": "A named tuple (U, S, Vh) which corresponds to UUU, SSS, VHV^{\\text{H}}VH above.\nS will always be real-valued, even when A is complex.\nIt will also be ordered in descending order.\nU and Vh will have the same dtype as A. The left / right singular vectors will be given by\nthe columns of U and the rows of Vh respectively.\n\n", "description": "Computes the singular value decomposition (SVD) of a matrix."}, "torch.linalg.svdvals": {"Parameters": {"A (Tensor)": "tensor of shape (*, m, n) where * is zero or more batch dimensions."}, "Returns": "A real-valued tensor, even when A is complex.\n", "description": "Computes the singular values of a matrix."}, "torch.linalg.solve": {"Parameters": {"A (Tensor)": "tensor of shape (*, n, n) where * is zero or more batch dimensions.", "B (Tensor)": "right-hand side tensor of shape (*, n) or  (*, n, k) or (n,) or (n, k)\naccording to the rules described above"}, "description": "Computes the solution of a square system of linear equations with a unique solution."}, "torch.linalg.solve_triangular": {"Parameters": {"A (Tensor)": "tensor of shape (*, n, n) (or (*, k, k) if left= True)\nwhere * is zero or more batch dimensions.", "B (Tensor)": "right-hand side tensor of shape (*, n, k)."}, "description": "Computes the solution of a triangular system of linear equations with a unique solution."}, "torch.linalg.lstsq": {"Parameters": {"A (Tensor)": "lhs tensor of shape (*, m, n) where * is zero or more batch dimensions.", "B (Tensor)": "rhs tensor of shape (*, m, k) where * is zero or more batch dimensions.", "rcond (float, optional)": "used to determine the effective rank of A.\nIf rcond= None, rcond is set to the machine\nprecision of the dtype of A times max(m, n). Default: None."}, "Returns": "A named tuple (solution, residuals, rank, singular_values).\n", "description": "Computes a solution to the least squares problem of a system of linear equations."}, "torch.linalg.inv": {"Parameters": {"A (Tensor)": "tensor of shape (*, n, n) where * is zero or more batch dimensions\nconsisting of invertible matrices."}, "description": "Computes the inverse of a square matrix if it exists."}, "torch.linalg.pinv": {"Parameters": {"A (Tensor)": "tensor of shape (*, m, n) where * is zero or more batch dimensions.", "rcond (float, Tensor, optional)": "[NumPy Compat]. Alias for rtol. Default: None."}, "description": "Computes the pseudoinverse (Moore-Penrose inverse) of a matrix."}, "torch.linalg.matrix_exp": {"Parameters": {"A (Tensor)": "tensor of shape (*, n, n) where * is zero or more batch dimensions."}, "description": "Computes the matrix exponential of a square matrix."}, "torch.linalg.matrix_power": {"Parameters": {"A (Tensor)": "tensor of shape (*, m, m) where * is zero or more batch dimensions.", "n (int)": "the exponent."}, "description": "Computes the n-th power of a square matrix for an integer n."}, "torch.linalg.cross": {"Parameters": {"input (Tensor)": "the first input tensor.", "other (Tensor)": "the second input tensor.", "dim (int, optional)": "the dimension along which to take the cross-product. Default: -1."}, "description": "Computes the cross product of two 3-dimensional vectors."}, "torch.linalg.matmul": {"description": "Alias for torch.matmul()"}, "torch.linalg.multi_dot": {"Parameters": {"tensors (Sequence[Tensor])": "two or more tensors to multiply. The first and last\ntensors may be 1D or 2D. Every other tensor must be 2D."}, "description": "Efficiently multiplies two or more matrices by reordering the multiplications so that the fewest arithmetic operations are performed."}, "torch.linalg.householder_product": {"Parameters": {"A (Tensor)": "tensor of shape (*, m, n) where * is zero or more batch dimensions.", "tau (Tensor)": "tensor of shape (*, k) where * is zero or more batch dimensions."}, "description": "Computes the first n columns of a product of Householder matrices."}, "torch.linalg.tensorinv": {"Parameters": {"A (Tensor)": "tensor to invert. Its shape must satisfy\nprod(A.shape[:ind]) ==\nprod(A.shape[ind:]).", "ind (int)": "index at which to compute the inverse of torch.tensordot(). Default: 2."}, "description": "Computes the multiplicative inverse of torch.tensordot()."}, "torch.linalg.tensorsolve": {"Parameters": {"A (Tensor)": "tensor to solve for. Its shape must satisfy\nprod(A.shape[:B.ndim]) ==\nprod(A.shape[B.ndim:]).", "B (Tensor)": "tensor of shape A.shape[B.ndim].", "dims (Tuple[int], optional)": "dimensions of A to be moved.\nIf None, no dimensions are moved. Default: None."}, "description": "Computes the solution X to the system torch.tensordot(A, X) = B."}, "torch.linalg.cholesky_ex": {"Parameters": {"A (Tensor)": "the Hermitian n times n matrix or the batch of such matrices of size\n(*, n, n) where * is one or more batch dimensions."}, "description": "Computes the Cholesky decomposition of a complex Hermitian or real symmetric positive-definite matrix."}, "torch.linalg.inv_ex": {"Parameters": {"A (Tensor)": "tensor of shape (*, n, n) where * is zero or more batch dimensions\nconsisting of square matrices.", "check_errors (bool, optional)": "controls whether to check the content of info. Default: False."}, "description": "Computes the inverse of a square matrix if it is invertible."}, "torch.linalg.lu_factor_ex": {"Parameters": {"A (Tensor)": "tensor of shape (*, m, n) where * is zero or more batch dimensions."}, "Returns": "A named tuple (LU, pivots, info).\n", "description": "This is a version of lu_factor() that does not perform error checks unless check_errors= True."}, "torch.optim.Optimizer.add_param_group": {"Parameters": {"param_group (dict)": "Specifies what Tensors should be optimized along with group\nspecific optimization options."}, "description": "Add a param group to the Optimizer s param_groups."}, "torch.optim.Optimizer.load_state_dict": {"Parameters": {"state_dict (dict)": "optimizer state. Should be an object returned\nfrom a call to state_dict()."}, "description": "Loads the optimizer state."}, "torch.optim.Optimizer.state_dict": {"description": "Returns the state of the optimizer as a dict."}, "torch.optim.Optimizer.step": {"Parameters": {"closure (callable)": "A closure that reevaluates the model and\nreturns the loss. Optional for most optimizers."}, "description": "Performs a single optimization step (parameter update)."}, "torch.optim.Optimizer.zero_grad": {"Parameters": {"set_to_none (bool)": "instead of setting to zero, set the grads to None.\nThis will in general have lower memory footprint, and can modestly improve performance.\nHowever, it changes certain behaviors. For example:\n1. When the user tries to access a gradient and perform manual ops on it,\na None attribute or a Tensor full of 0s will behave differently.\n2. If the user requests zero_grad(set_to_none=True) followed by a backward pass, .grads\nare guaranteed to be None for params that did not receive a gradient.\n3. torch.optim optimizers have a different behavior if the gradient is 0 or None\n(in one case it does the step with a gradient of 0 and in the other it skips\nthe step altogether)."}, "description": "Sets the gradients of all optimized torch.Tensor s to zero."}, "torch.optim.Adadelta": {"Parameters": {"params (iterable)": "iterable of parameters to optimize or dicts defining\nparameter groups", "rho (float, optional)": "coefficient used for computing a running average\nof squared gradients (default: 0.9)", "eps (float, optional)": "term added to the denominator to improve\nnumerical stability (default: 1e-6)", "lr (float, optional)": "coefficient that scale delta before it is applied\nto the parameters (default: 1.0)", "weight_decay (float, optional)": "weight decay (L2 penalty) (default: 0)"}, "method": {"torch.optim.Adadelta.add_param_group": {"Parameters": {"param_group (dict)": "Specifies what Tensors should be optimized along with group\nspecific optimization options."}, "description": null}, "torch.optim.Adadelta.load_state_dict": {"Parameters": {"state_dict (dict)": "optimizer state. Should be an object returned\nfrom a call to state_dict()."}, "description": "Loads the optimizer state."}, "torch.optim.Adadelta.state_dict": {"description": null}, "torch.optim.Adadelta.step": {"Parameters": {"closure (callable, optional)": "A closure that reevaluates the model\nand returns the loss."}, "description": "Performs a single optimization step."}, "torch.optim.Adadelta.zero_grad": {"Parameters": {"set_to_none (bool)": "instead of setting to zero, set the grads to None.\nThis will in general have lower memory footprint, and can modestly improve performance.\nHowever, it changes certain behaviors. For example:\n1. When the user tries to access a gradient and perform manual ops on it,\na None attribute or a Tensor full of 0s will behave differently.\n2. If the user requests zero_grad(set_to_none=True) followed by a backward pass, .grads\nare guaranteed to be None for params that did not receive a gradient.\n3. torch.optim optimizers have a different behavior if the gradient is 0 or None\n(in one case it does the step with a gradient of 0 and in the other it skips\nthe step altogether)."}, "description": null}}, "description": "Implements Adadelta algorithm."}, "torch.optim.Adagrad": {"Parameters": {"params (iterable)": "iterable of parameters to optimize or dicts defining\nparameter groups", "lr (float, optional)": "learning rate (default: 1e-2)", "lr_decay (float, optional)": "learning rate decay (default: 0)", "weight_decay (float, optional)": "weight decay (L2 penalty) (default: 0)", "eps (float, optional)": "term added to the denominator to improve\nnumerical stability (default: 1e-10)"}, "method": {"torch.optim.Adagrad.add_param_group": {"Parameters": {"param_group (dict)": "Specifies what Tensors should be optimized along with group\nspecific optimization options."}, "description": null}, "torch.optim.Adagrad.load_state_dict": {"Parameters": {"state_dict (dict)": "optimizer state. Should be an object returned\nfrom a call to state_dict()."}, "description": "Loads the optimizer state."}, "torch.optim.Adagrad.state_dict": {"description": null}, "torch.optim.Adagrad.step": {"Parameters": {"closure (callable, optional)": "A closure that reevaluates the model\nand returns the loss."}, "description": "Performs a single optimization step."}, "torch.optim.Adagrad.zero_grad": {"Parameters": {"set_to_none (bool)": "instead of setting to zero, set the grads to None.\nThis will in general have lower memory footprint, and can modestly improve performance.\nHowever, it changes certain behaviors. For example:\n1. When the user tries to access a gradient and perform manual ops on it,\na None attribute or a Tensor full of 0s will behave differently.\n2. If the user requests zero_grad(set_to_none=True) followed by a backward pass, .grads\nare guaranteed to be None for params that did not receive a gradient.\n3. torch.optim optimizers have a different behavior if the gradient is 0 or None\n(in one case it does the step with a gradient of 0 and in the other it skips\nthe step altogether)."}, "description": null}}, "description": "Implements Adagrad algorithm."}, "torch.optim.Adam": {"Parameters": {"params (iterable)": "iterable of parameters to optimize or dicts defining\nparameter groups", "lr (float, optional)": "learning rate (default: 1e-3)", "betas (Tuple[float, float], optional)": "coefficients used for computing\nrunning averages of gradient and its square (default: (0.9, 0.999))", "eps (float, optional)": "term added to the denominator to improve\nnumerical stability (default: 1e-8)", "weight_decay (float, optional)": "weight decay (L2 penalty) (default: 0)", "amsgrad (boolean, optional)": "whether to use the AMSGrad variant of this\nalgorithm from the paper On the Convergence of Adam and Beyond\n(default: False)", "maximize (bool, optional)": "maximize the params based on the objective, instead of\nminimizing (default: False)"}, "method": {"torch.optim.Adam.add_param_group": {"Parameters": {"param_group (dict)": "Specifies what Tensors should be optimized along with group\nspecific optimization options."}, "description": null}, "torch.optim.Adam.load_state_dict": {"Parameters": {"state_dict (dict)": "optimizer state. Should be an object returned\nfrom a call to state_dict()."}, "description": "Loads the optimizer state."}, "torch.optim.Adam.state_dict": {"description": null}, "torch.optim.Adam.step": {"Parameters": {"closure (callable, optional)": "A closure that reevaluates the model\nand returns the loss."}, "description": "Performs a single optimization step."}, "torch.optim.Adam.zero_grad": {"Parameters": {"set_to_none (bool)": "instead of setting to zero, set the grads to None.\nThis will in general have lower memory footprint, and can modestly improve performance.\nHowever, it changes certain behaviors. For example:\n1. When the user tries to access a gradient and perform manual ops on it,\na None attribute or a Tensor full of 0s will behave differently.\n2. If the user requests zero_grad(set_to_none=True) followed by a backward pass, .grads\nare guaranteed to be None for params that did not receive a gradient.\n3. torch.optim optimizers have a different behavior if the gradient is 0 or None\n(in one case it does the step with a gradient of 0 and in the other it skips\nthe step altogether)."}, "description": null}}, "description": "Implements Adam algorithm."}, "torch.optim.AdamW": {"Parameters": {"params (iterable)": "iterable of parameters to optimize or dicts defining\nparameter groups", "lr (float, optional)": "learning rate (default: 1e-3)", "betas (Tuple[float, float], optional)": "coefficients used for computing\nrunning averages of gradient and its square (default: (0.9, 0.999))", "eps (float, optional)": "term added to the denominator to improve\nnumerical stability (default: 1e-8)", "weight_decay (float, optional)": "weight decay coefficient (default: 1e-2)", "amsgrad (boolean, optional)": "whether to use the AMSGrad variant of this\nalgorithm from the paper On the Convergence of Adam and Beyond\n(default: False)", "maximize (bool, optional)": "maximize the params based on the objective, instead of\nminimizing (default: False)"}, "method": {"torch.optim.AdamW.add_param_group": {"Parameters": {"param_group (dict)": "Specifies what Tensors should be optimized along with group\nspecific optimization options."}, "description": null}, "torch.optim.AdamW.load_state_dict": {"Parameters": {"state_dict (dict)": "optimizer state. Should be an object returned\nfrom a call to state_dict()."}, "description": "Loads the optimizer state."}, "torch.optim.AdamW.state_dict": {"description": null}, "torch.optim.AdamW.step": {"Parameters": {"closure (callable, optional)": "A closure that reevaluates the model\nand returns the loss."}, "description": "Performs a single optimization step."}, "torch.optim.AdamW.zero_grad": {"Parameters": {"set_to_none (bool)": "instead of setting to zero, set the grads to None.\nThis will in general have lower memory footprint, and can modestly improve performance.\nHowever, it changes certain behaviors. For example:\n1. When the user tries to access a gradient and perform manual ops on it,\na None attribute or a Tensor full of 0s will behave differently.\n2. If the user requests zero_grad(set_to_none=True) followed by a backward pass, .grads\nare guaranteed to be None for params that did not receive a gradient.\n3. torch.optim optimizers have a different behavior if the gradient is 0 or None\n(in one case it does the step with a gradient of 0 and in the other it skips\nthe step altogether)."}, "description": null}}, "description": "Implements AdamW algorithm."}, "torch.optim.SparseAdam": {"Parameters": {"params (iterable)": "iterable of parameters to optimize or dicts defining\nparameter groups", "lr (float, optional)": "learning rate (default: 1e-3)", "betas (Tuple[float, float], optional)": "coefficients used for computing\nrunning averages of gradient and its square (default: (0.9, 0.999))", "eps (float, optional)": "term added to the denominator to improve\nnumerical stability (default: 1e-8)"}, "method": {"torch.optim.SparseAdam.add_param_group": {"Parameters": {"param_group (dict)": "Specifies what Tensors should be optimized along with group\nspecific optimization options."}, "description": null}, "torch.optim.SparseAdam.load_state_dict": {"Parameters": {"state_dict (dict)": "optimizer state. Should be an object returned\nfrom a call to state_dict()."}, "description": "Loads the optimizer state."}, "torch.optim.SparseAdam.state_dict": {"description": null}, "torch.optim.SparseAdam.step": {"Parameters": {"closure (callable, optional)": "A closure that reevaluates the model\nand returns the loss."}, "description": "Performs a single optimization step."}, "torch.optim.SparseAdam.zero_grad": {"Parameters": {"set_to_none (bool)": "instead of setting to zero, set the grads to None.\nThis will in general have lower memory footprint, and can modestly improve performance.\nHowever, it changes certain behaviors. For example:\n1. When the user tries to access a gradient and perform manual ops on it,\na None attribute or a Tensor full of 0s will behave differently.\n2. If the user requests zero_grad(set_to_none=True) followed by a backward pass, .grads\nare guaranteed to be None for params that did not receive a gradient.\n3. torch.optim optimizers have a different behavior if the gradient is 0 or None\n(in one case it does the step with a gradient of 0 and in the other it skips\nthe step altogether)."}, "description": null}}, "description": "Implements lazy version of Adam algorithm suitable for sparse tensors."}, "torch.optim.Adamax": {"Parameters": {"params (iterable)": "iterable of parameters to optimize or dicts defining\nparameter groups", "lr (float, optional)": "learning rate (default: 2e-3)", "betas (Tuple[float, float], optional)": "coefficients used for computing\nrunning averages of gradient and its square", "eps (float, optional)": "term added to the denominator to improve\nnumerical stability (default: 1e-8)", "weight_decay (float, optional)": "weight decay (L2 penalty) (default: 0)"}, "method": {"torch.optim.Adamax.add_param_group": {"Parameters": {"param_group (dict)": "Specifies what Tensors should be optimized along with group\nspecific optimization options."}, "description": null}, "torch.optim.Adamax.load_state_dict": {"Parameters": {"state_dict (dict)": "optimizer state. Should be an object returned\nfrom a call to state_dict()."}, "description": "Loads the optimizer state."}, "torch.optim.Adamax.state_dict": {"description": null}, "torch.optim.Adamax.step": {"Parameters": {"closure (callable, optional)": "A closure that reevaluates the model\nand returns the loss."}, "description": "Performs a single optimization step."}, "torch.optim.Adamax.zero_grad": {"Parameters": {"set_to_none (bool)": "instead of setting to zero, set the grads to None.\nThis will in general have lower memory footprint, and can modestly improve performance.\nHowever, it changes certain behaviors. For example:\n1. When the user tries to access a gradient and perform manual ops on it,\na None attribute or a Tensor full of 0s will behave differently.\n2. If the user requests zero_grad(set_to_none=True) followed by a backward pass, .grads\nare guaranteed to be None for params that did not receive a gradient.\n3. torch.optim optimizers have a different behavior if the gradient is 0 or None\n(in one case it does the step with a gradient of 0 and in the other it skips\nthe step altogether)."}, "description": null}}, "description": "Implements Adamax algorithm (a variant of Adam based on infinity norm)."}, "torch.optim.ASGD": {"Parameters": {"params (iterable)": "iterable of parameters to optimize or dicts defining\nparameter groups", "lr (float, optional)": "learning rate (default: 1e-2)", "lambd (float, optional)": "decay term (default: 1e-4)", "alpha (float, optional)": "power for eta update (default: 0.75)", "t0 (float, optional)": "point at which to start averaging (default: 1e6)", "weight_decay (float, optional)": "weight decay (L2 penalty) (default: 0)"}, "method": {"torch.optim.ASGD.add_param_group": {"Parameters": {"param_group (dict)": "Specifies what Tensors should be optimized along with group\nspecific optimization options."}, "description": null}, "torch.optim.ASGD.load_state_dict": {"Parameters": {"state_dict (dict)": "optimizer state. Should be an object returned\nfrom a call to state_dict()."}, "description": "Loads the optimizer state."}, "torch.optim.ASGD.state_dict": {"description": null}, "torch.optim.ASGD.step": {"Parameters": {"closure (callable, optional)": "A closure that reevaluates the model\nand returns the loss."}, "description": "Performs a single optimization step."}, "torch.optim.ASGD.zero_grad": {"Parameters": {"set_to_none (bool)": "instead of setting to zero, set the grads to None.\nThis will in general have lower memory footprint, and can modestly improve performance.\nHowever, it changes certain behaviors. For example:\n1. When the user tries to access a gradient and perform manual ops on it,\na None attribute or a Tensor full of 0s will behave differently.\n2. If the user requests zero_grad(set_to_none=True) followed by a backward pass, .grads\nare guaranteed to be None for params that did not receive a gradient.\n3. torch.optim optimizers have a different behavior if the gradient is 0 or None\n(in one case it does the step with a gradient of 0 and in the other it skips\nthe step altogether)."}, "description": null}}, "description": "Implements Averaged Stochastic Gradient Descent."}, "torch.optim.LBFGS": {"Parameters": {"lr (float)": "learning rate (default: 1)", "max_iter (int)": "maximal number of iterations per optimization step\n(default: 20)", "max_eval (int)": "maximal number of function evaluations per optimization\nstep (default: max_iter * 1.25).", "tolerance_grad (float)": "termination tolerance on first order optimality\n(default: 1e-5).", "tolerance_change (float)": "termination tolerance on function\nvalue/parameter changes (default: 1e-9).", "history_size (int)": "update history size (default: 100).", "line_search_fn (str)": "either \u2018strong_wolfe\u2019 or None (default: None)."}, "method": {"torch.optim.LBFGS.add_param_group": {"Parameters": {"param_group (dict)": "Specifies what Tensors should be optimized along with group\nspecific optimization options."}, "description": null}, "torch.optim.LBFGS.load_state_dict": {"Parameters": {"state_dict (dict)": "optimizer state. Should be an object returned\nfrom a call to state_dict()."}, "description": "Loads the optimizer state."}, "torch.optim.LBFGS.state_dict": {"description": null}, "torch.optim.LBFGS.step": {"Parameters": {"closure (callable)": "A closure that reevaluates the model\nand returns the loss."}, "description": "Performs a single optimization step."}, "torch.optim.LBFGS.zero_grad": {"Parameters": {"set_to_none (bool)": "instead of setting to zero, set the grads to None.\nThis will in general have lower memory footprint, and can modestly improve performance.\nHowever, it changes certain behaviors. For example:\n1. When the user tries to access a gradient and perform manual ops on it,\na None attribute or a Tensor full of 0s will behave differently.\n2. If the user requests zero_grad(set_to_none=True) followed by a backward pass, .grads\nare guaranteed to be None for params that did not receive a gradient.\n3. torch.optim optimizers have a different behavior if the gradient is 0 or None\n(in one case it does the step with a gradient of 0 and in the other it skips\nthe step altogether)."}, "description": null}}, "description": "Implements L-BFGS algorithm, heavily inspired by minFunc."}, "torch.optim.NAdam": {"Parameters": {"params (iterable)": "iterable of parameters to optimize or dicts defining\nparameter groups", "lr (float, optional)": "learning rate (default: 2e-3)", "betas (Tuple[float, float], optional)": "coefficients used for computing\nrunning averages of gradient and its square (default: (0.9, 0.999))", "eps (float, optional)": "term added to the denominator to improve\nnumerical stability (default: 1e-8)", "weight_decay (float, optional)": "weight decay (L2 penalty) (default: 0)", "momentum_decay (float, optional)": "momentum momentum_decay (default: 4e-3)"}, "method": {"torch.optim.NAdam.add_param_group": {"Parameters": {"param_group (dict)": "Specifies what Tensors should be optimized along with group\nspecific optimization options."}, "description": null}, "torch.optim.NAdam.load_state_dict": {"Parameters": {"state_dict (dict)": "optimizer state. Should be an object returned\nfrom a call to state_dict()."}, "description": "Loads the optimizer state."}, "torch.optim.NAdam.state_dict": {"description": null}, "torch.optim.NAdam.step": {"Parameters": {"closure (callable, optional)": "A closure that reevaluates the model\nand returns the loss."}, "description": "Performs a single optimization step."}, "torch.optim.NAdam.zero_grad": {"Parameters": {"set_to_none (bool)": "instead of setting to zero, set the grads to None.\nThis will in general have lower memory footprint, and can modestly improve performance.\nHowever, it changes certain behaviors. For example:\n1. When the user tries to access a gradient and perform manual ops on it,\na None attribute or a Tensor full of 0s will behave differently.\n2. If the user requests zero_grad(set_to_none=True) followed by a backward pass, .grads\nare guaranteed to be None for params that did not receive a gradient.\n3. torch.optim optimizers have a different behavior if the gradient is 0 or None\n(in one case it does the step with a gradient of 0 and in the other it skips\nthe step altogether)."}, "description": null}}, "description": "Implements NAdam algorithm."}, "torch.optim.RAdam": {"Parameters": {"params (iterable)": "iterable of parameters to optimize or dicts defining\nparameter groups", "lr (float, optional)": "learning rate (default: 1e-3)", "betas (Tuple[float, float], optional)": "coefficients used for computing\nrunning averages of gradient and its square (default: (0.9, 0.999))", "eps (float, optional)": "term added to the denominator to improve\nnumerical stability (default: 1e-8)", "weight_decay (float, optional)": "weight decay (L2 penalty) (default: 0)"}, "method": {"torch.optim.RAdam.add_param_group": {"Parameters": {"param_group (dict)": "Specifies what Tensors should be optimized along with group\nspecific optimization options."}, "description": null}, "torch.optim.RAdam.load_state_dict": {"Parameters": {"state_dict (dict)": "optimizer state. Should be an object returned\nfrom a call to state_dict()."}, "description": "Loads the optimizer state."}, "torch.optim.RAdam.state_dict": {"description": null}, "torch.optim.RAdam.step": {"Parameters": {"closure (callable, optional)": "A closure that reevaluates the model\nand returns the loss."}, "description": "Performs a single optimization step."}, "torch.optim.RAdam.zero_grad": {"Parameters": {"set_to_none (bool)": "instead of setting to zero, set the grads to None.\nThis will in general have lower memory footprint, and can modestly improve performance.\nHowever, it changes certain behaviors. For example:\n1. When the user tries to access a gradient and perform manual ops on it,\na None attribute or a Tensor full of 0s will behave differently.\n2. If the user requests zero_grad(set_to_none=True) followed by a backward pass, .grads\nare guaranteed to be None for params that did not receive a gradient.\n3. torch.optim optimizers have a different behavior if the gradient is 0 or None\n(in one case it does the step with a gradient of 0 and in the other it skips\nthe step altogether)."}, "description": null}}, "description": "Implements RAdam algorithm."}, "torch.optim.RMSprop": {"Parameters": {"params (iterable)": "iterable of parameters to optimize or dicts defining\nparameter groups", "lr (float, optional)": "learning rate (default: 1e-2)", "momentum (float, optional)": "momentum factor (default: 0)", "alpha (float, optional)": "smoothing constant (default: 0.99)", "eps (float, optional)": "term added to the denominator to improve\nnumerical stability (default: 1e-8)", "centered (bool, optional)": "if True, compute the centered RMSProp,\nthe gradient is normalized by an estimation of its variance", "weight_decay (float, optional)": "weight decay (L2 penalty) (default: 0)"}, "method": {"torch.optim.RMSprop.add_param_group": {"Parameters": {"param_group (dict)": "Specifies what Tensors should be optimized along with group\nspecific optimization options."}, "description": null}, "torch.optim.RMSprop.load_state_dict": {"Parameters": {"state_dict (dict)": "optimizer state. Should be an object returned\nfrom a call to state_dict()."}, "description": "Loads the optimizer state."}, "torch.optim.RMSprop.state_dict": {"description": null}, "torch.optim.RMSprop.step": {"Parameters": {"closure (callable, optional)": "A closure that reevaluates the model\nand returns the loss."}, "description": "Performs a single optimization step."}, "torch.optim.RMSprop.zero_grad": {"Parameters": {"set_to_none (bool)": "instead of setting to zero, set the grads to None.\nThis will in general have lower memory footprint, and can modestly improve performance.\nHowever, it changes certain behaviors. For example:\n1. When the user tries to access a gradient and perform manual ops on it,\na None attribute or a Tensor full of 0s will behave differently.\n2. If the user requests zero_grad(set_to_none=True) followed by a backward pass, .grads\nare guaranteed to be None for params that did not receive a gradient.\n3. torch.optim optimizers have a different behavior if the gradient is 0 or None\n(in one case it does the step with a gradient of 0 and in the other it skips\nthe step altogether)."}, "description": null}}, "description": "Implements RMSprop algorithm."}, "torch.optim.Rprop": {"Parameters": {"params (iterable)": "iterable of parameters to optimize or dicts defining\nparameter groups", "lr (float, optional)": "learning rate (default: 1e-2)", "etas (Tuple[float, float], optional)": "pair of (etaminus, etaplis), that\nare multiplicative increase and decrease factors\n(default: (0.5, 1.2))", "step_sizes (Tuple[float, float], optional)": "a pair of minimal and\nmaximal allowed step sizes (default: (1e-6, 50))"}, "method": {"torch.optim.Rprop.add_param_group": {"Parameters": {"param_group (dict)": "Specifies what Tensors should be optimized along with group\nspecific optimization options."}, "description": null}, "torch.optim.Rprop.load_state_dict": {"Parameters": {"state_dict (dict)": "optimizer state. Should be an object returned\nfrom a call to state_dict()."}, "description": "Loads the optimizer state."}, "torch.optim.Rprop.state_dict": {"description": null}, "torch.optim.Rprop.step": {"Parameters": {"closure (callable, optional)": "A closure that reevaluates the model\nand returns the loss."}, "description": "Performs a single optimization step."}, "torch.optim.Rprop.zero_grad": {"Parameters": {"set_to_none (bool)": "instead of setting to zero, set the grads to None.\nThis will in general have lower memory footprint, and can modestly improve performance.\nHowever, it changes certain behaviors. For example:\n1. When the user tries to access a gradient and perform manual ops on it,\na None attribute or a Tensor full of 0s will behave differently.\n2. If the user requests zero_grad(set_to_none=True) followed by a backward pass, .grads\nare guaranteed to be None for params that did not receive a gradient.\n3. torch.optim optimizers have a different behavior if the gradient is 0 or None\n(in one case it does the step with a gradient of 0 and in the other it skips\nthe step altogether)."}, "description": null}}, "description": "Implements the resilient backpropagation algorithm."}, "torch.optim.SGD": {"Parameters": {"params (iterable)": "iterable of parameters to optimize or dicts defining\nparameter groups", "lr (float)": "learning rate", "momentum (float, optional)": "momentum factor (default: 0)", "weight_decay (float, optional)": "weight decay (L2 penalty) (default: 0)", "dampening (float, optional)": "dampening for momentum (default: 0)", "nesterov (bool, optional)": "enables Nesterov momentum (default: False)", "maximize (bool, optional)": "maximize the params based on the objective, instead of\nminimizing (default: False)"}, "method": {"torch.optim.SGD.add_param_group": {"Parameters": {"param_group (dict)": "Specifies what Tensors should be optimized along with group\nspecific optimization options."}, "description": null}, "torch.optim.SGD.load_state_dict": {"Parameters": {"state_dict (dict)": "optimizer state. Should be an object returned\nfrom a call to state_dict()."}, "description": "Loads the optimizer state."}, "torch.optim.SGD.state_dict": {"description": null}, "torch.optim.SGD.step": {"Parameters": {"closure (callable, optional)": "A closure that reevaluates the model\nand returns the loss."}, "description": "Performs a single optimization step."}, "torch.optim.SGD.zero_grad": {"Parameters": {"set_to_none (bool)": "instead of setting to zero, set the grads to None.\nThis will in general have lower memory footprint, and can modestly improve performance.\nHowever, it changes certain behaviors. For example:\n1. When the user tries to access a gradient and perform manual ops on it,\na None attribute or a Tensor full of 0s will behave differently.\n2. If the user requests zero_grad(set_to_none=True) followed by a backward pass, .grads\nare guaranteed to be None for params that did not receive a gradient.\n3. torch.optim optimizers have a different behavior if the gradient is 0 or None\n(in one case it does the step with a gradient of 0 and in the other it skips\nthe step altogether)."}, "description": null}}, "description": "Implements stochastic gradient descent (optionally with momentum)."}, "torch.optim.lr_scheduler.LambdaLR": {"Parameters": {"optimizer (Optimizer)": "Wrapped optimizer.", "lr_lambda (function or list)": "A function which computes a multiplicative\nfactor given an integer parameter epoch, or a list of such\nfunctions, one for each group in optimizer.param_groups.", "last_epoch (int)": "The index of last epoch. Default: -1.", "verbose (bool)": "If True, prints a message to stdout for\neach update. Default: False."}, "method": {"torch.optim.lr_scheduler.LambdaLR.load_state_dict": {"Parameters": {"state_dict (dict)": "scheduler state. Should be an object returned\nfrom a call to state_dict()."}, "description": "Loads the schedulers state."}}, "description": "Sets the learning rate of each parameter group to the initial lr times a given function."}, "torch.optim.lr_scheduler.MultiplicativeLR": {"Parameters": {"optimizer (Optimizer)": "Wrapped optimizer.", "lr_lambda (function or list)": "A function which computes a multiplicative\nfactor given an integer parameter epoch, or a list of such\nfunctions, one for each group in optimizer.param_groups.", "last_epoch (int)": "The index of last epoch. Default: -1.", "verbose (bool)": "If True, prints a message to stdout for\neach update. Default: False."}, "method": {"torch.optim.lr_scheduler.MultiplicativeLR.load_state_dict": {"Parameters": {"state_dict (dict)": "scheduler state. Should be an object returned\nfrom a call to state_dict()."}, "description": "Loads the schedulers state."}}, "description": "Multiply the learning rate of each parameter group by the factor given in the specified function."}, "torch.optim.lr_scheduler.StepLR": {"Parameters": {"optimizer (Optimizer)": "Wrapped optimizer.", "step_size (int)": "Period of learning rate decay.", "gamma (float)": "Multiplicative factor of learning rate decay.\nDefault: 0.1.", "last_epoch (int)": "The index of last epoch. Default: -1.", "verbose (bool)": "If True, prints a message to stdout for\neach update. Default: False."}, "method": {"torch.optim.lr_scheduler.StepLR.load_state_dict": {"Parameters": {"state_dict (dict)": "scheduler state. Should be an object returned\nfrom a call to state_dict()."}, "description": "Loads the schedulers state."}}, "description": "Decays the learning rate of each parameter group by gamma every step_size epochs."}, "torch.optim.lr_scheduler.MultiStepLR": {"Parameters": {"optimizer (Optimizer)": "Wrapped optimizer.", "milestones (list)": "List of epoch indices. Must be increasing.", "gamma (float)": "Multiplicative factor of learning rate decay.\nDefault: 0.1.", "last_epoch (int)": "The index of last epoch. Default: -1.", "verbose (bool)": "If True, prints a message to stdout for\neach update. Default: False."}, "method": {"torch.optim.lr_scheduler.MultiStepLR.load_state_dict": {"Parameters": {"state_dict (dict)": "scheduler state. Should be an object returned\nfrom a call to state_dict()."}, "description": "Loads the schedulers state."}}, "description": "Decays the learning rate of each parameter group by gamma once the number of epoch reaches one of the milestones."}, "torch.optim.lr_scheduler.ConstantLR": {"Parameters": {"optimizer (Optimizer)": "Wrapped optimizer.", "factor (float)": "The number we multiply learning rate until the milestone. Default: 1./3.", "total_iters (int)": "The number of steps that the scheduler decays the learning rate.\nDefault: 5.", "last_epoch (int)": "The index of the last epoch. Default: -1.", "verbose (bool)": "If True, prints a message to stdout for\neach update. Default: False."}, "method": {"torch.optim.lr_scheduler.ConstantLR.load_state_dict": {"Parameters": {"state_dict (dict)": "scheduler state. Should be an object returned\nfrom a call to state_dict()."}, "description": "Loads the schedulers state."}}, "description": "Decays the learning rate of each parameter group by a small constant factor until the number of epoch reaches a pre-defined milestone: total_iters."}, "torch.optim.lr_scheduler.LinearLR": {"Parameters": {"optimizer (Optimizer)": "Wrapped optimizer.", "start_factor (float)": "The number we multiply learning rate in the first epoch.\nThe multiplication factor changes towards end_factor in the following epochs.\nDefault: 1./3.", "end_factor (float)": "The number we multiply learning rate at the end of linear changing\nprocess. Default: 1.0.", "total_iters (int)": "The number of iterations that multiplicative factor reaches to 1.\nDefault: 5.", "last_epoch (int)": "The index of the last epoch. Default: -1.", "verbose (bool)": "If True, prints a message to stdout for\neach update. Default: False."}, "method": {"torch.optim.lr_scheduler.LinearLR.load_state_dict": {"Parameters": {"state_dict (dict)": "scheduler state. Should be an object returned\nfrom a call to state_dict()."}, "description": "Loads the schedulers state."}}, "description": "Decays the learning rate of each parameter group by linearly changing small multiplicative factor until the number of epoch reaches a pre-defined milestone: total_iters."}, "torch.optim.lr_scheduler.ExponentialLR": {"Parameters": {"optimizer (Optimizer)": "Wrapped optimizer.", "gamma (float)": "Multiplicative factor of learning rate decay.", "last_epoch (int)": "The index of last epoch. Default: -1.", "verbose (bool)": "If True, prints a message to stdout for\neach update. Default: False."}, "method": {"torch.optim.lr_scheduler.ExponentialLR.load_state_dict": {"Parameters": {"state_dict (dict)": "scheduler state. Should be an object returned\nfrom a call to state_dict()."}, "description": "Loads the schedulers state."}}, "description": "Decays the learning rate of each parameter group by gamma every epoch."}, "torch.optim.lr_scheduler.CosineAnnealingLR": {"Parameters": {"optimizer (Optimizer)": "Wrapped optimizer.", "T_max (int)": "Maximum number of iterations.", "eta_min (float)": "Minimum learning rate. Default: 0.", "last_epoch (int)": "The index of last epoch. Default: -1.", "verbose (bool)": "If True, prints a message to stdout for\neach update. Default: False."}, "method": {"torch.optim.lr_scheduler.CosineAnnealingLR.load_state_dict": {"Parameters": {"state_dict (dict)": "scheduler state. Should be an object returned\nfrom a call to state_dict()."}, "description": "Loads the schedulers state."}}, "description": "Set the learning rate of each parameter group using a cosine annealing schedule, where \u03b7max\\eta_{max}\u03b7max\u200b is set to the initial lr and TcurT_{cur}Tcur\u200b is the number of epochs since the last restart in SGDR:"}, "torch.optim.lr_scheduler.ChainedScheduler": {"Parameters": {"schedulers (list)": "List of chained schedulers."}, "method": {"torch.optim.lr_scheduler.ChainedScheduler.load_state_dict": {"Parameters": {"state_dict (dict)": "scheduler state. Should be an object returned\nfrom a call to state_dict()."}, "description": "Loads the schedulers state."}}, "description": "Chains list of learning rate schedulers."}, "torch.optim.lr_scheduler.SequentialLR": {"Parameters": {"optimizer (Optimizer)": "Wrapped optimizer.", "schedulers (list)": "List of chained schedulers.", "milestones (list)": "List of integers that reflects milestone points.", "last_epoch (int)": "The index of last epoch. Default: -1.", "verbose (bool)": "Does nothing."}, "method": {"torch.optim.lr_scheduler.SequentialLR.load_state_dict": {"Parameters": {"state_dict (dict)": "scheduler state. Should be an object returned\nfrom a call to state_dict()."}, "description": "Loads the schedulers state."}}, "description": "Receives the list of schedulers that is expected to be called sequentially during optimization process and milestone points that provides exact intervals to reflect which scheduler is supposed to be called at a given epoch."}, "torch.optim.lr_scheduler.ReduceLROnPlateau": {"Parameters": {"optimizer (Optimizer)": "Wrapped optimizer.", "mode (str)": "One of min, max. In min mode, lr will\nbe reduced when the quantity monitored has stopped\ndecreasing; in max mode it will be reduced when the\nquantity monitored has stopped increasing. Default: \u2018min\u2019.", "factor (float)": "Factor by which the learning rate will be\nreduced. new_lr = lr * factor. Default: 0.1.", "patience (int)": "Number of epochs with no improvement after\nwhich learning rate will be reduced. For example, if\npatience = 2, then we will ignore the first 2 epochs\nwith no improvement, and will only decrease the LR after the\n3rd epoch if the loss still hasn\u2019t improved then.\nDefault: 10.", "threshold (float)": "Threshold for measuring the new optimum,\nto only focus on significant changes. Default: 1e-4.", "threshold_mode (str)": "One of rel, abs. In rel mode,\ndynamic_threshold = best * ( 1 + threshold ) in \u2018max\u2019\nmode or best * ( 1 - threshold ) in min mode.\nIn abs mode, dynamic_threshold = best + threshold in\nmax mode or best - threshold in min mode. Default: \u2018rel\u2019.", "cooldown (int)": "Number of epochs to wait before resuming\nnormal operation after lr has been reduced. Default: 0.", "min_lr (float or list)": "A scalar or a list of scalars. A\nlower bound on the learning rate of all param groups\nor each group respectively. Default: 0.", "eps (float)": "Minimal decay applied to lr. If the difference\nbetween new and old lr is smaller than eps, the update is\nignored. Default: 1e-8.", "verbose (bool)": "If True, prints a message to stdout for\neach update. Default: False."}, "description": "Reduce learning rate when a metric has stopped improving."}, "torch.optim.lr_scheduler.CyclicLR": {"Parameters": {"optimizer (Optimizer)": "Wrapped optimizer.", "base_lr (float or list)": "Initial learning rate which is the\nlower boundary in the cycle for each parameter group.", "max_lr (float or list)": "Upper learning rate boundaries in the cycle\nfor each parameter group. Functionally,\nit defines the cycle amplitude (max_lr - base_lr).\nThe lr at any cycle is the sum of base_lr\nand some scaling of the amplitude; therefore\nmax_lr may not actually be reached depending on\nscaling function.", "step_size_up (int)": "Number of training iterations in the\nincreasing half of a cycle. Default: 2000", "step_size_down (int)": "Number of training iterations in the\ndecreasing half of a cycle. If step_size_down is None,\nit is set to step_size_up. Default: None", "mode (str)": "One of {triangular, triangular2, exp_range}.\nValues correspond to policies detailed above.\nIf scale_fn is not None, this argument is ignored.\nDefault: \u2018triangular\u2019", "gamma (float)": "Constant in \u2018exp_range\u2019 scaling function:\ngamma**(cycle iterations)\nDefault: 1.0", "scale_fn (function)": "Custom scaling policy defined by a single\nargument lambda function, where\n0 <= scale_fn(x) <= 1 for all x >= 0.\nIf specified, then \u2018mode\u2019 is ignored.\nDefault: None", "scale_mode (str)": "{\u2018cycle\u2019, \u2018iterations\u2019}.\nDefines whether scale_fn is evaluated on\ncycle number or cycle iterations (training\niterations since start of cycle).\nDefault: \u2018cycle\u2019", "cycle_momentum (bool)": "If True, momentum is cycled inversely\nto learning rate between \u2018base_momentum\u2019 and \u2018max_momentum\u2019.\nDefault: True", "base_momentum (float or list)": "Lower momentum boundaries in the cycle\nfor each parameter group. Note that momentum is cycled inversely\nto learning rate; at the peak of a cycle, momentum is\n\u2018base_momentum\u2019 and learning rate is \u2018max_lr\u2019.\nDefault: 0.8", "max_momentum (float or list)": "Upper momentum boundaries in the cycle\nfor each parameter group. Functionally,\nit defines the cycle amplitude (max_momentum - base_momentum).\nThe momentum at any cycle is the difference of max_momentum\nand some scaling of the amplitude; therefore\nbase_momentum may not actually be reached depending on\nscaling function. Note that momentum is cycled inversely\nto learning rate; at the start of a cycle, momentum is \u2018max_momentum\u2019\nand learning rate is \u2018base_lr\u2019\nDefault: 0.9", "last_epoch (int)": "The index of the last batch. This parameter is used when\nresuming a training job. Since step() should be invoked after each\nbatch instead of after each epoch, this number represents the total\nnumber of batches computed, not the total number of epochs computed.\nWhen last_epoch=-1, the schedule is started from the beginning.\nDefault: -1", "verbose (bool)": "If True, prints a message to stdout for\neach update. Default: False."}, "method": {"torch.optim.lr_scheduler.CyclicLR.load_state_dict": {"Parameters": {"state_dict (dict)": "scheduler state. Should be an object returned\nfrom a call to state_dict()."}, "description": "Loads the schedulers state."}}, "description": "Sets the learning rate of each parameter group according to cyclical learning rate policy (CLR)."}, "torch.optim.lr_scheduler.OneCycleLR": {"Parameters": {"optimizer (Optimizer)": "Wrapped optimizer.", "max_lr (float or list)": "Upper learning rate boundaries in the cycle\nfor each parameter group.", "total_steps (int)": "The total number of steps in the cycle. Note that\nif a value is not provided here, then it must be inferred by providing\na value for epochs and steps_per_epoch.\nDefault: None", "epochs (int)": "The number of epochs to train for. This is used along\nwith steps_per_epoch in order to infer the total number of steps in the cycle\nif a value for total_steps is not provided.\nDefault: None", "steps_per_epoch (int)": "The number of steps per epoch to train for. This is\nused along with epochs in order to infer the total number of steps in the\ncycle if a value for total_steps is not provided.\nDefault: None", "pct_start (float)": "The percentage of the cycle (in number of steps) spent\nincreasing the learning rate.\nDefault: 0.3", "anneal_strategy (str)": "{\u2018cos\u2019, \u2018linear\u2019}\nSpecifies the annealing strategy: \u201ccos\u201d for cosine annealing, \u201clinear\u201d for\nlinear annealing.\nDefault: \u2018cos\u2019", "cycle_momentum (bool)": "If True, momentum is cycled inversely\nto learning rate between \u2018base_momentum\u2019 and \u2018max_momentum\u2019.\nDefault: True", "base_momentum (float or list)": "Lower momentum boundaries in the cycle\nfor each parameter group. Note that momentum is cycled inversely\nto learning rate; at the peak of a cycle, momentum is\n\u2018base_momentum\u2019 and learning rate is \u2018max_lr\u2019.\nDefault: 0.85", "max_momentum (float or list)": "Upper momentum boundaries in the cycle\nfor each parameter group. Functionally,\nit defines the cycle amplitude (max_momentum - base_momentum).\nNote that momentum is cycled inversely\nto learning rate; at the start of a cycle, momentum is \u2018max_momentum\u2019\nand learning rate is \u2018base_lr\u2019\nDefault: 0.95", "div_factor (float)": "Determines the initial learning rate via\ninitial_lr = max_lr/div_factor\nDefault: 25", "final_div_factor (float)": "Determines the minimum learning rate via\nmin_lr = initial_lr/final_div_factor\nDefault: 1e4", "three_phase (bool)": "If True, use a third phase of the schedule to annihilate the\nlearning rate according to \u2018final_div_factor\u2019 instead of modifying the second\nphase (the first two phases will be symmetrical about the step indicated by\n\u2018pct_start\u2019).", "last_epoch (int)": "The index of the last batch. This parameter is used when\nresuming a training job. Since step() should be invoked after each\nbatch instead of after each epoch, this number represents the total\nnumber of batches computed, not the total number of epochs computed.\nWhen last_epoch=-1, the schedule is started from the beginning.\nDefault: -1", "verbose (bool)": "If True, prints a message to stdout for\neach update. Default: False."}, "method": {"torch.optim.lr_scheduler.OneCycleLR.load_state_dict": {"Parameters": {"state_dict (dict)": "scheduler state. Should be an object returned\nfrom a call to state_dict()."}, "description": "Loads the schedulers state."}}, "description": "Sets the learning rate of each parameter group according to the 1cycle learning rate policy."}, "torch.optim.lr_scheduler.CosineAnnealingWarmRestarts": {"Parameters": {"optimizer (Optimizer)": "Wrapped optimizer.", "T_0 (int)": "Number of iterations for the first restart.", "T_mult (int, optional)": "A factor increases TiT_{i}Ti\u200b after a restart. Default: 1.", "eta_min (float, optional)": "Minimum learning rate. Default: 0.", "last_epoch (int, optional)": "The index of last epoch. Default: -1.", "verbose (bool)": "If True, prints a message to stdout for\neach update. Default: False."}, "method": {"torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.load_state_dict": {"Parameters": {"state_dict (dict)": "scheduler state. Should be an object returned\nfrom a call to state_dict()."}, "description": "Loads the schedulers state."}}, "description": "Set the learning rate of each parameter group using a cosine annealing schedule, where \u03b7max\\eta_{max}\u03b7max\u200b is set to the initial lr, TcurT_{cur}Tcur\u200b is the number of epochs since the last restart and TiT_{i}Ti\u200b is the number of epochs between two warm restarts in SGDR:"}, "Tensor.to_sparse_coo": {"description": "Convert a tensor to coordinate format."}, "Tensor.to_sparse_csr": {"description": "Convert a tensor to compressed row storage format."}, "torch.Tensor.coalesce": {"description": "Returns a coalesced copy of self if self is an uncoalesced tensor."}, "torch.Tensor.sparse_resize_": {"Parameters": {"size (torch.Size)": "the desired size. If self is non-empty\nsparse tensor, the desired size cannot be smaller than the\noriginal size.", "sparse_dim (int)": "the number of sparse dimensions", "dense_dim (int)": "the number of dense dimensions"}, "description": "Resizes self sparse tensor to the desired size and the number of sparse and dense dimensions."}, "torch.Tensor.sparse_resize_and_clear_": {"Parameters": {"size (torch.Size)": "the desired size.", "sparse_dim (int)": "the number of sparse dimensions", "dense_dim (int)": "the number of dense dimensions"}, "description": "Removes all specified elements from a sparse tensor self and resizes self to the desired size and the number of sparse and dense dimensions."}, "torch.Tensor.is_coalesced": {"description": "Returns True if self is a sparse COO tensor that is coalesced, False otherwise."}, "torch.Tensor.to_dense": {"description": "Creates a strided copy of self."}, "Tensor.crow_indices": {"description": "Returns the tensor containing the compressed row indices of the self tensor when self is a sparse CSR tensor of layout sparse_csr."}, "Tensor.col_indices": {"description": "Returns the tensor containing the column indices of the self tensor when self is a sparse CSR tensor of layout sparse_csr."}, "torch.sparse_csr_tensor": {"Parameters": {"crow_indices (array_like)": "One-dimensional array of size size[0] + 1. The last element\nis the number of non-zeros. This tensor encodes the index in values and col_indices\ndepending on where the given row starts. Each successive number in the tensor\nsubtracted by the number before it denotes the number of elements in a given row.", "col_indices (array_like)": "Column co-ordinates of each element in values. Strictly one\ndimensional tensor with the same length as values.", "values (array_list)": "Initial values for the tensor. Can be a list, tuple, NumPy ndarray, scalar,\nand other types.", "size (list, tuple, torch.Size, optional)": "Size of the sparse tensor. If not provided, the\nsize will be inferred as the minimum size big enough to hold all non-zero elements."}, "description": "Constructs a sparse tensor in CSR (Compressed Sparse Row) with specified values at the given crow_indices and col_indices."}, "torch.sparse.sum": {"Parameters": {"input (Tensor)": "the input sparse tensor", "dim (int or tuple of python:ints)": "a dimension or a list of dimensions to reduce. Default: reduce\nover all dims.", "dtype (torch.dtype, optional)": "the desired data type of returned Tensor.\nDefault: dtype of input."}, "description": "Returns the sum of each row of the sparse tensor input in the given dimensions dim."}, "torch.sparse.addmm": {"Parameters": {"mat (Tensor)": "a dense matrix to be added", "mat1 (Tensor)": "a sparse matrix to be multiplied", "mat2 (Tensor)": "a dense matrix to be multiplied", "beta (Number, optional)": "multiplier for mat (\u03b2\\beta\u03b2)", "alpha (Number, optional)": "multiplier for mat1@mat2mat1 @ mat2mat1@mat2 (\u03b1\\alpha\u03b1)"}, "description": "This function does exact same thing as torch.addmm() in the forward, except that it supports backward for sparse matrix mat1."}, "torch.sparse.sampled_addmm": {"Parameters": {"input (Tensor)": "a sparse CSR matrix of shape (m, n) to be added and used to compute\nthe sampled matrix multiplication", "mat1 (Tensor)": "a dense matrix of shape (m, k) to be multiplied", "mat2 (Tensor)": "a dense matrix of shape (k, n) to be multiplied"}, "description": "Performs a matrix multiplication of the dense matrices mat1 and mat2 at the locations specified by the sparsity pattern of input."}, "torch.sparse.mm": {"Parameters": {"mat1 (SparseTensor)": "the first sparse matrix to be multiplied", "mat2 (Tensor)": "the second matrix to be multiplied, which could be sparse or dense"}, "description": "Performs a matrix multiplication of the sparse matrix mat1 and the (sparse or strided) matrix mat2."}, "torch.sspaddmm": {"Parameters": {"input (Tensor)": "a sparse matrix to be added", "mat1 (Tensor)": "a sparse matrix to be matrix multiplied", "mat2 (Tensor)": "a dense matrix to be matrix multiplied"}, "description": "Matrix multiplies a sparse tensor mat1 with a dense tensor mat2, then adds the sparse tensor input to the result."}, "torch.hspmm": {"Parameters": {"mat1 (Tensor)": "the first sparse matrix to be matrix multiplied", "mat2 (Tensor)": "the second strided matrix to be matrix multiplied"}, "description": "Performs a matrix multiplication of a sparse COO matrix mat1 and a strided matrix mat2."}, "torch.smm": {"Parameters": {"input (Tensor)": "a sparse matrix to be matrix multiplied", "mat (Tensor)": "a dense matrix to be matrix multiplied"}, "description": "Performs a matrix multiplication of the sparse matrix input with the dense matrix mat."}, "torch.sparse.softmax": {"Parameters": {"input (Tensor)": "input", "dim (int)": "A dimension along which softmax will be computed.", "dtype (torch.dtype, optional)": "the desired data type\nof returned tensor.  If specified, the input tensor is\ncasted to dtype before the operation is\nperformed. This is useful for preventing data type\noverflows. Default: None"}, "description": "Applies a softmax function."}, "torch.sparse.log_softmax": {"Parameters": {"input (Tensor)": "input", "dim (int)": "A dimension along which softmax will be computed.", "dtype (torch.dtype, optional)": "the desired data type\nof returned tensor.  If specified, the input tensor is\ncasted to dtype before the operation is\nperformed. This is useful for preventing data type\noverflows. Default: None"}, "description": "Applies a softmax function followed by logarithm."}}